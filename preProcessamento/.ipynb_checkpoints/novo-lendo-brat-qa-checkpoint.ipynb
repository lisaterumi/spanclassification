{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando arquivo para NER-NestedClinBr\n",
    "\n",
    "Teste com formato QA.. tem como retornar as entidades descontinuas tbm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTiposEntidade():\n",
    "    return ['Problema','Teste','Tratamento','Anatomia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceWhiteSpaces(str):\n",
    "    return re.sub('\\s{2,}',' ',str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(name, obj):\n",
    "    existeDir = os.path.exists('../obj')\n",
    "    if not existeDir:\n",
    "        os.makedirs('../obj')\n",
    "    with open('../obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    existeDir = os.path.exists('../obj')\n",
    "    if not existeDir:\n",
    "        os.makedirs('../obj')\n",
    "    try:\n",
    "        with open('../obj/' + name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastasCorpus = [r'corpus\\test',r'corpus\\train']\n",
    "#pastasCorpus = [r'corpus\\test']\n",
    "#pastasCorpus = [r'corpus\\TESTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make the World a 2y4Better Place2y0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = 'Make the World a 2.4Better Place2.0'\n",
    "pattern = r'([0-9])\\.([0-9])'\n",
    "replacement = r'\\1y\\2'\n",
    "html = re.sub(pattern, replacement, s)\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicSentences(pastaCorpus):\n",
    "    #devePrintar=True\n",
    "    devePrintar=False\n",
    "    dic_sentences = {}\n",
    "    numMaxTokensPorFrase=0 # numero tokens da maior frase\n",
    "    num=0\n",
    "    listaEntidades=[]\n",
    "    frasesComDescontinuas=[]\n",
    "    for filename in os.listdir(pastaCorpus):\n",
    "        f = os.path.join(pastaCorpus, filename)\n",
    "        if os.path.isfile(f):\n",
    "            fileNameSemExtensao=os.path.splitext(filename)[0]\n",
    "            if devePrintar:\n",
    "                print('\\n\\n--fileName (sem extensao):--', fileNameSemExtensao)\n",
    "                pass\n",
    "            extension = os.path.splitext(filename)[1][1:]\n",
    "            if extension=='ann':\n",
    "                # tokens da frase\n",
    "                fileTxt = open(os.path.join(pastaCorpus, fileNameSemExtensao)+'.txt', \"r\", encoding='utf-8')\n",
    "                linha=fileTxt.readlines()\n",
    "                fileTxt.close()\n",
    "                if devePrintar:\n",
    "                    print('linha:', linha)\n",
    "                    pass\n",
    "                frases=[]\n",
    "                allFrasesString=''\n",
    "                numL=0\n",
    "                for l in linha:\n",
    "                    numL=numL+1\n",
    "                    allFrasesString = allFrasesString+l\n",
    "                    if numL==1: # descarta primeira frase, que é data de criação do doc\n",
    "                        #print('descartando frase:', l)\n",
    "                        continue\n",
    "                    if l.strip() and l.strip()!='\\n':\n",
    "                        #print('l:', l)\n",
    "                        pattern = r'([0-9])\\.([0-9])'\n",
    "                        replacement = r'\\1==\\2'\n",
    "                        novoL = re.sub(pattern, replacement, l.strip())\n",
    "                        l2 = novoL.split('.') # quebrando frases\n",
    "                        for l3 in l2:\n",
    "                            if l3.strip() and l3.strip()!='\\n':\n",
    "                                novaFrase = l3.replace('\\n','').replace('==','.').strip()+'.'\n",
    "                                frases.append(novaFrase)\n",
    "                #print('frases:', frases)\n",
    "                # para cada frase\n",
    "                # para tokenizar nesses tokens\n",
    "                #print('allFrasesString:', allFrasesString)\n",
    "                frasesTokens={}\n",
    "                #numCaracteresTotal=42 # primeira frase ignorada\n",
    "                numIndiceAnterior=0\n",
    "                for frase in frases:\n",
    "                    tokens=[]\n",
    "                    frase2 = frase.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                    frase2 = replaceWhiteSpaces(frase2)\n",
    "                    frase2 = frase2.split()\n",
    "                    for numtoken, token in enumerate(frase2):\n",
    "                        if devePrintar:\n",
    "                            print('token:', token)\n",
    "                            print('numIndiceAnterior:', numIndiceAnterior)\n",
    "                        if token!='.':\n",
    "                            numCaracteresTotal = allFrasesString.find(token, numIndiceAnterior, len(allFrasesString))\n",
    "                        else:\n",
    "                            numCaracteresTotal=numIndiceAnterior+1\n",
    "                        #tokens.append([token,numtoken])\n",
    "                        tokens.append([token,numtoken, numCaracteresTotal])\n",
    "                        numIndiceAnterior = numCaracteresTotal+len(token)-1\n",
    "                        if numMaxTokensPorFrase<len(tokens):\n",
    "                            numMaxTokensPorFrase = len(tokens)\n",
    "                    frasesTokens[frase]=tokens\n",
    "                    #linhaTokens=linha.copy()    \n",
    "                if devePrintar:\n",
    "                    print('frasesTokens:', frasesTokens)\n",
    "                # agora, as entidades\n",
    "                fileAnn = open(f, \"r\", encoding='utf-8')\n",
    "                linha=fileAnn.readlines()\n",
    "                fileAnn.close()\n",
    "\n",
    "                dicEntidades={}\n",
    "                for entidade_linha in linha:\n",
    "                    if ';' not in entidade_linha: # tem descontinua?\n",
    "                        entidade = entidade_linha.split('\\t')\n",
    "                        tipo_entidade = entidade[1]\n",
    "                        inicio, fim = tipo_entidade.split()[1:3]\n",
    "                        tipo_entidade = tipo_entidade.split()[0]\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        dicEntidades[(int(inicio), int(fim))]=[tipo_entidade, replaceWhiteSpaces(termos_entidade)]\n",
    "                    else:\n",
    "                        frasesComDescontinuas.append(num)\n",
    "                        #print('descontinua, linha: {}, num: {}'.format(linha, num))\n",
    "                        #print('descontinua, file: {}, num: {}'.format(filename, num))\n",
    "                        entidade = entidade_linha.split('\\t')\n",
    "                        # ex T10\tProblema 244 252;279 306\tdispneia aos mdoeardos-leves esforço\n",
    "                        #Problema 244 252;279 306\n",
    "                        entidade_temp=entidade[1].split(';')\n",
    "                        entidade1=entidade_temp[0]\n",
    "                        tipo_entidade = entidade1\n",
    "                        inicio1, fim1 = tipo_entidade.split()[1:3]\n",
    "                        tipo_entidade_string = tipo_entidade.split()[0]\n",
    "                        # mandar só os termos referentes...\n",
    "                        tamTermo1=int(fim1)-int(inicio1)\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade=termos_entidade[:tamTermo1]\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        #print('aaaaaaaaaaaaaaaaa')\n",
    "                        dicEntidades[(int(inicio1), int(fim1))]=[tipo_entidade_string, replaceWhiteSpaces(termos_entidade)]\n",
    "                        #print(\"(int(inicio1), int(fim1)):\", (int(inicio1), int(fim1)))\n",
    "                        #print(\"tipo_entidade_string, replaceWhiteSpaces(termos_entidade):\", tipo_entidade_string, replaceWhiteSpaces(termos_entidade))\n",
    "                        \n",
    "                        entidade2=entidade_temp[1]\n",
    "                        inicio2, fim2 = entidade2.split()[0:2]\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade=termos_entidade[tamTermo1:len(termos_entidade)]\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        dicEntidades[(int(inicio2), int(fim2))]=[tipo_entidade_string, replaceWhiteSpaces(termos_entidade)]\n",
    "                        #print(\"(int(inicio2), int(fim2)):\", (int(inicio2), int(fim2)))\n",
    "                        #print(\"tipo_entidade_string, replaceWhiteSpaces(termos_entidade):\", tipo_entidade_string, replaceWhiteSpaces(termos_entidade))\n",
    "\n",
    "\n",
    "                #print('frasesTokens:', frasesTokens)\n",
    "                indicesDic = sorted(dicEntidades.keys(), key = lambda item: item[0])\n",
    "                listaIndicesJaUsados = []\n",
    "                #list_students.sort(key = lambda x: x[1])   #index 1 means second element\n",
    "                #print(indicesDic)\n",
    "                #print('dicEntidades:', dicEntidades)\n",
    "                \n",
    "                for key, value in frasesTokens.items():\n",
    "                    for i in indicesDic:\n",
    "                        tipo_entidade,termos_entidade = dicEntidades[i]\n",
    "                        ##key (i) = indices old a comparar\n",
    "                        #print('key:', key)\n",
    "                        #print('value:', value)\n",
    "                        #print('i:', i)\n",
    "                        for token in value:\n",
    "                            #print('token:', token)\n",
    "                            if i[0]==token[2]:\n",
    "                                novo_inicio, novo_fim = [token[1],token[1]+len(termos_entidade.split())]\n",
    "                                novos_indices=[]\n",
    "                                for k in range(novo_inicio,novo_fim):\n",
    "                                    novos_indices.append(k)\n",
    "                                listaEntidades.append([termos_entidade, novos_indices, tipo_entidade])\n",
    "                                #print(\"[termos_entidade, novos_indices, tipo_entidade]:\", [termos_entidade, novos_indices, tipo_entidade])\n",
    "                            else:\n",
    "                                #print('else, i[0]:',i[0])\n",
    "                                pass\n",
    "                        \n",
    "                    if len(value)>0:\n",
    "                        #print('incluindo:', key)\n",
    "                        dic_sentences[num]=[value, listaEntidades]\n",
    "                        listaEntidades=[]\n",
    "                        num=num+1 \n",
    "\n",
    "        #print(num)\n",
    "        #if num>318:\n",
    "        #    break\n",
    "\n",
    "        #if num>3:\n",
    "        #    break\n",
    "    print('numMaxTokensPorFrase:', numMaxTokensPorFrase)\n",
    "    return dic_sentences, frasesComDescontinuas\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numMaxTokensPorFrase: 146\n"
     ]
    }
   ],
   "source": [
    "dic_sentencesTest, frasesComDescontinuasTest = getDicSentences(pastasCorpus[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Paciente', 0, 43],\n",
       "  ['em', 1, 52],\n",
       "  ['tratamento', 2, 55],\n",
       "  ['para', 3, 66],\n",
       "  ['ICC', 4, 71],\n",
       "  ['diastólica', 5, 75],\n",
       "  ['há', 6, 86],\n",
       "  ['cerca', 7, 89],\n",
       "  ['de', 8, 95],\n",
       "  ['5', 9, 98],\n",
       "  ['a', 10, 100],\n",
       "  ['com', 11, 102],\n",
       "  ['melhora', 12, 106],\n",
       "  ['importante', 13, 114],\n",
       "  ['dos', 14, 125],\n",
       "  ['sintomas', 15, 129],\n",
       "  ['após', 16, 138],\n",
       "  ['início', 17, 143],\n",
       "  ['do', 18, 150],\n",
       "  ['tratamento', 19, 153],\n",
       "  ['.', 20, 163]],\n",
       " [['tratamento', [2], 'Tratamento'],\n",
       "  ['ICC diastólica', [4, 5], 'Problema'],\n",
       "  ['melhora importante dos sintomas após início do tratamento',\n",
       "   [12, 13, 14, 15, 16, 17, 18, 19],\n",
       "   'Problema'],\n",
       "  ['tratamento', [19], 'Tratamento']]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTest[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numMaxTokensPorFrase: 192\n"
     ]
    }
   ],
   "source": [
    "dic_sentencesTrain, frasesComDescontinuasTrain = getDicSentences(pastasCorpus[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Treinamento:-- corpus\\train\n",
      "numMaxTokensPorFrase: 192\n",
      "len(sentences): 1736\n",
      "len(Descontinuas): 91\n",
      "len(frasesComDescontinuas): 51\n",
      "--Teste:-- corpus\\test\n",
      "numMaxTokensPorFrase: 146\n",
      "len(sentences): 506\n",
      "len(Descontinuas): 44\n",
      "len(frasesComDescontinuas): 17\n"
     ]
    }
   ],
   "source": [
    "print('--Treinamento:--', pastasCorpus[1])\n",
    "dic_sentencesTrain, frasesComDescontinuasTrain = getDicSentences(pastasCorpus[1])\n",
    "print('len(sentences):', len(dic_sentencesTrain))\n",
    "print('len(Descontinuas):',len(frasesComDescontinuasTrain))\n",
    "print('len(frasesComDescontinuas):',len(set(frasesComDescontinuasTrain)))\n",
    "\n",
    "\n",
    "print('--Teste:--', pastasCorpus[0])\n",
    "dic_sentencesTest, frasesComDescontinuasTest = getDicSentences(pastasCorpus[0])\n",
    "print('len(sentences):', len(dic_sentencesTest))\n",
    "print('len(Descontinuas):',len(frasesComDescontinuasTest))\n",
    "print('len(frasesComDescontinuas):',len(set(frasesComDescontinuasTest)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Abd', 0, 644],\n",
       "  ['globoso', 1, 648],\n",
       "  [',', 2, 655],\n",
       "  ['flacido', 3, 657],\n",
       "  [',', 4, 664],\n",
       "  ['indolor', 5, 666],\n",
       "  ['a', 6, 674],\n",
       "  ['palpacao', 7, 676],\n",
       "  [',', 8, 684],\n",
       "  ['sem', 9, 686],\n",
       "  ['VCM', 10, 690],\n",
       "  ['.', 11, 693]],\n",
       " [['Abd', [0], 'Anatomia'], ['VCM', [10], 'Problema']]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTest[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CONTRAÇÃO', 0, 507],\n",
       "  ['SEGMENTAR', 1, 517],\n",
       "  ['DO', 2, 527],\n",
       "  ['VE', 3, 530],\n",
       "  ['ALTERADA', 4, 533],\n",
       "  ['.', 5, 541]],\n",
       " [['CONTRAÇÃO SEGMENTAR DO VE ALTERADA', [0, 1, 2, 3, 4], 'Problema'],\n",
       "  ['VE', [3], 'Anatomia']]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTrain[861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 15, 30, 30, 30, 30, 55, 55, 65, 65]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frasesComDescontinuasTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# frases com entidades descontinuas\n",
    "print(len(set(frasesComDescontinuasTrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 49,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 91,\n",
       " 131,\n",
       " 147,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 227,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 263,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 316,\n",
       " 329,\n",
       " 367,\n",
       " 367,\n",
       " 367,\n",
       " 367,\n",
       " 406,\n",
       " 468]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frasesComDescontinuasTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Comorbidades', 0, 142], [':', 1, 154], ['DM', 2, 156], ['há', 3, 159], ['10', 4, 162], ['anos', 5, 165], ['em', 6, 170], ['uso', 7, 173], ['de', 8, 177], ['metformina', 9, 180], ['850mg', 10, 191], ['3', 11, 197], ['cp', 12, 199], ['/', 13, 201], ['dia', 14, 202], [',', 15, 205], ['acarbose', 16, 207], ['1', 17, 216], ['cp', 18, 218], ['/', 19, 220], ['dia', 20, 221], ['e', 21, 225], ['glicazida', 22, 227], ['60mg', 23, 237], ['2', 24, 242], ['cp', 25, 244], ['/', 26, 246], ['dia', 27, 247], ['e', 28, 251], ['insulina', 29, 253], ['(', 30, 262], ['24', 31, 263], ['-', 32, 266], ['0', 33, 268], ['-', 34, 270], ['24', 35, 272], [')', 36, 274], ['.', 37, 275]], [['Comorbidades', [0], 'Problema'], ['DM', [2], 'Problema'], ['metformina 850mg', [9, 10], 'Tratamento'], ['acarbose', [16], 'Tratamento'], ['glicazida 60mg', [22, 23], 'Tratamento'], ['insulina', [29], 'Tratamento']]]\n"
     ]
    }
   ],
   "source": [
    "print(dic_sentencesTest[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanhoTrain 1319\n",
      "tamanhoDev 417\n",
      "len(dic_sentencesTrain): 1319\n",
      "len(dic_sentencesDev): 416\n",
      "[[['Paciente', 0, 151], ['relata', 1, 160], ['apenas', 2, 167], ['um', 3, 174], ['episodio', 4, 177], ['no', 5, 186], ['momento', 6, 189], ['de', 7, 197], ['gripe', 8, 200], ['.', 9, 205]], [['gripe', [8], 'Problema']]]\n",
      "[[['HAS', 0, 207], [',', 1, 210], ['ICC', 2, 212], [',', 3, 215], ['nega', 4, 217], ['DM', 5, 222], ['.', 6, 224]], [['HAS', [0], 'Problema'], ['ICC', [2], 'Problema'], ['DM', [5], 'Problema']]]\n"
     ]
    }
   ],
   "source": [
    "save_obj('dic_sentencesTrainDev',dic_sentencesTrain)\n",
    "porc=0.76\n",
    "tamanhoTotal = len(dic_sentencesTrain)\n",
    "tamanhoTrain = int(tamanhoTotal*porc)\n",
    "print('tamanhoTrain', tamanhoTrain)\n",
    "tamanhoDev = tamanhoTotal - tamanhoTrain\n",
    "print('tamanhoDev', tamanhoDev)\n",
    "dic_sentencesDev_temp = {k: dic_sentencesTrain[k] for k in list(dic_sentencesTrain)[tamanhoTrain:-1]}\n",
    "dic_sentencesTrain = {k: dic_sentencesTrain[k] for k in list(dic_sentencesTrain)[:tamanhoTrain]}\n",
    "num=0\n",
    "dic_sentencesDev = {}\n",
    "for key, value in dic_sentencesDev_temp.items():\n",
    "    dic_sentencesDev[num] = value\n",
    "    num=num+1\n",
    "\n",
    "print('len(dic_sentencesTrain):', len(dic_sentencesTrain))\n",
    "print('len(dic_sentencesDev):', len(dic_sentencesDev))\n",
    "print(dic_sentencesTrain[tamanhoTrain-1])\n",
    "print(dic_sentencesDev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', 0, 207],\n",
       "  [',', 1, 210],\n",
       "  ['ICC', 2, 212],\n",
       "  [',', 3, 215],\n",
       "  ['nega', 4, 217],\n",
       "  ['DM', 5, 222],\n",
       "  ['.', 6, 224]],\n",
       " [['HAS', [0], 'Problema'], ['ICC', [2], 'Problema'], ['DM', [5], 'Problema']]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesDev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['carvedilol', 0, 226],\n",
       "  ['1', 1, 237],\n",
       "  ['cp', 2, 239],\n",
       "  ['12', 3, 242],\n",
       "  ['/', 4, 244],\n",
       "  ['12', 5, 245],\n",
       "  [',', 6, 247],\n",
       "  ['furosemida', 7, 249],\n",
       "  ['20mg', 8, 260],\n",
       "  ['2', 9, 265],\n",
       "  ['cp', 10, 267],\n",
       "  ['de', 11, 270],\n",
       "  ['12', 12, 273],\n",
       "  ['/', 13, 275],\n",
       "  ['12', 14, 276],\n",
       "  [',', 15, 278],\n",
       "  ['sinvastatina', 16, 280],\n",
       "  ['1cp', 17, 293],\n",
       "  ['a', 18, 297],\n",
       "  ['noite', 19, 299],\n",
       "  [',', 20, 304],\n",
       "  ['AAS', 21, 306],\n",
       "  ['100mg', 22, 310],\n",
       "  ['apos', 23, 316],\n",
       "  ['almoço', 24, 321],\n",
       "  ['e', 25, 328],\n",
       "  ['Omeprazol', 26, 330],\n",
       "  ['20mg', 27, 340],\n",
       "  ['1', 28, 345],\n",
       "  ['xdia', 29, 347],\n",
       "  ['.', 30, 351]],\n",
       " [['carvedilol', [0], 'Tratamento'],\n",
       "  ['furosemida 20mg', [7, 8], 'Tratamento'],\n",
       "  ['sinvastatina', [16], 'Tratamento'],\n",
       "  ['AAS 100mg', [21, 22], 'Tratamento'],\n",
       "  ['Omeprazol 20mg', [26, 27], 'Tratamento']]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesDev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[280]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i[2] for i in dic_sentencesDev[1][0] if i[1]==16]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i[0]) for i in dic_sentencesDev[1][0] if i[1]==1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": [{\"title\":texto_1\",\"paragraphs\": [{\"context\": \"Em acompanhamento no ambualtorio há 5 anos por FA , uso de marevan 5mg 1 x ao dia .\", \"qas\": [{\"answers\": [{\"title\":texto_2\",\"paragraphs\": [{\"context\": \"Comorbidades : DM há 10 anos em uso de metformina 850mg 3 cp / dia , acarbose 1 cp / dia e glicazida 60mg 2 cp / dia e insulina ( 24 - 0 - 24 ) .\", \"qas\": [{\"answers\": [{\"title\":texto_3\",\"paragraphs\": [{\"context\": \"HAS há 15 anos em uso de losartana 50mg / dia e digoxina 1 / 2 cp / dia , carvedilol 25 12 / 12 , HCTZ .\", \"qas\": [{\"answers\": [{\"title\":texto_4\",\"paragraphs\": [{\"context\": \"DSLP em uso de sinvastatina , marevan 1 cp / dia seg - sab para no alvo sic .\", \"qas\": [{\"answers\": [{\"title\":texto_6\",\"paragraphs\": [{\"context\": \"Nega dispnéia , DPN e ortopneia , palpitações e sincope .\", \"qas\": [{\"answers\": [{\"title\":texto_7\",\"paragraphs\": [{\"context\": \"O : BEG , corada , hidtratada , afebril , fc 63 , so2 97 % , pa 130 / 80 ; MV presente , simétrico , sem RA .\", \"qas\": [{\"answers\": [{\"title\":texto_8\",\"paragraphs\": [{\"context\": \"BC arritmicas , NF SS 2T .\", \"qas\": [{\"answers\": [{\"title\":texto_9\",\"paragraphs\": [{\"context\": \"Abd globoso , flacido , indolor a palpacao , sem VCM .\", \"qas\": [{\"answers\": [{\"title\":texto_10\",\"paragraphs\": [{\"context\": \"MMII sem edema , panturrilhas livres .\", \"qas\": [{\"answers\": [{\"title\":texto_11\",\"paragraphs\": [{\"context\": \"Exames - Holter : FC controlada , media 92 .\", \"qas\": [{\"answers\": [{\"title\":texto_12\",\"paragraphs\": [{\"context\": \"Cr - 0 , 7 ; glic - 140 ; ureia - 33 ; CPK - 68 , Triglerideos - 335 ; HDL - 30 ; CT - 216 ; LDL - 119 ; K - 5 , 1 ; RNI - 2 , 07 ; Microalbuminúria 308 mg / g .\", \"qas\": [{\"answers\": [{\"title\":texto_13\",\"paragraphs\": [{\"context\": \"Ecocardiograma - ventrículo esquerdo com hipertrofia concentrica de grau discreto e função sistólica preservada .\", \"qas\": [{\"answers\": [{\"title\":texto_14\",\"paragraphs\": [{\"context\": \"aumento moderado de átrio esquerdo .\", \"qas\": [{\"answers\": [{\"title\":texto_15\",\"paragraphs\": [{\"context\": \"calcificação mitral e aórtica com refluxo leve .\", \"qas\": [{\"answers\": [{\"title\":texto_16\",\"paragraphs\": [{\"context\": \"A : FA .\", \"qas\": [{\"answers\": [{\"title\":texto_17\",\"paragraphs\": [{\"context\": \"PA - 120 / 80 , P - 72 , bulhas arritimicas , normofonéticas , sem sopros .\", \"qas\": [{\"answers\": [{\"title\":texto_18\",\"paragraphs\": [{\"context\": \"Abdomen flácido , indolor , sem visceromegalias .\", \"qas\": [{\"answers\": [{\"title\":texto_19\",\"paragraphs\": [{\"context\": \"Sem alterações nos MMII .\", \"qas\": [{\"answers\": [{\"title\":texto_20\",\"paragraphs\": [{\"context\": \"Otimizo dose da sinvastatina para 40mg / dia .\", \"qas\": [{\"answers\": [{\"title\":texto_23\",\"paragraphs\": [{\"context\": \"# Lucas , 78 anos * HAS , * Gota , * DAC - IAM + ATC em 2012 ( angina instavel ) - Ecocardiograma mar / 14 : FE 42 % / comprometimento difuso do VE grau moderado , insuf Mi discreta , insuf Tri discreta , hipetensao pulmonar discreta .\", \"qas\": [{\"answers\": [{\"title\":texto_24\",\"paragraphs\": [{\"context\": \"Paciente refere fraqueza intermitente em MMII , associada a tontura , turvação visual e epigastralgia .\", \"qas\": [{\"answers\": [{\"title\":texto_25\",\"paragraphs\": [{\"context\": \"Nega dor toracica associada ou dispneia .\", \"qas\": [{\"answers\": [{\"title\":texto_26\",\"paragraphs\": [{\"context\": \"Nega DPN .\", \"qas\": [{\"answers\": [{\"title\":texto_27\",\"paragraphs\": [{\"context\": \"Nega sincope .\", \"qas\": [{\"answers\": [{\"title\":texto_28\",\"paragraphs\": [{\"context\": \"Nega edema de MMII .\", \"qas\": [{\"answers\": [{\"title\":texto_30\",\"paragraphs\": [{\"context\": \"Nega queixas urinarias e gastrointestinais .\", \"qas\": [{\"answers\": [{\"title\":texto_31\",\"paragraphs\": [{\"context\": \"Nega tabagismo atual e pregresso .\", \"qas\": [{\"answers\": [{\"title\":texto_32\",\"paragraphs\": [{\"context\": \"- Laboratorio Cr 1 , 5 / glicose 85 / ureia 70 / CPK 161 / acido urico 5 , 3 / TG 107 / TGP 23 / HDL 38 / Na 143 / TGO 26 / CT 103 / LDL 44 / K 5 , 1 / HB 16 , 1 / leucocitos 6800 / plaquetas 116000 / - Albumina / Cr isolada = 174 , 3 *** CKD 44 ; Paciente encaminhado via UBS para nefrologia - aguarda consulta .\", \"qas\": [{\"answers\": [{\"title\":texto_33\",\"paragraphs\": [{\"context\": \"Em uso de : alopurinol 150mg / dia , anlodipino 5mg / noite , enalapril 10mg 12 / 12 h , selozok 100mg / dia , AAS 100mg / dia , clopidogrel 75mg / dia , sinvastatina 40mg / dia , colecalciferol 10 gotas / semana .\", \"qas\": [{\"answers\": [{\"title\":texto_34\",\"paragraphs\": [{\"context\": \"Ao exame : PA : 90 / 60 mmHg / FC 55 bpm , BCRNF , SS , MV + bilateralmente , sem RA , MMII edema + / IV bilateral .\", \"qas\": [{\"answers\": [{\"title\":texto_35\",\"paragraphs\": [{\"context\": \"# # Reduzimos anlodipino para 2 , 5mg / dia .\", \"qas\": [{\"answers\": [{\"title\":texto_36\",\"paragraphs\": [{\"context\": \"Suspendemos clopidogrel .\", \"qas\": [{\"answers\": [{\"title\":texto_37\",\"paragraphs\": [{\"context\": \"Mantemos demais medicações .\", \"qas\": [{\"answers\": [{\"title\":texto_38\",\"paragraphs\": [{\"context\": \"Retorno em 10 meses com a cardio com novos exames .\", \"qas\": [{\"answers\": [{\"title\":texto_41\",\"paragraphs\": [{\"context\": \"* HAS * Gota * DAC - IAM + ATC em 2012 ( angina instavel ) .\", \"qas\": [{\"answers\": [{\"title\":texto_42\",\"paragraphs\": [{\"context\": \"Paciente em tratamento para ICC diastólica há cerca de 5 a com melhora importante dos sintomas após início do tratamento .\", \"qas\": [{\"answers\": [{\"title\":texto_43\",\"paragraphs\": [{\"context\": \"Hoje relata dispneia aos moderados esforços , nega disnpneía paroxística notrna , dorme com apenas 1 travesseiro .\", \"qas\": [{\"answers\": [{\"title\":texto_44\",\"paragraphs\": [{\"context\": \"Nega precordialgia aos moderados esforços .\", \"qas\": [{\"answers\": [{\"title\":texto_45\",\"paragraphs\": [{\"context\": \"Nega episódios anginosos .\", \"qas\": [{\"answers\": [{\"title\":texto_46\",\"paragraphs\": [{\"context\": \"Nega outras queixas .\", \"qas\": [{\"answers\": [{\"title\":texto_47\",\"paragraphs\": [{\"context\": \"Rsultado de exames : 1 - Microalbuminúria 12 / 04 : 10 . 64 / G de creatinina 2 - US abdome total : rins com alterações tróficas 3 - ECG 19 / 03 / 14 : isquemia subepicárdica anterior , alteração de repolarização ventricular infero - lateral 4 - Laboratoriais 12 / 04 / 14 : K 5 . 1 , clearence creatinina 57 Ao EF : PA 170x100mmHg ( relata PA normal quando em ambiente não hospitalar ) , FC 63bpm AR : mv sem RA ACV : rcr em 2T sem sopros , com hipofonese de bulhas AD : abdome globos , normotenso , indolor , ausência de massas ou visceromegalias MMII sem edema HD : - ICC diastólica classe III - HAS - DMII - Dislipidemia CD : - mantenho medicação - retorno em 6 m com exames laboratoriais + ECG .\", \"qas\": [{\"answers\": [{\"title\":texto_48\",\"paragraphs\": [{\"context\": \"ICC classe III HAS , em uso de atenolol 100mg / dia , AAS , 100mg / dia , furosemida 40mg 1cp 12 / 12h , anlodipino 5mg 1 / 2 cp à noite , losartana 50mg 12 / 12h DMII , metformina 850mg 12 / 12h Dislipidemia , faz uso de sinvastatina 20mg 02 cp à noite .\", \"qas\": [{\"answers\": [{\"title\":texto_49\",\"paragraphs\": [{\"context\": \"POS TX CARDIACO HA 20 dias .\", \"qas\": [{\"answers\": [{\"title\":texto_50\",\"paragraphs\": [{\"context\": \"ULTIMA BIOPSIA AINDA SEM RESULTADO .\", \"qas\": [{\"answers\": [{\"title\":texto_51\",\"paragraphs\": [{\"context\": \"EM USO DE EVEROLIMUS 0 , 75 DE 8 / 8 , AZATIOPRINA 50 / 50 E PREDNISONA 20MG / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_52\",\"paragraphs\": [{\"context\": \"USO DE FURO , AAS , SINVA .\", \"qas\": [{\"answers\": [{\"title\":texto_53\",\"paragraphs\": [{\"context\": \"S # SEM QUEIXAS .\", \"qas\": [{\"answers\": [{\"title\":texto_54\",\"paragraphs\": [{\"context\": \"REFERE QUEIMAÇÃO NAS PERNAS .\", \"qas\": [{\"answers\": [{\"title\":texto_56\",\"paragraphs\": [{\"context\": \"O # PA 120 / 80 , FC 89 .\", \"qas\": [{\"answers\": [{\"title\":texto_58\",\"paragraphs\": [{\"context\": \"CPP LIVRE .\", \"qas\": [{\"answers\": [{\"title\":texto_59\",\"paragraphs\": [{\"context\": \"MMII SEM EDEMA .\", \"qas\": [{\"answers\": [{\"title\":texto_60\",\"paragraphs\": [{\"context\": \"A # POS TX CARDIACO , COM BOA EVOLUÇÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_61\",\"paragraphs\": [{\"context\": \"P # NOVA BIOPSIA , ECO E LAB .\", \"qas\": [{\"answers\": [{\"title\":texto_62\",\"paragraphs\": [{\"context\": \"PROTESE VALVAR MI 2012 .\", \"qas\": [{\"answers\": [{\"title\":texto_63\",\"paragraphs\": [{\"context\": \"USA S MAREVAN ENL 20 12 - 12 ATL 50 12 - 12 ESPIRONOLACTONA 25 MG - D SVT 20 MG - D .\", \"qas\": [{\"answers\": [{\"title\":texto_64\",\"paragraphs\": [{\"context\": \"SEM QX CARDIOLOGICAS .\", \"qas\": [{\"answers\": [{\"title\":texto_65\",\"paragraphs\": [{\"context\": \"27 - 01 - 15 FE 50 EP 25 AE 46 VE REMODELAMENTO CONCENTRICO AE E AD AUMENTADOS VD NL PROTESE AO NF REFLUXO DISCRETO = DUPLA LESAO MI COM ESTENOSE E INSUF MODERADAS - INSUF TRI MODERADA A IMPORTANTE = HIPERTENSAO PULMONAR .\", \"qas\": [{\"answers\": [{\"title\":texto_66\",\"paragraphs\": [{\"context\": \"CONTROLE NO AMB VALVAS E ACO .\", \"qas\": [{\"answers\": [{\"title\":texto_67\",\"paragraphs\": [{\"context\": \"Protese Metalica Aortica em 2004 .\", \"qas\": [{\"answers\": [{\"title\":texto_68\",\"paragraphs\": [{\"context\": \"Uso : Enalapril 10 - 2cp - 12 / 12 / Atenolol 50 - 1cp = 12 / 12 ; Espironolactona 25 - 1xd ; Sinvastatina 20 - 1x noite ; Calcio 500 - 3x d ; Marevan 5 - amb da ACXO ; Trazodona 25 1x d .\", \"qas\": [{\"answers\": [{\"title\":texto_69\",\"paragraphs\": [{\"context\": \"Dispnia esporadica , edema mmii eventual , sem palpitação , dor toracica quando epigastralgia que melhoram com paracetamol .\", \"qas\": [{\"answers\": [{\"title\":texto_70\",\"paragraphs\": [{\"context\": \"Lab ( 21 / 01 / 16 ) : Hbglic 6 , 34 ; TSH 2 , 15 ; Hb 13 , 5 ; VG 42 % leuco 9610 ; plaq 234000 ; Urina I ok ; K 4 , 4 ; Cr 1 , 1 ; Gli 71 ; U 69 ; Tri 67 ; HDL - C 77 ; ColT 160 ; LDL - C 70 ; .\", \"qas\": [{\"answers\": [{\"title\":texto_71\",\"paragraphs\": [{\"context\": \"Ecocardio ( 04 / 12 / 15 ) : AE 42 ; DDVE 39 ; DSVE 23 ; FE 73 % ; VMi area 1 , 65 ; calcificada , refluxo discreto .\", \"qas\": [{\"answers\": [{\"title\":texto_72\",\"paragraphs\": [{\"context\": \"VAo protese metalica com espessamento , e relfuxo discreto .\", \"qas\": [{\"answers\": [{\"title\":texto_75\",\"paragraphs\": [{\"context\": \"VTri = refluxo discreto com PSAP 56mmHg .\", \"qas\": [{\"answers\": [{\"title\":texto_76\",\"paragraphs\": [{\"context\": \"VP refluxo minimo .\", \"qas\": [{\"answers\": [{\"title\":texto_77\",\"paragraphs\": [{\"context\": \"VE hipertrofiado .\", \"qas\": [{\"answers\": [{\"title\":texto_80\",\"paragraphs\": [{\"context\": \"PA ( sentada ) : 140x60mmHg , P 76 .\", \"qas\": [{\"answers\": [{\"title\":texto_82\",\"paragraphs\": [{\"context\": \"MV normodist sem ruidos adsventicios .\", \"qas\": [{\"answers\": [{\"title\":texto_83\",\"paragraphs\": [{\"context\": \"RCR , 2T , BNF ss + + / 6 + FAo e Mi ( + / 6 + .\", \"qas\": [{\"answers\": [{\"title\":texto_84\",\"paragraphs\": [{\"context\": \"BEG , eupneica , acianotica , orientada , Sem edema mmii .\", \"qas\": [{\"answers\": [{\"title\":texto_85\",\"paragraphs\": [{\"context\": \"HD : protese Metalica AOrtoca normofuncionante .\", \"qas\": [{\"answers\": [{\"title\":texto_86\",\"paragraphs\": [{\"context\": \"Disfunbção diastolica .\", \"qas\": [{\"answers\": [{\"title\":texto_87\",\"paragraphs\": [{\"context\": \"CD : Suspendo Espironolactona .\", \"qas\": [{\"answers\": [{\"title\":texto_88\",\"paragraphs\": [{\"context\": \"Reduzo Sinvastatina para 10mg / noite .\", \"qas\": [{\"answers\": [{\"title\":texto_89\",\"paragraphs\": [{\"context\": \"ACrescento Omeprazol 20 - 1x d .\", \"qas\": [{\"answers\": [{\"title\":texto_90\",\"paragraphs\": [{\"context\": \"Retonro em 6m com lab .\", \"qas\": [{\"answers\": [{\"title\":texto_93\",\"paragraphs\": [{\"context\": \"# DÇ DE CHAGAS .\", \"qas\": [{\"answers\": [{\"title\":texto_94\",\"paragraphs\": [{\"context\": \"# BAVT .\", \"qas\": [{\"answers\": [{\"title\":texto_95\",\"paragraphs\": [{\"context\": \"# MARCA - PASSO DUPLACAMARA EM DDD 50 - 60 DESDE 2007 .\", \"qas\": [{\"answers\": [{\"title\":texto_97\",\"paragraphs\": [{\"context\": \"PACIENTE NEGA DISPNEIA , NEGA ORTOPNEIA , NEGA DPN .\", \"qas\": [{\"answers\": [{\"title\":texto_98\",\"paragraphs\": [{\"context\": \"SEM OUTRAS QUEIXAS .\", \"qas\": [{\"answers\": [{\"title\":texto_99\",\"paragraphs\": [{\"context\": \"# NEGA HX DE HAS , DM , DISLIPIDEMIA E TIREOIDOPATIAS .\", \"qas\": [{\"answers\": [{\"title\":texto_101\",\"paragraphs\": [{\"context\": \"# CX DE APENDICITE E HERNIAS PARAMEDIANAS HÁ > 20 ANOS .\", \"qas\": [{\"answers\": [{\"title\":texto_103\",\"paragraphs\": [{\"context\": \"METOPROLOL 50MG 12 / 12HS .\", \"qas\": [{\"answers\": [{\"title\":texto_104\",\"paragraphs\": [{\"context\": \"ENALAPRIL 10 MG 12 / 12HS .\", \"qas\": [{\"answers\": [{\"title\":texto_105\",\"paragraphs\": [{\"context\": \"ESPIRONO 25 .\", \"qas\": [{\"answers\": [{\"title\":texto_106\",\"paragraphs\": [{\"context\": \"SVT 20 .\", \"qas\": [{\"answers\": [{\"title\":texto_107\",\"paragraphs\": [{\"context\": \"EXAMES LAB 11 / 11 : CREAT 1 ; UR 58 ; GLI 71 ; TG 88 ; HDL 52 ; CT 160 ; LDL 90 ; Na 140 ; K 5 , 2 ; Hb 14 , 8 / Ht 46 , 6 / LEUC 5150 .\", \"qas\": [{\"answers\": [{\"title\":texto_108\",\"paragraphs\": [{\"context\": \"EF # BEG , LOTE , CORADO E HIDRATADO .\", \"qas\": [{\"answers\": [{\"title\":texto_109\",\"paragraphs\": [{\"context\": \"PA : 90 / 60MMHG ; P : 72 .\", \"qas\": [{\"answers\": [{\"title\":texto_110\",\"paragraphs\": [{\"context\": \"AUSENCIA DE TURGÊNCIA JUGULAR .\", \"qas\": [{\"answers\": [{\"title\":texto_111\",\"paragraphs\": [{\"context\": \"ICTUS PALPÁVEL EM 7º EIC EM LINHA HEMIAXILAR E .\", \"qas\": [{\"answers\": [{\"title\":texto_112\",\"paragraphs\": [{\"context\": \"BCRNF 2T SS .\", \"qas\": [{\"answers\": [{\"title\":texto_113\",\"paragraphs\": [{\"context\": \"AUSCULTA PULMONAR SEM ALTERAÇÕES .\", \"qas\": [{\"answers\": [{\"title\":texto_114\",\"paragraphs\": [{\"context\": \"ABDOME INOCENTE .\", \"qas\": [{\"answers\": [{\"title\":texto_115\",\"paragraphs\": [{\"context\": \"SEM EDEMA EM MMII .\", \"qas\": [{\"answers\": [{\"title\":texto_117\",\"paragraphs\": [{\"context\": \"A : DÇA CHAGAS .\", \"qas\": [{\"answers\": [{\"title\":texto_118\",\"paragraphs\": [{\"context\": \"P : MANTENHO MEDICAÇÕES .\", \"qas\": [{\"answers\": [{\"title\":texto_119\",\"paragraphs\": [{\"context\": \"SOLICITO ECOCARDIO .\", \"qas\": [{\"answers\": [{\"title\":texto_121\",\"paragraphs\": [{\"context\": \"sem queixas .\", \"qas\": [{\"answers\": [{\"title\":texto_123\",\"paragraphs\": [{\"context\": \"# hoje avaliação exclusiva de mp .\", \"qas\": [{\"answers\": [{\"title\":texto_124\",\"paragraphs\": [{\"context\": \"# mp camara - dupla .\", \"qas\": [{\"answers\": [{\"title\":texto_131\",\"paragraphs\": [{\"context\": \"ABLAÇÃO DE TAQUICARDIA ATRIAL 2009 E A SEGUNDA EM 2010 .\", \"qas\": [{\"answers\": [{\"title\":texto_132\",\"paragraphs\": [{\"context\": \"HAS , NEGA DM , DLPD , TABAGISMO , ALERGIA MEDICAMENTOSA .\", \"qas\": [{\"answers\": [{\"title\":texto_133\",\"paragraphs\": [{\"context\": \"CATETERISMO COM AUSENCIA DE CORONARIOPATIA .\", \"qas\": [{\"answers\": [{\"title\":texto_134\",\"paragraphs\": [{\"context\": \"FAZ USO DE ATENOLOL 100MG 12 / 12H , DILTIAZEN 60MG 12 / 12H , ENALAPRIL 10MG 12 / 12H , HCTZ 25MG , MAREVAN 5MG .\", \"qas\": [{\"answers\": [{\"title\":texto_135\",\"paragraphs\": [{\"context\": \"HOLTER COM PRESENCA DE EV E ESV RARAS COM EPISODIOS NAO SUSTENTADOS DE TAQUICARDIA ATRIAL SEM PRESENCA DE SINTOMAS .\", \"qas\": [{\"answers\": [{\"title\":texto_136\",\"paragraphs\": [{\"context\": \"# PACIENTE REFERE ESTAR SE SENTINDO BEM COM AS MEDICAÇÕES .\", \"qas\": [{\"answers\": [{\"title\":texto_137\",\"paragraphs\": [{\"context\": \"NEGA SINTOMAS DE PALPITAÇÕES .\", \"qas\": [{\"answers\": [{\"title\":texto_138\",\"paragraphs\": [{\"context\": \"RELATA DISPNEIA AOS GRANDES ESFORCOS , COM MELHORA COM REPOUSO .\", \"qas\": [{\"answers\": [{\"title\":texto_139\",\"paragraphs\": [{\"context\": \"RELATA QUE APRESENTOU 1 EPISODIO DE HIPOTENSAO .\", \"qas\": [{\"answers\": [{\"title\":texto_140\",\"paragraphs\": [{\"context\": \"RELATA CEFALEIA .\", \"qas\": [{\"answers\": [{\"title\":texto_141\",\"paragraphs\": [{\"context\": \"# BEG , PA 120 / 80MMHG , FC 70 .\", \"qas\": [{\"answers\": [{\"title\":texto_143\",\"paragraphs\": [{\"context\": \"CORAÇÃO : BRNF 2T , SEM SOPRO .\", \"qas\": [{\"answers\": [{\"title\":texto_144\",\"paragraphs\": [{\"context\": \"PULMAO : MV + , SEM RA .\", \"qas\": [{\"answers\": [{\"title\":texto_145\",\"paragraphs\": [{\"context\": \"CD : MEDICAÇÃO MANTIDA .\", \"qas\": [{\"answers\": [{\"title\":texto_146\",\"paragraphs\": [{\"context\": \"SOLICITO NOVO HOLTER E ECOCARDIO .\", \"qas\": [{\"answers\": [{\"title\":texto_148\",\"paragraphs\": [{\"context\": \"Comorbidades : HAS .\", \"qas\": [{\"answers\": [{\"title\":texto_149\",\"paragraphs\": [{\"context\": \"Medicamentos atenolol 100mg , 12 - 12h , .\", \"qas\": [{\"answers\": [{\"title\":texto_150\",\"paragraphs\": [{\"context\": \"diltiazen 60mg , 12 - 12h , .\", \"qas\": [{\"answers\": [{\"title\":texto_151\",\"paragraphs\": [{\"context\": \"Enalapril 10mg , 12 - 12h , .\", \"qas\": [{\"answers\": [{\"title\":texto_152\",\"paragraphs\": [{\"context\": \"HCTZ 25mg , .\", \"qas\": [{\"answers\": [{\"title\":texto_153\",\"paragraphs\": [{\"context\": \"Marevan 5mg .\", \"qas\": [{\"answers\": [{\"title\":texto_154\",\"paragraphs\": [{\"context\": \"HMA : fez 02 ablações ( 2009 e 2010 ) POR PALPITAÇÕES com taquicardia atrial ; .\", \"qas\": [{\"answers\": [{\"title\":texto_155\",\"paragraphs\": [{\"context\": \"Atualmente sente palpitações quando faz grandes esforços ; dor de cabeça que melhora com analgésico comum .\", \"qas\": [{\"answers\": [{\"title\":texto_156\",\"paragraphs\": [{\"context\": \"Relata que acompanha pressão no posto e normalmente está 120x80 .\", \"qas\": [{\"answers\": [{\"title\":texto_157\",\"paragraphs\": [{\"context\": \"FC : 88 .\", \"qas\": [{\"answers\": [{\"title\":texto_158\",\"paragraphs\": [{\"context\": \"Edema discreto mmi .\", \"qas\": [{\"answers\": [{\"title\":texto_159\",\"paragraphs\": [{\"context\": \"Ausculta pulmonar e cardiaca normais .\", \"qas\": [{\"answers\": [{\"title\":texto_161\",\"paragraphs\": [{\"context\": \"Homoenxerto aortico ( por EAo ) + MIE - DA ; RAD - CD ; SAF - MG em 2006 - Doutor Vital Brazil .\", \"qas\": [{\"answers\": [{\"title\":texto_162\",\"paragraphs\": [{\"context\": \"Hipertenso , .\", \"qas\": [{\"answers\": [{\"title\":texto_163\",\"paragraphs\": [{\"context\": \"Em uso de : AAS 100 mg dia , losartana 100 mg dia , atovastatina 20 mg 4CP / DIA , atenolol 25mg / dia , furosemida 40mg / dia , omeoprazol 40mg ao dia , ezatimibe 10 mg , Hidantal 100mg - por cisticercose .\", \"qas\": [{\"answers\": [{\"title\":texto_164\",\"paragraphs\": [{\"context\": \"Penicilina G benzatina 1 , 200 , 000U IM a cada 21 dia - suspenso em 2013 .\", \"qas\": [{\"answers\": [{\"title\":texto_165\",\"paragraphs\": [{\"context\": \"DOR REGIAO ESTERNAL , EM FO , LOCAL FIOS AÇO , EM QUEIMAÇÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_166\",\"paragraphs\": [{\"context\": \"- Labs : tg 221 / ct 166 / ldl 76 , demais ok .\", \"qas\": [{\"answers\": [{\"title\":texto_167\",\"paragraphs\": [{\"context\": \"- Ecocardio 12 / 08 / 15 : A0 / VD 22 / Septo 11 / FE 66 .\", \"qas\": [{\"answers\": [{\"title\":texto_170\",\"paragraphs\": [{\"context\": \"Regurgitacao grau leve a moderada com jato dirigido valva mitral ( ? ) .\", \"qas\": [{\"answers\": [{\"title\":texto_171\",\"paragraphs\": [{\"context\": \"Exames : .\", \"qas\": [{\"answers\": [{\"title\":texto_172\",\"paragraphs\": [{\"context\": \"Ecocardiograma - 26 / 06 / 2013 : Homoenxerto em posição aórtica normofuncionante .\", \"qas\": [{\"answers\": [{\"title\":texto_173\",\"paragraphs\": [{\"context\": \"VE hipertrofiado com dimensões normais e fumção sistólica preservada .\", \"qas\": [{\"answers\": [{\"title\":texto_174\",\"paragraphs\": [{\"context\": \"ALteração do relaxamento do VE AE dilatado .\", \"qas\": [{\"answers\": [{\"title\":texto_175\",\"paragraphs\": [{\"context\": \"Homoenxerto com mobilidade adequada .\", \"qas\": [{\"answers\": [{\"title\":texto_177\",\"paragraphs\": [{\"context\": \"- Lab ( 05 / 02 / 15 ) : Cr 0 , 91 , CT 174 , TGC 197 , HDL 44 , K 4 , 8 , LDL 90 , Glic 107 .\", \"qas\": [{\"answers\": [{\"title\":texto_178\",\"paragraphs\": [{\"context\": \"Ao exame : .\", \"qas\": [{\"answers\": [{\"title\":texto_180\",\"paragraphs\": [{\"context\": \"FC79 PA : 130 / 80 .\", \"qas\": [{\"answers\": [{\"title\":texto_181\",\"paragraphs\": [{\"context\": \"CP : sem estase jugular .\", \"qas\": [{\"answers\": [{\"title\":texto_182\",\"paragraphs\": [{\"context\": \"AC : BCRNF sem sopros .\", \"qas\": [{\"answers\": [{\"title\":texto_183\",\"paragraphs\": [{\"context\": \"AP : MV presente bilateralmente , sem RA .\", \"qas\": [{\"answers\": [{\"title\":texto_184\",\"paragraphs\": [{\"context\": \"mantenho medicações .\", \"qas\": [{\"answers\": [{\"title\":texto_185\",\"paragraphs\": [{\"context\": \"encaminho para cir cardiaca para retirada pontos suttura esterno .\", \"qas\": [{\"answers\": [{\"title\":texto_188\",\"paragraphs\": [{\"context\": \"USUÁRIA DE MAREVAN DEVIDO ' ARRITMIA ' , NÃO SABE INFORMAR MAIORES DETALHES .\", \"qas\": [{\"answers\": [{\"title\":texto_189\",\"paragraphs\": [{\"context\": \"sEM QUEIXAS .\", \"qas\": [{\"answers\": [{\"title\":texto_190\",\"paragraphs\": [{\"context\": \"SEM RELATO DE SANGRAMENTOS .\", \"qas\": [{\"answers\": [{\"title\":texto_192\",\"paragraphs\": [{\"context\": \"RNI 3 , 40 .\", \"qas\": [{\"answers\": [{\"title\":texto_195\",\"paragraphs\": [{\"context\": \"MANTER AS MEDICAÇÃO DE USO , COM AJUSTE DE COSE .\", \"qas\": [{\"answers\": [{\"title\":texto_198\",\"paragraphs\": [{\"context\": \"# EAo .\", \"qas\": [{\"answers\": [{\"title\":texto_199\",\"paragraphs\": [{\"context\": \"# HAS .\", \"qas\": [{\"answers\": [{\"title\":texto_200\",\"paragraphs\": [{\"context\": \"# Uso : Atenol 50 - 1xd .\", \"qas\": [{\"answers\": [{\"title\":texto_201\",\"paragraphs\": [{\"context\": \"Enalapril 5 - 12 / 12h .\", \"qas\": [{\"answers\": [{\"title\":texto_202\",\"paragraphs\": [{\"context\": \"# Sem queixas cardiovasculares .\", \"qas\": [{\"answers\": [{\"title\":texto_203\",\"paragraphs\": [{\"context\": \"Ecocardio ( 13 / 02 / 15 ) : AE = 45 ; SIV = PPVE = 14mm ; DDVE = 48 ; DSVE = 29 ; FE = 69 % .\", \"qas\": [{\"answers\": [{\"title\":texto_204\",\"paragraphs\": [{\"context\": \"VMi = folhetos espessados , abertura preservada , refluxo discreto , fluxo diastólico com padrão E < A VAo = cúspides calcificadas , com dupla lesão ; Grad max de 54 e medio de 28mmHg .\", \"qas\": [{\"answers\": [{\"title\":texto_205\",\"paragraphs\": [{\"context\": \"VP = ok ; Vtri = folhetos espessados , abertura preservada , insuficiente , PSAP = 39mmHg .\", \"qas\": [{\"answers\": [{\"title\":texto_206\",\"paragraphs\": [{\"context\": \"VE = hipertrofiado , cavidade , função sistólica e contração preservadas , alt de relaxamento .\", \"qas\": [{\"answers\": [{\"title\":texto_207\",\"paragraphs\": [{\"context\": \"AD = aumentado .\", \"qas\": [{\"answers\": [{\"title\":texto_208\",\"paragraphs\": [{\"context\": \"Eco ( 14 / 04 / 16 ) RA : 38 AE : 45 VD : 20 S : 14 PP : 14 VE : 50 / 30 FE : 70 % .\", \"qas\": [{\"answers\": [{\"title\":texto_209\",\"paragraphs\": [{\"context\": \"AO : CUSPIDES CALCIFICADAS , COM DUPLA LESAO .\", \"qas\": [{\"answers\": [{\"title\":texto_211\",\"paragraphs\": [{\"context\": \"INSUF TRICU DISCRETA ( PSAP 39 ) .\", \"qas\": [{\"answers\": [{\"title\":texto_212\",\"paragraphs\": [{\"context\": \"REFLUXO MITRAL DISCRETO .\", \"qas\": [{\"answers\": [{\"title\":texto_213\",\"paragraphs\": [{\"context\": \"AO ASC : 41MM .\", \"qas\": [{\"answers\": [{\"title\":texto_215\",\"paragraphs\": [{\"context\": \"Nega dispneia , dor toracica , sincope .\", \"qas\": [{\"answers\": [{\"title\":texto_216\",\"paragraphs\": [{\"context\": \"Nega edema de MMII .\", \"qas\": [{\"answers\": [{\"title\":texto_217\",\"paragraphs\": [{\"context\": \"Refere controle pressorico bom em casa , porem nas consultas sempre apresenta elevação de PA .\", \"qas\": [{\"answers\": [{\"title\":texto_218\",\"paragraphs\": [{\"context\": \"Sd Jaleco Branco ? ) .\", \"qas\": [{\"answers\": [{\"title\":texto_220\",\"paragraphs\": [{\"context\": \"PA : 170 / 100 mmHg , P = 99 spm .\", \"qas\": [{\"answers\": [{\"title\":texto_221\",\"paragraphs\": [{\"context\": \"MV normodist sem ruidos .\", \"qas\": [{\"answers\": [{\"title\":texto_222\",\"paragraphs\": [{\"context\": \"RCR , 2T , taquicardico , ss + + / 6 + , crsec / decres , FAO , irradiação para todo o precórdio .\", \"qas\": [{\"answers\": [{\"title\":texto_223\",\"paragraphs\": [{\"context\": \"A # DUPLA LESAO AO ESTENOSE MOD + INSUF DISCRETA .\", \"qas\": [{\"answers\": [{\"title\":texto_224\",\"paragraphs\": [{\"context\": \"P # aumento Enalapril 20mg 2x d e inicio HCTZ 25mg / dia .\", \"qas\": [{\"answers\": [{\"title\":texto_225\",\"paragraphs\": [{\"context\": \"retorno em 1 ano com novo eco .\", \"qas\": [{\"answers\": [{\"title\":texto_227\",\"paragraphs\": [{\"context\": \"# MCP dilatada - IDIOPÁTICA .\", \"qas\": [{\"answers\": [{\"title\":texto_228\",\"paragraphs\": [{\"context\": \"CF II - III OSCILANTE .\", \"qas\": [{\"answers\": [{\"title\":texto_229\",\"paragraphs\": [{\"context\": \"** PROTOCOLO DE TX CARDIACO - INDICE CARDIACO .\", \"qas\": [{\"answers\": [{\"title\":texto_230\",\"paragraphs\": [{\"context\": \"*** Em uso de : Omeprazol 20mg / d , AAS 100mg / d , Losartan 50mg 12 / 12hs , Espironolactona 25mg / d , Hidralazina 50mg 12 / 12hs , Carvedilol 12 , 5mg 12 / 12hs .\", \"qas\": [{\"answers\": [{\"title\":texto_231\",\"paragraphs\": [{\"context\": \"S # QUEIXA DE CANSAÇO AOS ESFORÇOS .\", \"qas\": [{\"answers\": [{\"title\":texto_233\",\"paragraphs\": [{\"context\": \"TG 111 , HDL 37 , K 4 , 7 , CT 162 , LDL 103 , TSH 1 , 59 , HB 13 , HB GLICASADA 5 , 87 , NA 145 , TGP 28 , TGO 26 , CREAT 0 , 98 .\", \"qas\": [{\"answers\": [{\"title\":texto_234\",\"paragraphs\": [{\"context\": \"AO EAXME PA 110 / 70 FC 64 .\", \"qas\": [{\"answers\": [{\"title\":texto_235\",\"paragraphs\": [{\"context\": \"SEM TURGÊNCIA JUGULAR .\", \"qas\": [{\"answers\": [{\"title\":texto_236\",\"paragraphs\": [{\"context\": \"CPP - MV + BILATERAL , .\", \"qas\": [{\"answers\": [{\"title\":texto_237\",\"paragraphs\": [{\"context\": \"PC - BCR SEM SOPROS , .\", \"qas\": [{\"answers\": [{\"title\":texto_238\",\"paragraphs\": [{\"context\": \"MMII - SEM EDEM .\", \"qas\": [{\"answers\": [{\"title\":texto_239\",\"paragraphs\": [{\"context\": \"A # MCP dilatada CF II / III .\", \"qas\": [{\"answers\": [{\"title\":texto_240\",\"paragraphs\": [{\"context\": \"P # MEDICAÇÕES MANTIDAS .\", \"qas\": [{\"answers\": [{\"title\":texto_242\",\"paragraphs\": [{\"context\": \"# PO DE TX CARDÍACO ( 23 / 10 / 15 ) - ( IC DILATADA IDIOPÁTICA ) .\", \"qas\": [{\"answers\": [{\"title\":texto_243\",\"paragraphs\": [{\"context\": \"# EM USO DE : CICLOSPORINA 150MG 12 / 12H , MICOFENOLATO 720MG 8 / 8H , PREDNISONA 20MG / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_244\",\"paragraphs\": [{\"context\": \"AAS 100MG / DIA , OMZ 20MG / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_245\",\"paragraphs\": [{\"context\": \"- EXAMES - AVALIAÇÃO PRÉ - TRANSPLANTE : .\", \"qas\": [{\"answers\": [{\"title\":texto_246\",\"paragraphs\": [{\"context\": \"# DOPPLER CAROTIDAS + VERTEBRAIS : CERVICAL D : CAROTIDA : ESTENOSE 20 - 30 % NA BIFURCAÇÃO CAROTÍDEA ; .\", \"qas\": [{\"answers\": [{\"title\":texto_247\",\"paragraphs\": [{\"context\": \"# CATE 16 / 06 / 15 : PRÉ : RVP 2 , 19 / / RVS 24 , PÓS : RVP 2 , 08 / / RVS 12 , 59 .\", \"qas\": [{\"answers\": [{\"title\":texto_248\",\"paragraphs\": [{\"context\": \"# ECOTT 28 / 8 / 15 AE 46 / VD 26 / S / PP 10 / 10 VE 81 / 66 FE 37 % .\", \"qas\": [{\"answers\": [{\"title\":texto_249\",\"paragraphs\": [{\"context\": \"VE DILATADO COM HIPOCONTRATIBILIDADE DIFUSA MODERADA / I AO LEVE / IMI LEVE AMODERADA / PSAP 39 MMHG .\", \"qas\": [{\"answers\": [{\"title\":texto_250\",\"paragraphs\": [{\"context\": \"S # SENTE BEM , DOR NA FO SOMENTE AOS MOVIMENTOS E AO TOSSIR .\", \"qas\": [{\"answers\": [{\"title\":texto_251\",\"paragraphs\": [{\"context\": \"NEGA DISPNÉIA .\", \"qas\": [{\"answers\": [{\"title\":texto_252\",\"paragraphs\": [{\"context\": \"RELATA QUE FO ESTÁ SECA , SEM SINAIS FLOGÍSTICOS .\", \"qas\": [{\"answers\": [{\"title\":texto_253\",\"paragraphs\": [{\"context\": \"NEGA FEBRE .\", \"qas\": [{\"answers\": [{\"title\":texto_254\",\"paragraphs\": [{\"context\": \"O # BEG , HIPOCORADO + / 4 + , EUPNEICO , AFEBRIL .\", \"qas\": [{\"answers\": [{\"title\":texto_255\",\"paragraphs\": [{\"context\": \"PA : 110X70 / / FC : 80 .\", \"qas\": [{\"answers\": [{\"title\":texto_256\",\"paragraphs\": [{\"context\": \"CV : BRNF SS .\", \"qas\": [{\"answers\": [{\"title\":texto_257\",\"paragraphs\": [{\"context\": \"CPP : MV + BILATERAL , SEM RA .\", \"qas\": [{\"answers\": [{\"title\":texto_258\",\"paragraphs\": [{\"context\": \"FO LIMPA E SECA , SEM PRESENÇA DE SECREÇÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_259\",\"paragraphs\": [{\"context\": \"ABD : RHA + , INDOLOR .\", \"qas\": [{\"answers\": [{\"title\":texto_260\",\"paragraphs\": [{\"context\": \"MMII : SEM EDEMA OU EMPASTAMENTO .\", \"qas\": [{\"answers\": [{\"title\":texto_261\",\"paragraphs\": [{\"context\": \"A # PO DE TX CARDIACO ( 23 / 10 / 15 ) .\", \"qas\": [{\"answers\": [{\"title\":texto_263\",\"paragraphs\": [{\"context\": \"POS TX CARDIACO HA 3 ANOS e 7 MESES .\", \"qas\": [{\"answers\": [{\"title\":texto_264\",\"paragraphs\": [{\"context\": \"ULTIMA BIOPSIA .\", \"qas\": [{\"answers\": [{\"title\":texto_265\",\"paragraphs\": [{\"context\": \"EM USO DE CICLOSPORINA 100 / 100 , MYFORTIC 360 / 360 ( REDUZIU PARA ESSA DOSE POR ENGANO ) , E PREDNISONA 5 MG / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_266\",\"paragraphs\": [{\"context\": \"USO DE AAS 100 / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_267\",\"paragraphs\": [{\"context\": \"S # SEM QUEIXAS .\", \"qas\": [{\"answers\": [{\"title\":texto_269\",\"paragraphs\": [{\"context\": \"AGURADA BIOPSIA .\", \"qas\": [{\"answers\": [{\"title\":texto_270\",\"paragraphs\": [{\"context\": \"O # PA 120 / 80 , FC 70 .\", \"qas\": [{\"answers\": [{\"title\":texto_272\",\"paragraphs\": [{\"context\": \"CPP LIVRE .\", \"qas\": [{\"answers\": [{\"title\":texto_273\",\"paragraphs\": [{\"context\": \"MMII SEM EDEMA .\", \"qas\": [{\"answers\": [{\"title\":texto_274\",\"paragraphs\": [{\"context\": \"A # POS TX CARDIACO , COM BOA EVOLUÇÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_276\",\"paragraphs\": [{\"context\": \"P # SOLICITO LAB E ECOCC .\", \"qas\": [{\"answers\": [{\"title\":texto_277\",\"paragraphs\": [{\"context\": \"has / 10 anos / maço .\", \"qas\": [{\"answers\": [{\"title\":texto_278\",\"paragraphs\": [{\"context\": \"aas 100 / carvedilol 25 1x / d / sinva 40 mg 1 x / d / enalapril 1 cp 12 / 12 hs / furo 40 mg 1 x / d .\", \"qas\": [{\"answers\": [{\"title\":texto_279\",\"paragraphs\": [{\"context\": \"fez cat + angioplastia 2013 .\", \"qas\": [{\"answers\": [{\"title\":texto_280\",\"paragraphs\": [{\"context\": \"ECOCARDIO 25 / 11 / 13 - VE HIPERTROFIADO COM DIMENSÃO INTERNA AUMENTADA E FUNÇÃO GLOBAL MODERADAMENTE DIMINUIDA POR ACINESIA MEDIO APICAL PAREDE ANTERO SEPTAL .\", \"qas\": [{\"answers\": [{\"title\":texto_281\",\"paragraphs\": [{\"context\": \"AUMENTO DE AE .\", \"qas\": [{\"answers\": [{\"title\":texto_282\",\"paragraphs\": [{\"context\": \"REFLUXO MITRAL DISCRETO .\", \"qas\": [{\"answers\": [{\"title\":texto_283\",\"paragraphs\": [{\"context\": \"ECTASIA DA RAIZ AÓRTICA .\", \"qas\": [{\"answers\": [{\"title\":texto_284\",\"paragraphs\": [{\"context\": \"REFLUXO AÓRTICO DISCRETO .\", \"qas\": [{\"answers\": [{\"title\":texto_286\",\"paragraphs\": [{\"context\": \"01 / 03 / 11 : ECODOPPLER ARTERIAR MMII ESQ : ESTENOSE APROX DE 75 % DA BIFURCAÇÃO DOS VASOS FEMORAIS .\", \"qas\": [{\"answers\": [{\"title\":texto_287\",\"paragraphs\": [{\"context\": \"LESOES SUBSEGMENTARES DAS ART , TIBIAL ANTERIOR E FIBULAR .\", \"qas\": [{\"answers\": [{\"title\":texto_288\",\"paragraphs\": [{\"context\": \"OCLUSÃO DA ARTERIA POPLITEA MEDIO DISTAL .\", \"qas\": [{\"answers\": [{\"title\":texto_289\",\"paragraphs\": [{\"context\": \"ESTENOSE > A OCLUSAO DA ARTERIA TIBIAL POSTERIOR .\", \"qas\": [{\"answers\": [{\"title\":texto_290\",\"paragraphs\": [{\"context\": \"quadro de disfunção sistólica após iam , perdeu seguimento .\", \"qas\": [{\"answers\": [{\"title\":texto_293\",\"paragraphs\": [{\"context\": \"Em uso de : Diclin ( ACO ) .\", \"qas\": [{\"answers\": [{\"title\":texto_294\",\"paragraphs\": [{\"context\": \"HMA : Pcte relata síncope inicio em janeiro mais com o calor .\", \"qas\": [{\"answers\": [{\"title\":texto_295\",\"paragraphs\": [{\"context\": \"pródromos : tontura e sudorese e escurecimento visual .\", \"qas\": [{\"answers\": [{\"title\":texto_296\",\"paragraphs\": [{\"context\": \"Refere exacerbação dos sintomas com nervosismo .\", \"qas\": [{\"answers\": [{\"title\":texto_298\",\"paragraphs\": [{\"context\": \"Nega confusão mental ou salivação após .\", \"qas\": [{\"answers\": [{\"title\":texto_299\",\"paragraphs\": [{\"context\": \"Nega uso de medicação .\", \"qas\": [{\"answers\": [{\"title\":texto_300\",\"paragraphs\": [{\"context\": \"Nega outros sintomas .\", \"qas\": [{\"answers\": [{\"title\":texto_301\",\"paragraphs\": [{\"context\": \"Refere que continua apresentando sintomas , com ultimo ha 1 semana , durante atividades domesticas .\", \"qas\": [{\"answers\": [{\"title\":texto_302\",\"paragraphs\": [{\"context\": \"Ecocardio 18 / 02 / 15 : RA 20 , AE 26 , VD 17 , Septo 08 , PP 08 , VE 39 , FE 63 % .\", \"qas\": [{\"answers\": [{\"title\":texto_303\",\"paragraphs\": [{\"context\": \"Exame dentro da normalidade .\", \"qas\": [{\"answers\": [{\"title\":texto_304\",\"paragraphs\": [{\"context\": \"Teste ergometrico : Resposta cardiovascular normal ao esforço fisico , atingiu 11 METS .\", \"qas\": [{\"answers\": [{\"title\":texto_305\",\"paragraphs\": [{\"context\": \"ECG : DCRD .\", \"qas\": [{\"answers\": [{\"title\":texto_308\",\"paragraphs\": [{\"context\": \"FC 80 , FR 18 , PA : 120 / 70 , SAT 98 % AA .\", \"qas\": [{\"answers\": [{\"title\":texto_309\",\"paragraphs\": [{\"context\": \"AC bnf em 2t e ss , .\", \"qas\": [{\"answers\": [{\"title\":texto_310\",\"paragraphs\": [{\"context\": \"AP mv + simetrico s ra , .\", \"qas\": [{\"answers\": [{\"title\":texto_311\",\"paragraphs\": [{\"context\": \"Abd sp .\", \"qas\": [{\"answers\": [{\"title\":texto_312\",\"paragraphs\": [{\"context\": \"mmii s edema , .\", \"qas\": [{\"answers\": [{\"title\":texto_313\",\"paragraphs\": [{\"context\": \"Vaso vagal ? .\", \"qas\": [{\"answers\": [{\"title\":texto_314\",\"paragraphs\": [{\"context\": \"A : Aguarda holter .\", \"qas\": [{\"answers\": [{\"title\":texto_315\",\"paragraphs\": [{\"context\": \"Retorno com exames .\", \"qas\": [{\"answers\": [{\"title\":texto_316\",\"paragraphs\": [{\"context\": \"Paciente em acompanhamento com a cardiologia devido a 2 IAM previos ( em 2004 e 2012 ) .\", \"qas\": [{\"answers\": [{\"title\":texto_317\",\"paragraphs\": [{\"context\": \"Em uso de : carvediol 6 , 25 mg , AAS 100 mg , furosemida 40 mg , losartana 100 mg , atorvstatina 20 mg , omeprazol 20 mg .\", \"qas\": [{\"answers\": [{\"title\":texto_318\",\"paragraphs\": [{\"context\": \"Paciente relata dispnéia e cansaço aos minimos esforços .\", \"qas\": [{\"answers\": [{\"title\":texto_319\",\"paragraphs\": [{\"context\": \"Paciente relata parestesias em pé direito , dores musculares na panturrilha .\", \"qas\": [{\"answers\": [{\"title\":texto_320\",\"paragraphs\": [{\"context\": \"Comorbidades : HAS , ICC , dislipidemia .\", \"qas\": [{\"answers\": [{\"title\":texto_321\",\"paragraphs\": [{\"context\": \"Eventos : 2 CATs e 3 angioplastias .\", \"qas\": [{\"answers\": [{\"title\":texto_322\",\"paragraphs\": [{\"context\": \"Na ultima consulta foi trocada sinvastatina por atorvastatina mas o paciente continua em uso de sinvastatina .\", \"qas\": [{\"answers\": [{\"title\":texto_323\",\"paragraphs\": [{\"context\": \"Paciente nao traz exames .\", \"qas\": [{\"answers\": [{\"title\":texto_324\",\"paragraphs\": [{\"context\": \"EF : .\", \"qas\": [{\"answers\": [{\"title\":texto_325\",\"paragraphs\": [{\"context\": \"PA : 120 / 80 mmhg .\", \"qas\": [{\"answers\": [{\"title\":texto_327\",\"paragraphs\": [{\"context\": \"Pulso MMII pedioso poplíteo e femoral presentes .\", \"qas\": [{\"answers\": [{\"title\":texto_328\",\"paragraphs\": [{\"context\": \"Conduta : troco sinvastatina por atorvastatina e solicito exames de sangue ( CT , LDL , HDL , TG ) ; mantenho as demais medicações .\", \"qas\": [{\"answers\": [{\"title\":texto_331\",\"paragraphs\": [{\"context\": \"# HAS .\", \"qas\": [{\"answers\": [{\"title\":texto_332\",\"paragraphs\": [{\"context\": \"# IC .\", \"qas\": [{\"answers\": [{\"title\":texto_333\",\"paragraphs\": [{\"context\": \"# HIPOTIREOIDISMO .\", \"qas\": [{\"answers\": [{\"title\":texto_334\",\"paragraphs\": [{\"context\": \"# MIOCARDIOPATIA DILATADA .\", \"qas\": [{\"answers\": [{\"title\":texto_335\",\"paragraphs\": [{\"context\": \"# IMPLANTE DE RESSINCRONIZADOR / DESFIBRILADOR EM MAIO / 2012 .\", \"qas\": [{\"answers\": [{\"title\":texto_336\",\"paragraphs\": [{\"context\": \"# DEPRESSÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_337\",\"paragraphs\": [{\"context\": \"EM USO : CARVEDILOL 50 MG 2X / D + MONONITRATO DE ISOSSORBITA 20 MG 2X / D + ANCORON ( AMIODARONA ) 200 MG 2X / D + ESPIRONOLACTONA 25 MG / D + FUROSEMIDA 40 MG 2X / D + LOSARTAN 50 MG 2X / D + DIGOXINA 0 , 25 MG / D + SINVASTATINA 40 MG / D + LEVOTIROXINA 50 MCG / D + RIVOTRIL 2 MG / D + CITALOPRAM 20MG 3X / DIA .\", \"qas\": [{\"answers\": [{\"title\":texto_338\",\"paragraphs\": [{\"context\": \"REFERE DOR PRECORDIAL LEVE A MODERADA DO TIPO QUEIMAÇÃO , SEM IRRADIAÇÃO , SEM PIORA AOS ESFORÇOS .\", \"qas\": [{\"answers\": [{\"title\":texto_339\",\"paragraphs\": [{\"context\": \"DISPNEIA , MAL ESTAR E FADIGA AO SUBIR ESCADAS , ANDAR RÁPIDO .\", \"qas\": [{\"answers\": [{\"title\":texto_340\",\"paragraphs\": [{\"context\": \"NEGA ORTOPNEIA E DPN .\", \"qas\": [{\"answers\": [{\"title\":texto_341\",\"paragraphs\": [{\"context\": \"NEGA TOSSE E EDEMA .\", \"qas\": [{\"answers\": [{\"title\":texto_344\",\"paragraphs\": [{\"context\": \"1 CESAREA PRÉVIA , LIPOASPIRAÇÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_345\",\"paragraphs\": [{\"context\": \"NEGA ALERGIAS .\", \"qas\": [{\"answers\": [{\"title\":texto_346\",\"paragraphs\": [{\"context\": \"JÁ REALIZOU 3 CATETERISMOS , CINTILOGRAFIA E EXAMES PARA DOENÇA DE CHAGAS .\", \"qas\": [{\"answers\": [{\"title\":texto_350\",\"paragraphs\": [{\"context\": \"NEGA TABAGISMO , NEGA ETILISMO , NEGA EXERCÍCIO FÍSICO .\", \"qas\": [{\"answers\": [{\"title\":texto_351\",\"paragraphs\": [{\"context\": \"EXAMES : .\", \"qas\": [{\"answers\": [{\"title\":texto_352\",\"paragraphs\": [{\"context\": \"HB 14 , 7 .\", \"qas\": [{\"answers\": [{\"title\":texto_353\",\"paragraphs\": [{\"context\": \"HT 43 , 9 % .\", \"qas\": [{\"answers\": [{\"title\":texto_354\",\"paragraphs\": [{\"context\": \"CREATININA 0 , 8 .\", \"qas\": [{\"answers\": [{\"title\":texto_355\",\"paragraphs\": [{\"context\": \"GLICOSE 87 .\", \"qas\": [{\"answers\": [{\"title\":texto_356\",\"paragraphs\": [{\"context\": \"UREIA 48 48 .\", \"qas\": [{\"answers\": [{\"title\":texto_357\",\"paragraphs\": [{\"context\": \"HDL 28 .\", \"qas\": [{\"answers\": [{\"title\":texto_358\",\"paragraphs\": [{\"context\": \"SODIO 139 .\", \"qas\": [{\"answers\": [{\"title\":texto_359\",\"paragraphs\": [{\"context\": \"POTASSIO 4 , 8 .\", \"qas\": [{\"answers\": [{\"title\":texto_360\",\"paragraphs\": [{\"context\": \"COLESTEROL TOTAL 268 .\", \"qas\": [{\"answers\": [{\"title\":texto_361\",\"paragraphs\": [{\"context\": \"TSH 5 , 87 .\", \"qas\": [{\"answers\": [{\"title\":texto_362\",\"paragraphs\": [{\"context\": \"T4 LIVRE 0 , 86 .\", \"qas\": [{\"answers\": [{\"title\":texto_363\",\"paragraphs\": [{\"context\": \"TRIGLICERIDEOS 626 .\", \"qas\": [{\"answers\": [{\"title\":texto_364\",\"paragraphs\": [{\"context\": \"STRESS FARMACOLOGICO COM DIPIRIDAMOL : ECOCARDIOGRAMA DE STRESS FARMACOLOGICO SEM EVIDENCIA DE ISQUEMIA MIOCÁRDICA .\", \"qas\": [{\"answers\": [{\"title\":texto_365\",\"paragraphs\": [{\"context\": \"CONDUTA : AUMENTO DA DOSE DE LEVOTIROXINA PARA 100 MCG , CIPROFIBRATO 100MG 1X / DIA , FUROSEMIDA SE FALTA DE AR , SINVASTATINA PARA 40MG , HIDRALAZINA 25MG DE 8 / 8H .\", \"qas\": [{\"answers\": [{\"title\":texto_366\",\"paragraphs\": [{\"context\": \"EXAMES DE TSH , T4 LIVRE , CK , TGO E TGP E PERFIL LIPIDICO .\", \"qas\": [{\"answers\": [{\"title\":texto_368\",\"paragraphs\": [{\"context\": \"# HAS HÁ 10 ANOS .\", \"qas\": [{\"answers\": [{\"title\":texto_369\",\"paragraphs\": [{\"context\": \"# DSLP .\", \"qas\": [{\"answers\": [{\"title\":texto_370\",\"paragraphs\": [{\"context\": \"# HIPOTIREOIDISMO .\", \"qas\": [{\"answers\": [{\"title\":texto_371\",\"paragraphs\": [{\"context\": \"# DEPRESSÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_372\",\"paragraphs\": [{\"context\": \"# OSTEOARTRITE DE MÃOS .\", \"qas\": [{\"answers\": [{\"title\":texto_373\",\"paragraphs\": [{\"context\": \"# CAT EM JUNHO / 2011 : SEM INDICAÇÃO CIRÚRGICA .\", \"qas\": [{\"answers\": [{\"title\":texto_374\",\"paragraphs\": [{\"context\": \"# HÉRNIA DE DISCO HÁ 3 ANOS .\", \"qas\": [{\"answers\": [{\"title\":texto_375\",\"paragraphs\": [{\"context\": \"# CINTILOGRAFIA MIOCÁRDICA COM DIPIRIDAMOL EM 2011 : HIPOCAPTAÇÃO APICAL , DO SEGMENTO ANTERIOR ( TRANSITÓRIO ) E BASAL DO SEGMENTO ANTERO - SEPTAL .\", \"qas\": [{\"answers\": [{\"title\":texto_376\",\"paragraphs\": [{\"context\": \"# EM USO : FLUOXETINA 20MG / D ; ENALAPRIL 10MG 12 / 12H ; AAS 100MG / D ; CARVEDILOL 12 , 5MG 12 / 12H ; HCTZ 25MG / D ; SUSTRATE 10MG SN ; SINVASTATINA 40MG / D ; LEVOTIROXINA 25UCG / D ; HIDROXICLOROQUINA 400MG / D ; .\", \"qas\": [{\"answers\": [{\"title\":texto_377\",\"paragraphs\": [{\"context\": \"LAB 08 / 04 / 15 : TG 144 / HDL 50 / CT 178 / LDL 99 / .\", \"qas\": [{\"answers\": [{\"title\":texto_378\",\"paragraphs\": [{\"context\": \"S # REFERE DOR TORÁCICA PRECORDIAL TIPO QUEIMAÇÃO , COM MELHORA AO USO DE NITRATO , SEM IRRADIAÇÃO , SEM RELAÇÃO COM O ESFORÇO , 2 EPISÓDIOS AO MÊS .\", \"qas\": [{\"answers\": [{\"title\":texto_379\",\"paragraphs\": [{\"context\": \"NEGA DISPNÉIA , ORTOPNEIA OU DPN .\", \"qas\": [{\"answers\": [{\"title\":texto_380\",\"paragraphs\": [{\"context\": \"NEGA EDEMA DE MMII .\", \"qas\": [{\"answers\": [{\"title\":texto_381\",\"paragraphs\": [{\"context\": \"CONTA APRESENTAR ARTRALGIAS DIFUSAS PIORES AO FRIO .\", \"qas\": [{\"answers\": [{\"title\":texto_384\",\"paragraphs\": [{\"context\": \"PA 120 / 70 ; FC 62 ; SATO2 98 % EM AA .\", \"qas\": [{\"answers\": [{\"title\":texto_385\",\"paragraphs\": [{\"context\": \"MV PRESENTE E SIMÉTRICO SEM RA .\", \"qas\": [{\"answers\": [{\"title\":texto_386\",\"paragraphs\": [{\"context\": \"BCRNF SEM SOPROS EM 2T .\", \"qas\": [{\"answers\": [{\"title\":texto_387\",\"paragraphs\": [{\"context\": \"ABDOME GLOBOSO , FLÁCIDO , INDOLOR , SEM VCM OU MASSAS PALPAVEIS .\", \"qas\": [{\"answers\": [{\"title\":texto_388\",\"paragraphs\": [{\"context\": \"MMII SEM EDEMA OU EMPASTAMENTO .\", \"qas\": [{\"answers\": [{\"title\":texto_390\",\"paragraphs\": [{\"context\": \"- ANGINA INSTÁVEL ? .\", \"qas\": [{\"answers\": [{\"title\":texto_392\",\"paragraphs\": [{\"context\": \"- ACRESCENTO MONOCORDIL 20MG 12 / 12H .\", \"qas\": [{\"answers\": [{\"title\":texto_393\",\"paragraphs\": [{\"context\": \"- SOLICITO NOVA CINTILOGRAFIA DE PERFUSÃO MIOCÁRDICA .\", \"qas\": [{\"answers\": [{\"title\":texto_394\",\"paragraphs\": [{\"context\": \"- SOLICITO NOVO LAB .\", \"qas\": [{\"answers\": [{\"title\":texto_395\",\"paragraphs\": [{\"context\": \"- RETORNO COM EXAMES .\", \"qas\": [{\"answers\": [{\"title\":texto_399\",\"paragraphs\": [{\"context\": \"ACOMPANHANDO COM Doutor Vital Brazil SEM SINCOPE , SEM PALPITAÇÃO , SEM TERAPIAS .\", \"qas\": [{\"answers\": [{\"title\":texto_401\",\"paragraphs\": [{\"context\": \"# hoje realizou avaliação de mp - cdi , .\", \"qas\": [{\"answers\": [{\"title\":texto_402\",\"paragraphs\": [{\"context\": \"# sem registro de arritmias - terapias , .\", \"qas\": [{\"answers\": [{\"title\":texto_404\",\"paragraphs\": [{\"context\": \"# eletrodos atrial e ventricular = ok .\", \"qas\": [{\"answers\": [{\"title\":texto_407\",\"paragraphs\": [{\"context\": \"# CAT EM 2008 .\", \"qas\": [{\"answers\": [{\"title\":texto_408\",\"paragraphs\": [{\"context\": \"VALVOPLASTIA AÓRTICA EM 2008 .\", \"qas\": [{\"answers\": [{\"title\":texto_409\",\"paragraphs\": [{\"context\": \"VALVA BIOLÓGICA - 40 DIAS DEPOIS DA CX CARDIOVERSÃO .\", \"qas\": [{\"answers\": [{\"title\":texto_410\",\"paragraphs\": [{\"context\": \"# PACIENTE ASSINTOMÁTICO HÁ BASTANTE TEMPO ( APROX 1 ANO ) , A CAMINHO DO TRABALHO NO DIA 16 / 08 COMEÇOU A SENTIR TONTURA .\", \"qas\": [{\"answers\": [{\"title\":texto_412\",\"paragraphs\": [{\"context\": \"HOJE PACIENTE ESTÁ ASSINTOMÁTICO , NEGA QUEIXAS , VOLTOU AS ATIVIDADES NORMAIS ( FRENTISTA ) .\", \"qas\": [{\"answers\": [{\"title\":texto_413\",\"paragraphs\": [{\"context\": \"RELATA EMAGRECIMENTO DE 7 KG EM 10 DIAS .\", \"qas\": [{\"answers\": [{\"title\":texto_414\",\"paragraphs\": [{\"context\": \"# EX - TABAGISTA 40 MAÇOS - ANO - EM ABSTINÊNCIA HÁ 7 ANOS .\", \"qas\": [{\"answers\": [{\"title\":texto_415\",\"paragraphs\": [{\"context\": \"# EM USO DE : ENALAPRIL 10MG 2X / DIA , CARVEDILOL 12 , 5 MG 2X / DIA , ATORVASTATINA 40 MG , CLOPIDOGREL E MAREVAN .\", \"qas\": [{\"answers\": [{\"title\":texto_416\",\"paragraphs\": [{\"context\": \"# EXAME FÍSICO : .\", \"qas\": [{\"answers\": [{\"title\":texto_418\",\"paragraphs\": [{\"context\": \"FC 80 BPM , PA 120 / 80 MMHG .\", \"qas\": [{\"answers\": [{\"title\":texto_419\",\"paragraphs\": [{\"context\": \"BCRNF - HIPOFONESE DE BULHAS EM FOCO AÓRTICO .\", \"qas\": [{\"answers\": [{\"title\":texto_420\",\"paragraphs\": [{\"context\": \"MV + SIM BILATERAL , S / RA .\", \"qas\": [{\"answers\": [{\"title\":texto_421\",\"paragraphs\": [{\"context\": \"RHA + , ABDOME NÃO DOLOROSO A PALPAÇÃO , SEM VISCEROMEGALIAS .\", \"qas\": [{\"answers\": [{\"title\":texto_422\",\"paragraphs\": [{\"context\": \"HERNIA UMBILICAL REDUTÍVEL .\", \"qas\": [{\"answers\": [{\"title\":texto_423\",\"paragraphs\": [{\"context\": \"MMII EDEMA + / 4 + , PANTURRILHAS LIVRES .\", \"qas\": [{\"answers\": [{\"title\":texto_424\",\"paragraphs\": [{\"context\": \"# ECG 19 / 08 : FLUTTER ATRIAL PROVAVELMENTE ANTI - HORÁRIO 2 / 3 : 1 , EXTRASSÍSTOLES VENTRICULARES .\", \"qas\": [{\"answers\": [{\"title\":texto_425\",\"paragraphs\": [{\"context\": \"# CD : CONTROLE DO TAP .\", \"qas\": [{\"answers\": [{\"title\":texto_426\",\"paragraphs\": [{\"context\": \"PRECISA DE 4 TAP ENTRE 2 E 3 .\", \"qas\": [{\"answers\": [{\"title\":texto_430\",\"paragraphs\": [{\"context\": \"# sem intercorrencias , .\", \"qas\": [{\"answers\": [{\"title\":texto_431\",\"paragraphs\": [{\"context\": \"# hoje avaliação exclusiva de mp .\", \"qas\": [{\"answers\": [{\"title\":texto_432\",\"paragraphs\": [{\"context\": \"# mp camara - dupla , .\", \"qas\": [{\"answers\": [{\"title\":texto_442\",\"paragraphs\": [{\"context\": \"# DAC - IAM 2007 + RVM / / ATC 2010 , .\", \"qas\": [{\"answers\": [{\"title\":texto_443\",\"paragraphs\": [{\"context\": \"# Hipertireoidismo ? ? - em acompanhamento com endocrinologia , .\", \"qas\": [{\"answers\": [{\"title\":texto_444\",\"paragraphs\": [{\"context\": \"# FA paroxistica , .\", \"qas\": [{\"answers\": [{\"title\":texto_445\",\"paragraphs\": [{\"context\": \"# Internamento em jan / 15 por taquicardia atrial com aberrância - - DESCARTADO ISQUEMIA MIOCÁRDICA COMO CAUSA , PROVÁVEL FATOR DESCOMPENSADOR SERIA O HIPERTIREOIDISMO QUE AINDA APRESENTA - SE DESCOMPENSADO ( TSH < 0 , 01 ) .\", \"qas\": [{\"answers\": [{\"title\":texto_446\",\"paragraphs\": [{\"context\": \"Medicamentos : tapazol 10 mg , enalapril 10 mg 12 / 12h , selozok 50 mg , sinvastatina 40 mg , xarelto 20 mg , AAS100mg .\", \"qas\": [{\"answers\": [{\"title\":texto_447\",\"paragraphs\": [{\"context\": \"S # Nega palpitações , dispneia , dor torácica .\", \"qas\": [{\"answers\": [{\"title\":texto_448\",\"paragraphs\": [{\"context\": \"Epigastralgia .\", \"qas\": [{\"answers\": [{\"title\":texto_450\",\"paragraphs\": [{\"context\": \"Traz exames : .\", \"qas\": [{\"answers\": [{\"title\":texto_451\",\"paragraphs\": [{\"context\": \"- Holter 28 / 04 / 15 : ritmo sinusal , FC media 53 , Intervalo PR normal , QRS normais , extra - sistole ventricular unica , extra - sistole supra - ventricular rara , ausencia de pausas , ST sem alterações .\", \"qas\": [{\"answers\": [{\"title\":texto_452\",\"paragraphs\": [{\"context\": \"- TSH 47 / t4l 0 , 55 .\", \"qas\": [{\"answers\": [{\"title\":texto_453\",\"paragraphs\": [{\"context\": \"- Ecocardiograma out / 14 ( externo ) : AE 43 / VD 23 / septo 10 / VE 52 - 26 / FE 81 % .\", \"qas\": [{\"answers\": [{\"title\":texto_454\",\"paragraphs\": [{\"context\": \"VE com contração segmentar e função sistólica adequadas .\", \"qas\": [{\"answers\": [{\"title\":texto_455\",\"paragraphs\": [{\"context\": \"Ao exame : .\", \"qas\": [{\"answers\": [{\"title\":texto_456\",\"paragraphs\": [{\"context\": \"PA130 / 70 , FC 55 .\", \"qas\": [{\"answers\": [{\"title\":texto_457\",\"paragraphs\": [{\"context\": \"CV : BRNF , sem sopros .\", \"qas\": [{\"answers\": [{\"title\":texto_458\",\"paragraphs\": [{\"context\": \"CPP livres .\", \"qas\": [{\"answers\": [{\"title\":texto_459\",\"paragraphs\": [{\"context\": \"A # FA paroxística .\", \"qas\": [{\"answers\": [{\"title\":texto_461\",\"paragraphs\": [{\"context\": \"P # Retorno precoce na endocrino para ajuste medicação .\", \"qas\": [{\"answers\": [{\"title\":texto_462\",\"paragraphs\": [{\"context\": \"Suspendemos selozok .\", \"qas\": [{\"answers\": [{\"title\":texto_463\",\"paragraphs\": [{\"context\": \"prescrevemos propafenona 300mg 12 / 12h .\", \"qas\": [{\"answers\": [{\"title\":texto_464\",\"paragraphs\": [{\"context\": \"Retorno com ecocardio em 3 meses .\", \"qas\": [{\"answers\": [{\"title\":texto_465\",\"paragraphs\": [{\"context\": \"Demais medicações mantidas .\", \"qas\": [{\"answers\": [{\"title\":texto_469\",\"paragraphs\": [{\"context\": \"# IAM 2009 - ATC .\", \"qas\": [{\"answers\": [{\"title\":texto_470\",\"paragraphs\": [{\"context\": \"# CA de Laringe , fez QT e RT - TERMINO TTO 2002 , .\", \"qas\": [{\"answers\": [{\"title\":texto_471\",\"paragraphs\": [{\"context\": \"# HAS , .\", \"qas\": [{\"answers\": [{\"title\":texto_472\",\"paragraphs\": [{\"context\": \"# HPB , .\", \"qas\": [{\"answers\": [{\"title\":texto_473\",\"paragraphs\": [{\"context\": \"# DLP , .\", \"qas\": [{\"answers\": [{\"title\":texto_474\",\"paragraphs\": [{\"context\": \"# ARTRITE REUMATÓIDE .\", \"qas\": [{\"answers\": [{\"title\":texto_476\",\"paragraphs\": [{\"context\": \"- Enalapril 20 mg , 2 cp de 12 / 12 hr .\", \"qas\": [{\"answers\": [{\"title\":texto_477\",\"paragraphs\": [{\"context\": \"- CARVEDILOL 12 , 5MG , 1 cp de 12 / 12 hr , .\", \"qas\": [{\"answers\": [{\"title\":texto_478\",\"paragraphs\": [{\"context\": \"- AAS 100 mg , 1 / dia ; .\", \"qas\": [{\"answers\": [{\"title\":texto_479\",\"paragraphs\": [{\"context\": \"- Sinvastatina 20mg , 4 cp de noite ; .\", \"qas\": [{\"answers\": [{\"title\":texto_480\",\"paragraphs\": [{\"context\": \"- Omeprazol 20m mg , 2 cp de 12 / 12hr ; .\", \"qas\": [{\"answers\": [{\"title\":texto_481\",\"paragraphs\": [{\"context\": \"- PREDNISONA 5 MG ; .\", \"qas\": [{\"answers\": [{\"title\":texto_482\",\"paragraphs\": [{\"context\": \"- COMBODART .\", \"qas\": [{\"answers\": [{\"title\":texto_483\",\"paragraphs\": [{\"context\": \"***Teste de esforço 10 / 2013 : eficaz , submáximo , sem alterações .\", \"qas\": [{\"answers\": [{\"title\":texto_484\",\"paragraphs\": [{\"context\": \"Clínicas ou eletrocardiográficas de iesquemia miocardica .\", \"qas\": [{\"answers\": [{\"title\":texto_487\",\"paragraphs\": [{\"context\": \"Decréscimo normal da FC no 1° minuto de recuperação .\", \"qas\": [{\"answers\": [{\"title\":texto_488\",\"paragraphs\": [{\"context\": \"*** ECOCARDIO 11 / 06 / 2014 : VE COM DIMENSÃO INTERNA , CONTRATILIDADE MIOCARDICA E FUNÇÃO SISTOLICA GLOBAL NORMAIS , DISFUNÇÃO DIASTOLICA TIPO ALTERAÇÃO DE RELAXAMENTO , AE E CAVIDADES DIREITAS NORMAIS , .\", \"qas\": [{\"answers\": [{\"title\":texto_489\",\"paragraphs\": [{\"context\": \"FLUXOS VALVARES SEM ANORMALIDADES MORFOFUNCIONAIS SIGNIFICATIVAS .\", \"qas\": [{\"answers\": [{\"title\":texto_490\",\"paragraphs\": [{\"context\": \"AE 31 , VDC 21 , DDDV 44 , DSVE 30 , FE 60 .\", \"qas\": [{\"answers\": [{\"title\":texto_491\",\"paragraphs\": [{\"context\": \"S # SEM QUEIXAS .\", \"qas\": [{\"answers\": [{\"title\":texto_492\",\"paragraphs\": [{\"context\": \"NEGA DISPNEIA E DOR NO PEITO .\", \"qas\": [{\"answers\": [{\"title\":texto_496\",\"paragraphs\": [{\"context\": \"PA 120 / 80 , FC 80 ; .\", \"qas\": [{\"answers\": [{\"title\":texto_498\",\"paragraphs\": [{\"context\": \"AP : MV + BILAT , SEM RA ; .\", \"qas\": [{\"answers\": [{\"title\":texto_499\",\"paragraphs\": [{\"context\": \"ABD : SP ; .\", \"qas\": [{\"answers\": [{\"title\":texto_500\",\"paragraphs\": [{\"context\": \"MMII : SP ; .\", \"qas\": [{\"answers\": [{\"title\":texto_501\",\"paragraphs\": [{\"context\": \"A # DAC .\", \"qas\": [{\"answers\": [{\"title\":texto_503\",\"paragraphs\": [{\"context\": \"EX DE CONTROLE .\", \"qas\": [{\"answers\": [\n"
     ]
    }
   ],
   "source": [
    "tipos= ['Problema','Teste','Tratamento','Anatomia']\n",
    "\n",
    "texto='{\"data\": ['\n",
    "# title\n",
    "# paragraphs\n",
    "    #context, qas (answers (answer_start_original, text_original)), question (id, question_original)\n",
    "for i in range(len(dic_sentencesTest)):\n",
    "    ents = dic_sentencesTest[i][1]\n",
    "    \n",
    "    listaEntidadesProblema=list()\n",
    "    listaEntidadesTeste=list()\n",
    "    listaEntidadesTratamento=list()\n",
    "    listaEntidadesAnatomia=list()\n",
    "            \n",
    "\n",
    "    #print(contexto)\n",
    "    for entidade in ents:\n",
    "        if entidade[2] == 'Problema':\n",
    "            listaEntidadesProblema.append(entidade)\n",
    "        elif entidade[2] == 'Teste':\n",
    "            listaEntidadesTeste.append(entidade)\n",
    "        elif entidade[2] == 'Tratamento':\n",
    "            listaEntidadesTratamento.append(entidade)\n",
    "        elif entidade[2] == 'Anatomia':\n",
    "            listaEntidadesAnatomia.append(entidade)\n",
    "            \n",
    "    if len(listaEntidadesProblema)==0 and len(listaEntidadesTeste)==0 and len(listaEntidadesTratamento)==0 and len(listaEntidadesAnatomia)==0:\n",
    "        continue\n",
    "        \n",
    "    title='texto_'+str(i)\n",
    "    texto = texto+'{\"title\":'+title+'\",\"paragraphs\": [{\"context\": \"'\n",
    "    \n",
    "    tokens = dic_sentencesTest[i][0]\n",
    "    frase=[t[0] for t in tokens]\n",
    "    contexto = ' '.join(frase)\n",
    "    texto = texto+contexto+'\", \"qas\": [{\"answers\": ['\n",
    "    \n",
    "\n",
    "    if len(listaEntidadesProblema)>0:\n",
    "        for entidade in listaEntidadesProblema:\n",
    "            texto = texto+'{\"answer_start\":'\n",
    "            indices = entidade[1]\n",
    "            start =indices[0]\n",
    "            fim = indices[-1]\n",
    "            start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "            fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "            fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "            texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "        texto = texto+' \"question\": \"Problema\"},'\n",
    "        \n",
    "    if len(listaEntidadesTeste)>0:\n",
    "\n",
    "        texto = texto+'{\"answers\": ['\n",
    "        for entidade in listaEntidadesTeste:\n",
    "            texto = texto+'{\"answer_start\":'\n",
    "            indices = entidade[1]\n",
    "            start =indices[0]\n",
    "            fim = indices[-1]\n",
    "            try:\n",
    "                start_string = [j[2] for j in dic_sentencesTest[i][0] if j[1]==start][0]\n",
    "            except:\n",
    "                print()\n",
    "                raise\n",
    "            fim_string = [j[2] for j in dic_sentencesTest[i][0] if j[1]==fim][0]\n",
    "            fim_string = fim_string+[len(j[0]) for j in dic_sentencesTest[i][0] if j[1]==fim][0]\n",
    "\n",
    "            texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "        texto = texto+' \"question\": \"Teste\"},'\n",
    "        \n",
    "    if len(listaEntidadesTratamento)>0:\n",
    "\n",
    "        texto = texto+'{\"answers\": ['\n",
    "        for entidade in listaEntidadesTratamento:\n",
    "            texto = texto+'{\"answer_start\":'\n",
    "            indices = entidade[1]\n",
    "            start =indices[0]\n",
    "            fim = indices[-1]\n",
    "            start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "            fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "            fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "            texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "        texto = texto+' \"question\": \"Tratamento\"},'\n",
    "     \n",
    "    if len(listaEntidadesAnatomia)>0:\n",
    "\n",
    "        texto = texto+'{\"answers\": ['\n",
    "        for entidade in listaEntidadesAnatomia:\n",
    "            texto = texto+'{\"answer_start\":'\n",
    "            indices = entidade[1]\n",
    "            start =indices[0]\n",
    "            fim = indices[-1]\n",
    "            start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "            fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "            fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "            texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "        texto = texto+' \"question\": \"Anatomia\"},'\n",
    "print(texto)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravando em  data-ner\n",
      "num_entidade_train 13801\n",
      "num_entidade_dev 4009\n",
      "num_entidade_test: 5453\n",
      "num_entidade_total: 23263\n"
     ]
    }
   ],
   "source": [
    "# gerar arquivo treinamento\n",
    "path='data-qa'\n",
    "f_train = open(path+r'\\qa_nested_train.json', 'w', encoding='utf-8')\n",
    "print('Gravando em ', path)\n",
    "num_entidade_total=0\n",
    "num_entidade_train=0\n",
    "num_entidade_dev=0\n",
    "num_entidade_test=0\n",
    "\n",
    "\n",
    "for i in range(len(dic_sentencesTrain)):\n",
    "    tokens = dic_sentencesTrain[i][0]\n",
    "    ents = dic_sentencesTrain[i][1]\n",
    "    indiceEnts=[]\n",
    "    for token in tokens:\n",
    "        #print('token:', token)\n",
    "        indiceToken = token[1]\n",
    "        tag='O'\n",
    "        for ent in ents:\n",
    "            if indiceToken in ent[1]:\n",
    "                tag = ent[2]\n",
    "                break\n",
    "        tokenGravar = token[0].replace(' ','')\n",
    "        tokenGravar = tokenGravar.strip()\n",
    "        f_train.write(tokenGravar+' '+tag+'\\n')\n",
    "        num_entidade_train=num_entidade_train+1\n",
    "    f_train.write('\\n')\n",
    "        \n",
    "f_train.close()\n",
    "\n",
    "f_dev = open(path+r'\\nested_dev.conll', 'w', encoding='utf-8')\n",
    "for i in range(len(dic_sentencesDev)):\n",
    "    tokens = dic_sentencesDev[i][0]\n",
    "    ents = dic_sentencesDev[i][1]\n",
    "    indiceEnts=[]\n",
    "    for token in tokens:\n",
    "        #print('token:', token)\n",
    "        indiceToken = token[1]\n",
    "        tag='O'\n",
    "        for ent in ents:\n",
    "            if indiceToken in ent[1]:\n",
    "                tag = ent[2]\n",
    "                break\n",
    "        tokenGravar = token[0].replace(' ','')\n",
    "        tokenGravar = tokenGravar.strip()\n",
    "        f_dev.write(tokenGravar+' '+tag+'\\n')\n",
    "        num_entidade_dev=num_entidade_dev+1\n",
    "    f_dev.write('\\n')\n",
    "f_dev.close()\n",
    "\n",
    "\n",
    "f_test = open(path+r'\\qa_nested_test.json', 'w', encoding='utf-8')\n",
    "for i in range(len(dic_sentencesTest)):\n",
    "    tokens = dic_sentencesTest[i][0]\n",
    "    ents = dic_sentencesTest[i][1]\n",
    "    indiceEnts=[]\n",
    "    for token in tokens:\n",
    "        #print('token:', token)\n",
    "        indiceToken = token[1]\n",
    "        tag='O'\n",
    "        for ent in ents:\n",
    "            if indiceToken in ent[1]:\n",
    "                tag = ent[2]\n",
    "                break\n",
    "        tokenGravar = token[0].replace(' ','')\n",
    "        tokenGravar = tokenGravar.strip()\n",
    "        f_test.write(tokenGravar+' '+tag+'\\n')\n",
    "        num_entidade_test=num_entidade_test+1\n",
    "    f_test.write('\\n')\n",
    "f_test.close()\n",
    "\n",
    "print('num_entidade_train', num_entidade_train)\n",
    "print('num_entidade_dev', num_entidade_dev)\n",
    "print('num_entidade_test:', num_entidade_test)\n",
    "num_entidade_total=num_entidade_train+num_entidade_dev+num_entidade_test\n",
    "print('num_entidade_total:', num_entidade_total)\n",
    "\n",
    "#save_obj('dic_sentencesTrain',dic_sentencesTrain)\n",
    "#save_obj('dic_sentencesDev',dic_sentencesDev)\n",
    "#save_obj('dic_sentencesTest',dic_sentencesTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Dispneia', 0, 43],\n",
       "  ['importante', 1, 52],\n",
       "  ['aos', 2, 63],\n",
       "  ['esforços', 3, 67],\n",
       "  ['+', 4, 76],\n",
       "  ['dor', 5, 78],\n",
       "  ['tipo', 6, 82],\n",
       "  ['peso', 7, 87],\n",
       "  ['no', 8, 92],\n",
       "  ['peito', 9, 95],\n",
       "  ['no', 10, 101],\n",
       "  ['esforço', 11, 104],\n",
       "  ['.', 12, 111]],\n",
       " [['Dispneia importante aos esforços', [0, 1, 2, 3], 'Problema'],\n",
       "  ['dor tipo peso no peito no esforço', [5, 6, 7, 8, 9, 10, 11], 'Problema'],\n",
       "  ['peito', [9], 'Anatomia']]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravarArquivosBinarios(entidade, dic_sentences, tipo):\n",
    "    # gerar arquivo treinamento\n",
    "    f_entidade = open(r'binarios/nested_'+tipo+'_'+entidade+'.conll', 'w', encoding='utf-8')\n",
    "\n",
    "    num_entidade_total=0\n",
    "    num_entidade=0\n",
    "\n",
    "    # TODO - refazer.. qdo vem entidade isolada, nao está gravando...\n",
    "    print('\\nGravando arquivo de {} para entidade {}'.format(tipo, entidade))\n",
    "\n",
    "    for i in range(len(dic_sentences)):\n",
    "        tokens = dic_sentences[i][0]\n",
    "        ents = dic_sentences[i][1]\n",
    "        indiceEnts=[]\n",
    "        for token in tokens:\n",
    "            #print('token:', token)\n",
    "            indiceToken = token[1]\n",
    "            tag='O'\n",
    "            for ent in ents:\n",
    "                if indiceToken in ent[1] and ent[2]==entidade:\n",
    "                    tag = ent[2]\n",
    "                    num_entidade=num_entidade+1\n",
    "                    break\n",
    "            if tag != entidade:\n",
    "                tag='O'\n",
    "            tokenGravar = token[0].replace(' ','')\n",
    "            tokenGravar = tokenGravar.strip()\n",
    "            f_entidade.write(tokenGravar+' '+tag+'\\n')\n",
    "            num_entidade_total=num_entidade_total+1\n",
    "        f_entidade.write('\\n')\n",
    "\n",
    "    f_entidade.close()\n",
    "\n",
    "    print('num_entidade:', num_entidade)\n",
    "    print('num_entidade_total:', num_entidade_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gravando arquivo de train para entidade Problema\n",
      "num_entidade: 2297\n",
      "num_entidade_total: 13801\n",
      "\n",
      "Gravando arquivo de dev para entidade Problema\n",
      "num_entidade: 538\n",
      "num_entidade_total: 4009\n",
      "\n",
      "Gravando arquivo de test para entidade Problema\n",
      "num_entidade: 795\n",
      "num_entidade_total: 5453\n",
      "\n",
      "Gravando arquivo de train para entidade Teste\n",
      "num_entidade: 754\n",
      "num_entidade_total: 13801\n",
      "\n",
      "Gravando arquivo de dev para entidade Teste\n",
      "num_entidade: 172\n",
      "num_entidade_total: 4009\n",
      "\n",
      "Gravando arquivo de test para entidade Teste\n",
      "num_entidade: 308\n",
      "num_entidade_total: 5453\n",
      "\n",
      "Gravando arquivo de train para entidade Tratamento\n",
      "num_entidade: 1191\n",
      "num_entidade_total: 13801\n",
      "\n",
      "Gravando arquivo de dev para entidade Tratamento\n",
      "num_entidade: 377\n",
      "num_entidade_total: 4009\n",
      "\n",
      "Gravando arquivo de test para entidade Tratamento\n",
      "num_entidade: 450\n",
      "num_entidade_total: 5453\n",
      "\n",
      "Gravando arquivo de train para entidade Anatomia\n",
      "num_entidade: 582\n",
      "num_entidade_total: 13801\n",
      "\n",
      "Gravando arquivo de dev para entidade Anatomia\n",
      "num_entidade: 139\n",
      "num_entidade_total: 4009\n",
      "\n",
      "Gravando arquivo de test para entidade Anatomia\n",
      "num_entidade: 250\n",
      "num_entidade_total: 5453\n"
     ]
    }
   ],
   "source": [
    "entidades = ['Problema','Teste','Tratamento','Anatomia']\n",
    "#entidades = ['Anatomia']\n",
    "for entidade in entidades:\n",
    "    gravarArquivosBinarios(entidade, dic_sentencesTrain, 'train')\n",
    "    gravarArquivosBinarios(entidade, dic_sentencesDev, 'dev')\n",
    "    gravarArquivosBinarios(entidade, dic_sentencesTest, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gravar arquivo para multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravarArquivosMultilabel(dic_sentences, tipo):\n",
    "    # gerar arquivo treinamento\n",
    "    f_entidade = open(r'multilabel/nested_'+tipo+'.conll', 'w', encoding='utf-8')\n",
    "\n",
    "    num_entidade_total=0\n",
    "\n",
    "    print('\\nGravando arquivo multilabel de {}'.format(tipo))\n",
    "\n",
    "    entidades = ['Problema','Teste','Tratamento','Anatomia']\n",
    "    for i in range(len(dic_sentences)):\n",
    "        tokens = dic_sentences[i][0]\n",
    "        ents = dic_sentences[i][1]\n",
    "        #print('tokens:', tokens)\n",
    "        #print('ents:', ents)\n",
    "        for token in tokens:\n",
    "            listaTokensLabels = list()\n",
    "            #print('token:', token)\n",
    "            indiceToken = token[1]\n",
    "            #print('indiceToken:', indiceToken)\n",
    "            labels = list()\n",
    "            for ent in ents:\n",
    "                #print('ent:', ent)\n",
    "                #print('indiceToken:', indiceToken)\n",
    "                if indiceToken in ent[1]:\n",
    "                    for entidade in entidades:\n",
    "                        tag = ent[2]\n",
    "                        if tag==entidade:\n",
    "                            labels.append(tag)\n",
    "                            num_entidade_total=num_entidade_total+1\n",
    "                        else:\n",
    "                            labels.append('O')\n",
    "            if len(labels)==0:\n",
    "                labels = ['O','O','O','O']\n",
    "            tokenGravar = token[0].replace(' ','')\n",
    "            tokenGravar = tokenGravar.strip()\n",
    "            f_entidade.write(tokenGravar+'\\t'+'\\t'.join(labels)+'\\n')\n",
    "            #print(tokenGravar+'\\t'+'\\t'.join(labels))\n",
    "\n",
    "        \n",
    "        f_entidade.write('\\n')\n",
    "\n",
    "    f_entidade.close()\n",
    "\n",
    "    print('num_entidade_total:', num_entidade_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gravando arquivo multilabel de train\n",
      "num_entidade_total: 4830\n",
      "\n",
      "Gravando arquivo multilabel de dev\n",
      "num_entidade_total: 1226\n",
      "\n",
      "Gravando arquivo multilabel de test\n",
      "num_entidade_total: 1803\n"
     ]
    }
   ],
   "source": [
    "gravarArquivosMultilabel(dic_sentencesTrain, 'train')\n",
    "gravarArquivosMultilabel(dic_sentencesDev, 'dev')\n",
    "gravarArquivosMultilabel(dic_sentencesTest, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parte 2- Gerar arquivo treinamento para SpanClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areConsecutive(arr):\n",
    "    # Sort the array\n",
    "    arr.sort()\n",
    "    n = len(arr)\n",
    "    # checking the adjacent elements\n",
    "    for i in range (1,n):\n",
    "        if(arr[i]!=arr[i-1]+1):\n",
    "            return False;\n",
    "             \n",
    "    return True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sentencesTest = load_obj('dic_sentencesTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinacaoEntidades(dic_predictions, filtro_postagger, dicPosTagger, taxaDownsampling):\n",
    "    num=0\n",
    "    erro_corpus=0\n",
    "    num_frases_sem_entidade=0\n",
    "    lista_erro_corpus=list()\n",
    "    combinacaoEntidadesAll = list()\n",
    "    combinacaoEntidades = list()\n",
    "    pulando_termos_postagger = list()\n",
    "    if filtro_postagger:\n",
    "        print('Com filtro-postagger')\n",
    "    else:\n",
    "        print('Sem filtro-postagger')\n",
    "    if taxaDownsampling>0:\n",
    "        print('Com taxa de Downsampling de ', taxaDownsampling)\n",
    "    else:\n",
    "        print('Sem taxa de Downsampling')\n",
    "    for key, value in dic_predictions.items():\n",
    "        num=num+1\n",
    "        combinacaoEntidades = list()\n",
    "        tokens=value[0].copy()\n",
    "        so_tokens = [t[0] for t in tokens]\n",
    "        entidades=value[1].copy()\n",
    "        num_positivas=0\n",
    "        for entidade in entidades:\n",
    "            erros_entidade = list()\n",
    "            texto_entidade=entidade[0].strip()\n",
    "            indices = entidade[1]\n",
    "            tipo_entidade = entidade[2]\n",
    "            frase = so_tokens.copy()\n",
    "            inicio=indices[0]\n",
    "            fim=indices[-1]\n",
    "            frase.insert(inicio, '<e1>')\n",
    "            frase.insert(fim+2, '</e1>')\n",
    "            if texto_entidade=='-' or texto_entidade=='=' or texto_entidade=='+' or texto_entidade==':' or texto_entidade==',' or texto_entidade==\"'\" or texto_entidade=='\"' or texto_entidade=='.' or texto_entidade==';' or texto_entidade=='/' or texto_entidade=='(' or texto_entidade==')' or texto_entidade=='[' or texto_entidade==']':\n",
    "                pass\n",
    "            texto_entidade_comparar=texto_entidade.replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_entidade_comparar = replaceWhiteSpaces(texto_entidade_comparar)\n",
    "            texto_frase_comparar = ' '.join(frase[inicio+1:fim+2]).strip().replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_frase_comparar = replaceWhiteSpaces(texto_frase_comparar)\n",
    "            texto_entidade_comparar = texto_entidade_comparar.lower()\n",
    "            texto_frase_comparar = texto_frase_comparar.lower()\n",
    "            if (texto_entidade_comparar == texto_frase_comparar):\n",
    "                num_positivas=num_positivas+1\n",
    "                combinacaoEntidades.append([' '.join(frase).strip(), tipo_entidade]) # apendando entidades reais\n",
    "            else:\n",
    "                print('erro, key:', key)\n",
    "                erro_corpus=erro_corpus+1\n",
    "                erros_entidade.append(indices)\n",
    "                lista_erro_corpus.append([' '.join(frase).strip(), tipo_entidade, ' '.join(so_tokens), entidade])\n",
    "\n",
    "        for entidade in entidades:\n",
    "                indices = entidade[1]\n",
    "                #print('indices:', indices)\n",
    "                if indices in erros_entidade:\n",
    "                    continue\n",
    "                inicio=indices[0]\n",
    "                fim=indices[-1]\n",
    "                # agora, fazer a combinacao entre eles.. todas a seguir serão do tipo 'O'           \n",
    "                for indice in indices:\n",
    "                    for i in range(indice, fim+1):\n",
    "                        # ver se nao tem antes\n",
    "                        frase = so_tokens.copy()\n",
    "                        #termo = frase[indice:i+2]\n",
    "                        termo = frase[indice:i+1]\n",
    "                        #print('--termo--:', termo)\n",
    "                        frase.insert(indice, '<e1>')\n",
    "                        frase.insert(i+2, '</e1>')\n",
    "                        frase_string=' '.join(frase).strip()\n",
    "                        #print('frase_string:', frase_string)\n",
    "                        devePular = 0\n",
    "                        if '. </e1>' in frase_string or ', </e1>' in frase_string  or '; </e1>' in frase_string or '- </e1>' in frase_string  or ': </e1>' in frase_string  or '= </e1>' in frase_string  or '/ </e1>' in frase_string  or '( </e1>' in frase_string  or ') </e1>' in frase_string  or '[ </e1>' in frase_string  or '] </e1>' in frase_string  or ': </e1>' in frase_string or 'and </e1>' in frase_string or 'or </e1>' in frase_string:\n",
    "                            devePular=1\n",
    "                        if '<e1> .' in frase_string or '<e1> ,' in frase_string  or '<e1> ;' in frase_string or '<e1> -' in frase_string  or '<e1> :' in frase_string  or '<e1> =' in frase_string  or '<e1> /' in frase_string  or '<e1> (' in frase_string  or '<e1> )' in frase_string  or '<e1> [' in frase_string  or '<e1> ]' in frase_string  or '<e1> :' in frase_string  or '<e1> and' in frase_string  or '<e1> or' in frase_string:\n",
    "                            devePular=1\n",
    "                        if re.search(\"<e1> [0-9]* </e1>\", frase_string):\n",
    "                            devePular=1\n",
    "                        if filtro_postagger==True:\n",
    "                            pos_tagger_termo = tipoPostaggerTokens(termo, dicPosTagger)\n",
    "                            if pos_tagger_termo not in lista_postaggers_entidades:\n",
    "                                pulando_termos_postagger.append([termo, pos_tagger_termo])\n",
    "                                devePular=1\n",
    "                \n",
    "                        tem_frase = 0\n",
    "                        for frase in combinacaoEntidades:\n",
    "                            if frase[0] == frase_string:\n",
    "                                tem_frase=''\n",
    "                                break\n",
    "                        if tem_frase==0 and devePular==0:\n",
    "                            combinacaoEntidades.append([frase_string, 'O'])\n",
    "        # shuffle no combinacaoEntidades\n",
    "        # taxaDownsampling, ex 2 para o dobro, 1 para mesma quantidade\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            if taxaDownsampling>0:\n",
    "                combinacaoEntidades = combinacaoEntidades[:(num_positivas*taxaDownsampling)+num_positivas]\n",
    "            random.shuffle(combinacaoEntidades)\n",
    "            combinacaoEntidadesAll.append([' '.join(so_tokens).strip(), combinacaoEntidades])\n",
    "        else:\n",
    "            num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "            combinacaoEntidadesAll.append([])\n",
    "        combinacaoEntidades = list()\n",
    "        if (num % 1000) ==0:\n",
    "            print('key:', key)\n",
    "\n",
    "    print('erro_corpus:', erro_corpus)\n",
    "    print('num_frases_sem_entidade:', num_frases_sem_entidade)\n",
    "    print('len(combinacaoEntidadesAll:)',len(combinacaoEntidadesAll))\n",
    "    print('len(pulando_termos_postagger):', len(pulando_termos_postagger))\n",
    "    \n",
    "    return combinacaoEntidadesAll, pulando_termos_postagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels sempre tem que começar com zero, senao da erro no treinamento\n",
    "# RuntimeError: CUDA error: device-side assert triggered\n",
    "def getCombinacaoEntidadesSoPositivos(dic_predictions):\n",
    "    num=0\n",
    "    erro_corpus=0\n",
    "    num_frases_sem_entidade=0\n",
    "    lista_erro_corpus=list()\n",
    "    combinacaoEntidadesAll = list()\n",
    "    combinacaoEntidades = list()\n",
    "    print('Só positivos')\n",
    "    for key, value in dic_predictions.items():\n",
    "        num=num+1\n",
    "        combinacaoEntidades = list()\n",
    "        tokens=value[0].copy()\n",
    "        so_tokens = [t[0] for t in tokens]\n",
    "        entidades=value[1].copy()\n",
    "        num_positivas=0\n",
    "        for entidade in entidades:\n",
    "            erros_entidade = list()\n",
    "            texto_entidade=entidade[0].strip()\n",
    "            indices = entidade[1]\n",
    "            tipo_entidade = entidade[2]\n",
    "            #print('tipo_entidade:', tipo_entidade)\n",
    "            frase = so_tokens.copy()\n",
    "            inicio=indices[0]\n",
    "            fim=indices[-1]\n",
    "            frase.insert(inicio, '<e1>')\n",
    "            frase.insert(fim+2, '</e1>')\n",
    "            if texto_entidade=='-' or texto_entidade=='=' or texto_entidade=='+' or texto_entidade==':' or texto_entidade==',' or texto_entidade==\"'\" or texto_entidade=='\"' or texto_entidade=='.' or texto_entidade==';' or texto_entidade=='/' or texto_entidade=='(' or texto_entidade==')' or texto_entidade=='[' or texto_entidade==']':\n",
    "                pass\n",
    "            texto_entidade_comparar=texto_entidade.replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_entidade_comparar = replaceWhiteSpaces(texto_entidade_comparar)\n",
    "            texto_frase_comparar = ' '.join(frase[inicio+1:fim+2]).strip().replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_frase_comparar = replaceWhiteSpaces(texto_frase_comparar)\n",
    "            texto_entidade_comparar = texto_entidade_comparar.lower()\n",
    "            texto_frase_comparar = texto_frase_comparar.lower()\n",
    "            if (texto_entidade_comparar == texto_frase_comparar):\n",
    "                num_positivas=num_positivas+1\n",
    "                combinacaoEntidades.append([' '.join(frase).strip(), tipo_entidade]) # apendando entidades reais\n",
    "            else:\n",
    "                print('erro, key:', key)\n",
    "                erro_corpus=erro_corpus+1\n",
    "                erros_entidade.append(indices)\n",
    "                lista_erro_corpus.append([' '.join(frase).strip(), tipo_entidade, ' '.join(so_tokens), entidade])\n",
    "\n",
    "        # shuffle no combinacaoEntidades\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            random.shuffle(combinacaoEntidades)\n",
    "            combinacaoEntidadesAll.append([' '.join(so_tokens).strip(), combinacaoEntidades])\n",
    "        else:\n",
    "            num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "            combinacaoEntidadesAll.append([])\n",
    "        combinacaoEntidades = list()\n",
    "  \n",
    "    print('erro_corpus:', erro_corpus)\n",
    "    print('num_frases_sem_entidade:', num_frases_sem_entidade)\n",
    "    print('len(combinacaoEntidadesAll:)',len(combinacaoEntidadesAll))\n",
    "    \n",
    "    return combinacaoEntidadesAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Só positivos\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidadesAll:) 1319\n",
      "\n",
      "--Dev--\n",
      "Só positivos\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidadesAll:) 416\n",
      "\n",
      "--Test--\n",
      "Só positivos\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidadesAll:) 506\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrainPos= getCombinacaoEntidadesSoPositivos(dic_sentencesTrain)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevPos = getCombinacaoEntidadesSoPositivos(dic_sentencesDev)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestPos = getCombinacaoEntidadesSoPositivos(dic_sentencesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sem filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidadesAll:) 1319\n",
      "len(pulando_termos_postagger): 0\n",
      "\n",
      "--Dev--\n",
      "Sem filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidadesAll:) 416\n",
      "len(pulando_termos_postagger): 0\n",
      "\n",
      "--Test--\n",
      "Sem filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidadesAll:) 506\n",
      "len(pulando_termos_postagger): 0\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrain, _ = getCombinacaoEntidades(dic_sentencesTrain, False, '', 0)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDev, _ = getCombinacaoEntidades(dic_sentencesDev, False, '', 0)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTest, _ = getCombinacaoEntidades(dic_sentencesTest, False, '', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aumento moderado de átrio esquerdo .',\n",
       " [['aumento <e1> moderado de átrio </e1> esquerdo .', 'O'],\n",
       "  ['aumento moderado <e1> de </e1> átrio esquerdo .', 'O'],\n",
       "  ['<e1> aumento moderado de átrio esquerdo </e1> .', 'Problema'],\n",
       "  ['<e1> aumento moderado de </e1> átrio esquerdo .', 'O'],\n",
       "  ['aumento moderado <e1> de átrio esquerdo </e1> .', 'O'],\n",
       "  ['aumento <e1> moderado de </e1> átrio esquerdo .', 'O'],\n",
       "  ['<e1> aumento moderado </e1> de átrio esquerdo .', 'O'],\n",
       "  ['aumento moderado de átrio <e1> esquerdo </e1> .', 'O'],\n",
       "  ['aumento moderado de <e1> átrio esquerdo </e1> .', 'Anatomia'],\n",
       "  ['<e1> aumento moderado de átrio </e1> esquerdo .', 'O'],\n",
       "  ['aumento <e1> moderado </e1> de átrio esquerdo .', 'O'],\n",
       "  ['<e1> aumento </e1> moderado de átrio esquerdo .', 'O'],\n",
       "  ['aumento <e1> moderado de átrio esquerdo </e1> .', 'O'],\n",
       "  ['aumento moderado <e1> de átrio </e1> esquerdo .', 'O'],\n",
       "  ['aumento moderado de <e1> átrio </e1> esquerdo .', 'O']]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesTest[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CONTRAÇÃO', 0, 507],\n",
       "  ['SEGMENTAR', 1, 517],\n",
       "  ['DO', 2, 527],\n",
       "  ['VE', 3, 530],\n",
       "  ['ALTERADA', 4, 533],\n",
       "  ['.', 5, 541]],\n",
       " [['CONTRAÇÃO SEGMENTAR DO VE ALTERADA', [0, 1, 2, 3, 4], 'Problema'],\n",
       "  ['VE', [3], 'Anatomia']]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# o erro é que o ponto faz com que quebre a frase, mas a entidade continua...\n",
    "dic_sentencesTrain[829]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DSLP em uso de sinvastatina , marevan 1 cp / dia seg - sab para no alvo sic .',\n",
       " [['DSLP em uso de <e1> sinvastatina </e1> , marevan 1 cp / dia seg - sab para no alvo sic .',\n",
       "   'Tratamento'],\n",
       "  ['DSLP em uso de sinvastatina , <e1> marevan </e1> 1 cp / dia seg - sab para no alvo sic .',\n",
       "   'Tratamento'],\n",
       "  ['<e1> DSLP </e1> em uso de sinvastatina , marevan 1 cp / dia seg - sab para no alvo sic .',\n",
       "   'Problema']]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesTest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONTRAÇÃO SEGMENTAR DO VE ALTERADA .',\n",
       " [['CONTRAÇÃO SEGMENTAR <e1> DO </e1> VE ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO SEGMENTAR DO VE <e1> ALTERADA </e1> .', 'O'],\n",
       "  ['<e1> CONTRAÇÃO </e1> SEGMENTAR DO VE ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO <e1> SEGMENTAR DO VE </e1> ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO SEGMENTAR DO <e1> VE ALTERADA </e1> .', 'O'],\n",
       "  ['<e1> CONTRAÇÃO SEGMENTAR DO VE ALTERADA </e1> .', 'Problema'],\n",
       "  ['CONTRAÇÃO <e1> SEGMENTAR DO </e1> VE ALTERADA .', 'O'],\n",
       "  ['<e1> CONTRAÇÃO SEGMENTAR DO </e1> VE ALTERADA .', 'O'],\n",
       "  ['<e1> CONTRAÇÃO SEGMENTAR </e1> DO VE ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO SEGMENTAR <e1> DO VE </e1> ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO <e1> SEGMENTAR DO VE ALTERADA </e1> .', 'O'],\n",
       "  ['CONTRAÇÃO SEGMENTAR DO <e1> VE </e1> ALTERADA .', 'Anatomia'],\n",
       "  ['CONTRAÇÃO <e1> SEGMENTAR </e1> DO VE ALTERADA .', 'O'],\n",
       "  ['<e1> CONTRAÇÃO SEGMENTAR DO VE </e1> ALTERADA .', 'O'],\n",
       "  ['CONTRAÇÃO SEGMENTAR <e1> DO VE ALTERADA </e1> .', 'O']]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesTrain[829]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAS , ICC , nega DM .',\n",
       " [['HAS , <e1> ICC </e1> , nega DM .', 'Problema'],\n",
       "  ['<e1> HAS </e1> , ICC , nega DM .', 'Problema'],\n",
       "  ['HAS , ICC , nega <e1> DM </e1> .', 'Problema']]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesDev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravarArquivosTreinamento(path, combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest):\n",
    "\n",
    "    # já ir gravando arquivos treinamento, test e dev...\n",
    "    # pra fazer um teste sem descontinuas\n",
    "    numTotalEntidades=0\n",
    "    numTotalEntidadesTrain=0\n",
    "    numTotalEntidadesDev=0\n",
    "    numTotalEntidadesTest=0\n",
    "\n",
    "    existeDir = os.path.exists(path)\n",
    "    if not existeDir:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    f_train = open(path+r'\\span.train', 'w', encoding='utf-8')\n",
    "\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesTrain):\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            frase = combinacaoEntidades[0]\n",
    "            frases_entidade = combinacaoEntidades[1]\n",
    "            f_train.write(frase+'\\n')\n",
    "            for frase_entidade in frases_entidade:\n",
    "                f_train.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "                numTotalEntidades=numTotalEntidades+1\n",
    "                numTotalEntidadesTrain=numTotalEntidadesTrain+1\n",
    "\n",
    "    f_train.close()\n",
    "\n",
    "    f_dev = open(path+r'\\span.dev', 'w', encoding='utf-8')\n",
    "\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesDev):\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            frase = combinacaoEntidades[0]\n",
    "            frases_entidade = combinacaoEntidades[1]\n",
    "            f_dev.write(frase+'\\n')\n",
    "            for frase_entidade in frases_entidade:\n",
    "                f_dev.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "                numTotalEntidades=numTotalEntidades+1\n",
    "                numTotalEntidadesDev=numTotalEntidadesDev+1\n",
    "\n",
    "    f_dev.close()\n",
    "\n",
    "    f_test = open(path+r'\\span.test', 'w', encoding='utf-8')\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesTest):\n",
    "        #print(dicSentences[i])\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            frase = combinacaoEntidades[0]\n",
    "            frases_entidade = combinacaoEntidades[1]\n",
    "            f_test.write(frase+'\\n')\n",
    "            for frase_entidade in frases_entidade:\n",
    "                f_test.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "                numTotalEntidades=numTotalEntidades+1\n",
    "                numTotalEntidadesTest=numTotalEntidadesTest+1\n",
    "\n",
    "    f_test.close()\n",
    "\n",
    "    print('numTotalEntidades:', numTotalEntidades)\n",
    "    print('numTotalEntidadesTrain:', numTotalEntidadesTrain)\n",
    "    print('numTotalEntidadesDev:', numTotalEntidadesDev)\n",
    "    print('numTotalEntidadesTest:', numTotalEntidadesTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 14133\n",
      "numTotalEntidadesTrain: 9079\n",
      "numTotalEntidadesDev: 2001\n",
      "numTotalEntidadesTest: 3053\n"
     ]
    }
   ],
   "source": [
    "gravarArquivosTreinamento('sem_filtro',combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 4204\n",
      "numTotalEntidadesTrain: 2510\n",
      "numTotalEntidadesDev: 703\n",
      "numTotalEntidadesTest: 991\n"
     ]
    }
   ],
   "source": [
    "gravarArquivosTreinamento('so_positivos',combinacaoEntidadesTrainPos, combinacaoEntidadesDevPos, combinacaoEntidadesTestPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gravar arquivo para sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinacaoEntidadesSentence(dic_predictions):\n",
    "    #labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "    labels = {'O':0, 'Problema':1, 'Tratamento':2, 'Teste':3, 'Anatomia':4}\n",
    "    num=0\n",
    "    erro_corpus=0\n",
    "    num_frases_sem_entidade=0\n",
    "    lista_erro_corpus=list()\n",
    "    combinacaoEntidades = list()\n",
    "    print('Sentence Pairs - Só positivos')\n",
    "    for key, value in dic_predictions.items():\n",
    "        num=num+1\n",
    "        tokens=value[0].copy()\n",
    "        so_tokens = [t[0] for t in tokens]\n",
    "        entidades=value[1].copy()\n",
    "        num_positivas=0\n",
    "        for entidade in entidades:\n",
    "            erros_entidade = list()\n",
    "            texto_entidade=entidade[0].strip()\n",
    "            indices = entidade[1]\n",
    "            tipo_entidade = entidade[2]\n",
    "            frase = so_tokens.copy()\n",
    "            inicio=indices[0]\n",
    "            fim=indices[-1]\n",
    "            #entidade_frase=frase[inicio:fim+1] # texto_entidade\n",
    "            entidade_frase=texto_entidade\n",
    "            #print('entidade_frase:', entidade_frase)\n",
    "            #print('frase:', frase)\n",
    "            #print('texto_entidade:', texto_entidade)\n",
    "            if texto_entidade=='-' or texto_entidade=='=' or texto_entidade=='+' or texto_entidade==':' or texto_entidade==',' or texto_entidade==\"'\" or texto_entidade=='\"' or texto_entidade=='.' or texto_entidade==';' or texto_entidade=='/' or texto_entidade=='(' or texto_entidade==')' or texto_entidade=='[' or texto_entidade==']':\n",
    "                pass\n",
    "            texto_entidade_comparar=texto_entidade.replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_entidade_comparar = replaceWhiteSpaces(texto_entidade_comparar)\n",
    "            texto_frase_comparar = ' '.join(frase[inicio:fim+1]).strip().replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_frase_comparar = replaceWhiteSpaces(texto_frase_comparar)\n",
    "            texto_entidade_comparar = texto_entidade_comparar.lower()\n",
    "            texto_frase_comparar = texto_frase_comparar.lower()\n",
    "            #print('texto_entidade_comparar:', texto_entidade_comparar)\n",
    "            #print('texto_frase_comparar:', texto_frase_comparar)\n",
    "            if (texto_entidade_comparar == texto_frase_comparar):\n",
    "                num_positivas=num_positivas+1\n",
    "                combinacaoEntidades.append([entidade_frase, ' '.join(frase).strip(), labels[tipo_entidade]]) # apendando entidades reais\n",
    "            else:\n",
    "                print('erro, key:', key)\n",
    "                erro_corpus=erro_corpus+1\n",
    "                erros_entidade.append(indices)\n",
    "                lista_erro_corpus.append([' '.join(frase).strip(), tipo_entidade, ' '.join(so_tokens), entidade])\n",
    "\n",
    "        # shuffle no combinacaoEntidades\n",
    "        #if len(combinacaoEntidades)>0:\n",
    "        #    random.shuffle(combinacaoEntidades)\n",
    "        #    combinacaoEntidadesAll.append(combinacaoEntidades)\n",
    "        #else:\n",
    "        #    num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "            #combinacaoEntidadesAll.append([])\n",
    "        #combinacaoEntidades = list()\n",
    "        \n",
    "    random.shuffle(combinacaoEntidades)\n",
    "  \n",
    "    print('erro_corpus:', erro_corpus)\n",
    "    print('num_frases_sem_entidade:', num_frases_sem_entidade)\n",
    "    print('len(combinacaoEntidades:)',len(combinacaoEntidades))\n",
    "    \n",
    "    return combinacaoEntidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='12mg'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"^[0-9]*mg\", '12mg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinacaoEntidadesSentence(dic_predictions, filtro_postagger, dicPosTagger, taxaDownsampling):\n",
    "    #labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "    labels = {'O':0, 'Problema':1, 'Tratamento':2, 'Teste':3, 'Anatomia':4}\n",
    "    num=0\n",
    "    erro_corpus=0\n",
    "    num_frases_sem_entidade=0\n",
    "    lista_erro_corpus=list()\n",
    "    combinacaoEntidadesPos = list()\n",
    "    combinacaoEntidadesNeg = list()\n",
    "    combinacaoEntidades = list()\n",
    "    pulando_termos_postagger = list()\n",
    "    if filtro_postagger:\n",
    "        print('Sentence Pairs - Com filtro-postagger')\n",
    "    else:\n",
    "        print('Sentence Pairs - Sem filtro-postagger')\n",
    "    if taxaDownsampling>0:\n",
    "        print('Sentence Pairs - Com taxa de Downsampling de ', taxaDownsampling)\n",
    "    else:\n",
    "        print('Sentence Pairs - Sem taxa de Downsampling')\n",
    "\n",
    "    for key, value in dic_predictions.items():\n",
    "        num=num+1\n",
    "        tokens=value[0].copy()\n",
    "        so_tokens = [t[0] for t in tokens]\n",
    "        entidades=value[1].copy()\n",
    "        num_positivas=0\n",
    "        for entidade in entidades:\n",
    "            erros_entidade = list()\n",
    "            texto_entidade=entidade[0].strip()\n",
    "            indices = entidade[1]\n",
    "            tipo_entidade = entidade[2]\n",
    "            frase = so_tokens.copy()\n",
    "            inicio=indices[0]\n",
    "            fim=indices[-1]\n",
    "            #entidade_frase=frase[inicio:fim+1] # texto_entidade\n",
    "            entidade_frase=texto_entidade\n",
    "            #print('entidade_frase:', entidade_frase)\n",
    "            #print('frase:', frase)\n",
    "            #print('texto_entidade:', texto_entidade)\n",
    "            if texto_entidade=='-' or texto_entidade=='=' or texto_entidade=='+' or texto_entidade==':' or texto_entidade==',' or texto_entidade==\"'\" or texto_entidade=='\"' or texto_entidade=='.' or texto_entidade==';' or texto_entidade=='/' or texto_entidade=='(' or texto_entidade==')' or texto_entidade=='[' or texto_entidade==']':\n",
    "                pass\n",
    "            texto_entidade_comparar=texto_entidade.replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_entidade_comparar = replaceWhiteSpaces(texto_entidade_comparar)\n",
    "            texto_frase_comparar = ' '.join(frase[inicio:fim+1]).strip().replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_frase_comparar = replaceWhiteSpaces(texto_frase_comparar)\n",
    "            texto_entidade_comparar = texto_entidade_comparar.lower()\n",
    "            texto_frase_comparar = texto_frase_comparar.lower()\n",
    "            #print('texto_entidade_comparar:', texto_entidade_comparar)\n",
    "            #print('texto_frase_comparar:', texto_frase_comparar)\n",
    "            if (texto_entidade_comparar == texto_frase_comparar):\n",
    "                num_positivas=num_positivas+1\n",
    "                combinacaoEntidadesPos.append([entidade_frase, ' '.join(frase).strip(), labels[tipo_entidade]]) # apendando entidades reais\n",
    "            else:\n",
    "                print('erro, key:', key)\n",
    "                erro_corpus=erro_corpus+1\n",
    "                erros_entidade.append(indices)\n",
    "                lista_erro_corpus.append([' '.join(frase).strip(), tipo_entidade, ' '.join(so_tokens), entidade])\n",
    "        # agora, os negativos\n",
    "        for entidade in entidades:\n",
    "                indices = entidade[1]\n",
    "                #print('indices:', indices)\n",
    "                if indices in erros_entidade:\n",
    "                    continue\n",
    "                inicio=indices[0]\n",
    "                fim=indices[-1]\n",
    "                # agora, fazer a combinacao entre eles.. todas a seguir serão do tipo 'O'           \n",
    "                for indice in indices:\n",
    "                    for i in range(indice, fim+1):\n",
    "                        # ver se nao tem antes\n",
    "                        frase = so_tokens.copy()\n",
    "                        termo = frase[indice:i+1]\n",
    "                        #termo=entidade[0].strip()\n",
    "                        #print('--termo--:', termo)\n",
    "                        #frase.insert(indice, '<e1>')\n",
    "                        #frase.insert(i+2, '</e1>')\n",
    "                        #frase_string=' '.join(frase).strip()\n",
    "                        #frase_string=texto_entidade\n",
    "                        #frase_string=termo[0]\n",
    "                        frase_string=' '.join(termo).strip()\n",
    "                        #print('frase_string:', frase_string)\n",
    "                        devePular = 0\n",
    "                        if '.' in frase_string[-1:] or ',' in frase_string[-1:]  or ';' in frase_string[-1:] or '-' in frase_string[-1:]  or ':' in frase_string[-1:]  or '=' in frase_string[-1:]  or '/' in frase_string[-1:]  or '(' in frase_string[-1:]  or ')' in frase_string[-1:]  or '[' in frase_string[-1:]  or ']' in frase_string[-1:]  or ':' in frase_string[-1:]:\n",
    "                            devePular=1\n",
    "                        if '.' in frase_string[:1] or ',' in frase_string[:1]  or ';' in frase_string[:1] or '-' in frase_string[:1]  or ':' in frase_string[:1]  or '=' in frase_string[:1] or '/' in frase_string[:1]  or '(' in frase_string[:1]  or ')' in frase_string[:1] or '[' in frase_string[:1]  or ']' in frase_string[:1]  or ':' in frase_string[:1]:\n",
    "                            devePular=1\n",
    "                        if re.search(\"^[0-9]*mg\", frase_string):\n",
    "                            devePular=1\n",
    "                            \n",
    "                        if filtro_postagger==True:\n",
    "                            pos_tagger_termo = tipoPostaggerTokens(termo, dicPosTagger)\n",
    "                            if pos_tagger_termo not in lista_postaggers_entidades:\n",
    "                                pulando_termos_postagger.append([termo, pos_tagger_termo])\n",
    "                                devePular=1\n",
    "                \n",
    "                        tem_frase = 0\n",
    "                        for frase_l in combinacaoEntidadesPos:\n",
    "                            if frase_l[0] == frase_string:\n",
    "                                tem_frase='1'\n",
    "                                break\n",
    "                        if tem_frase==0 and devePular==0:\n",
    "                        #print('tem_frase:', tem_frase)\n",
    "                        #if tem_frase==0:\n",
    "                            #print('aaaaaaaaaaaa, frase_string:', frase_string)\n",
    "                            combinacaoEntidadesNeg.append([frase_string, ' '.join(frase).strip(), labels['O']])\n",
    "                        #combinacaoEntidadesNeg.append([frase_string, ' '.join(frase).strip(), labels['O']])\n",
    "                        \n",
    "        # shuffle no combinacaoEntidades\n",
    "        #if len(combinacaoEntidades)>0:\n",
    "        #    random.shuffle(combinacaoEntidades)\n",
    "        #    combinacaoEntidadesAll.append(combinacaoEntidades)\n",
    "        #else:\n",
    "        #    num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "            #combinacaoEntidadesAll.append([])\n",
    "        #combinacaoEntidades = list()\n",
    "        \n",
    "        # shuffle no combinacaoEntidades\n",
    "        # taxaDownsampling, ex 2 para o dobro, 1 para mesma quantidade\n",
    "        if len(combinacaoEntidadesPos)>0:\n",
    "            if taxaDownsampling>0:\n",
    "                combinacaoEntidadesNeg = combinacaoEntidadesNeg[:(num_positivas*taxaDownsampling)]\n",
    "            random.shuffle(combinacaoEntidadesNeg)\n",
    "        else:\n",
    "            num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "        if (num % 1000) ==0:\n",
    "            print('key:', key)\n",
    "\n",
    "        #print('combinacaoEntidadesNeg:',combinacaoEntidadesNeg)\n",
    "        combinacaoEntidades = combinacaoEntidades+combinacaoEntidadesPos+combinacaoEntidadesNeg\n",
    "        combinacaoEntidadesPos=list()\n",
    "        combinacaoEntidadesNeg=list()\n",
    "  \n",
    "    print('erro_corpus:', erro_corpus)\n",
    "    print('num_frases_sem_entidade:', num_frases_sem_entidade)\n",
    "    print('len(combinacaoEntidades:)',len(combinacaoEntidades))\n",
    "    \n",
    "    return combinacaoEntidades\n",
    "\n",
    "#combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, True, dicPosTagger, 1)\n",
    "#combinacaoEntidadesTrain, pulando_termos_postaggerTrain = getCombinacaoEntidades(dic_sentencesTrain, True, dicPosTagger, 0)\n",
    "#combinacaoEntidadesTestSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinacaoEntidadesSentencePos(dic_predictions):\n",
    "    labels = {'Problema':0, 'Tratamento':1, 'Teste':2, 'Anatomia':3}\n",
    "    num=0\n",
    "    erro_corpus=0\n",
    "    num_frases_sem_entidade=0\n",
    "    lista_erro_corpus=list()\n",
    "    combinacaoEntidadesPos = list()\n",
    "    combinacaoEntidades = list()\n",
    "    pulando_termos_postagger = list()\n",
    "    print('Sentence Pairs - So positivos')\n",
    "\n",
    "    for key, value in dic_predictions.items():\n",
    "        num=num+1\n",
    "        tokens=value[0].copy()\n",
    "        so_tokens = [t[0] for t in tokens]\n",
    "        entidades=value[1].copy()\n",
    "        num_positivas=0\n",
    "        for entidade in entidades:\n",
    "            erros_entidade = list()\n",
    "            texto_entidade=entidade[0].strip()\n",
    "            indices = entidade[1]\n",
    "            tipo_entidade = entidade[2]\n",
    "            frase = so_tokens.copy()\n",
    "            inicio=indices[0]\n",
    "            fim=indices[-1]\n",
    "            #entidade_frase=frase[inicio:fim+1] # texto_entidade\n",
    "            entidade_frase=texto_entidade\n",
    "            #print('entidade_frase:', entidade_frase)\n",
    "            #print('frase:', frase)\n",
    "            #print('texto_entidade:', texto_entidade)\n",
    "            if texto_entidade=='-' or texto_entidade=='=' or texto_entidade=='+' or texto_entidade==':' or texto_entidade==',' or texto_entidade==\"'\" or texto_entidade=='\"' or texto_entidade=='.' or texto_entidade==';' or texto_entidade=='/' or texto_entidade=='(' or texto_entidade==')' or texto_entidade=='[' or texto_entidade==']':\n",
    "                pass\n",
    "            texto_entidade_comparar=texto_entidade.replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_entidade_comparar = replaceWhiteSpaces(texto_entidade_comparar)\n",
    "            texto_frase_comparar = ' '.join(frase[inicio:fim+1]).strip().replace('/','').replace(')','').replace('(','').replace(']','').replace('[','').replace(',','').replace('.','').replace(';','').replace('-','').replace('+','').replace(\"'\",'')\n",
    "            texto_frase_comparar = replaceWhiteSpaces(texto_frase_comparar)\n",
    "            texto_entidade_comparar = texto_entidade_comparar.lower()\n",
    "            texto_frase_comparar = texto_frase_comparar.lower()\n",
    "            #print('texto_entidade_comparar:', texto_entidade_comparar)\n",
    "            #print('texto_frase_comparar:', texto_frase_comparar)\n",
    "            if (texto_entidade_comparar == texto_frase_comparar):\n",
    "                num_positivas=num_positivas+1\n",
    "                combinacaoEntidadesPos.append([entidade_frase, ' '.join(frase).strip(), labels[tipo_entidade]]) # apendando entidades reais\n",
    "            else:\n",
    "                print('erro, key:', key)\n",
    "                erro_corpus=erro_corpus+1\n",
    "                erros_entidade.append(indices)\n",
    "                lista_erro_corpus.append([' '.join(frase).strip(), tipo_entidade, ' '.join(so_tokens), entidade])\n",
    "\n",
    "        if len(combinacaoEntidadesPos)>0:\n",
    "            random.shuffle(combinacaoEntidadesPos)\n",
    "        else:\n",
    "            num_frases_sem_entidade = num_frases_sem_entidade+1\n",
    "        if (num % 1000) ==0:\n",
    "            print('key:', key)\n",
    "\n",
    "        #print('combinacaoEntidadesNeg:',combinacaoEntidadesNeg)\n",
    "        combinacaoEntidades = combinacaoEntidades+combinacaoEntidadesPos\n",
    "        combinacaoEntidadesPos=list()\n",
    "  \n",
    "    print('erro_corpus:', erro_corpus)\n",
    "    print('num_frases_sem_entidade:', num_frases_sem_entidade)\n",
    "    print('len(combinacaoEntidades:)',len(combinacaoEntidades))\n",
    "    \n",
    "    return combinacaoEntidades\n",
    "\n",
    "#combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentencePos(dic_sentencesTest)\n",
    "#combinacaoEntidadesTrain, pulando_termos_postaggerTrain = getCombinacaoEntidades(dic_sentencesTrain, True, dicPosTagger, 0)\n",
    "#combinacaoEntidadesTestSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - Sem filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 9696\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - Sem filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 2159\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - Sem filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 3233\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentence= getCombinacaoEntidadesSentence(dic_sentencesTrain, False, '', 0)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentence = getCombinacaoEntidadesSentence(dic_sentencesDev, False, '', 0)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, False, '', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravarArquivosTreinamentoSentence(path, combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest):\n",
    "\n",
    "    # já ir gravando arquivos treinamento, test e dev...\n",
    "    # pra fazer um teste sem descontinuas\n",
    "    numTotalEntidades=0\n",
    "    numTotalEntidadesTrain=0\n",
    "    numTotalEntidadesDev=0\n",
    "    numTotalEntidadesTest=0\n",
    "\n",
    "    existeDir = os.path.exists(path)\n",
    "    if not existeDir:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    f_train = open(path+r'\\sentence_pairs.train', 'w', encoding='utf-8')\n",
    "\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesTrain):\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            termo = combinacaoEntidades[0]\n",
    "            frase = combinacaoEntidades[1]\n",
    "            label = str(combinacaoEntidades[2])\n",
    "            f_train.write(termo+'\\t'+frase+'\\t'+label+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesTrain=numTotalEntidadesTrain+1\n",
    "    f_train.close()\n",
    "\n",
    "    f_dev = open(path+r'\\sentence_pairs.dev', 'w', encoding='utf-8')\n",
    "\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesDev):\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            termo = combinacaoEntidades[0]\n",
    "            frase = combinacaoEntidades[1]\n",
    "            label = str(combinacaoEntidades[2])\n",
    "            f_dev.write(termo+'\\t'+frase+'\\t'+label+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesDev=numTotalEntidadesDev+1\n",
    "    f_dev.close()\n",
    "\n",
    "    f_test = open(path+r'\\sentence_pairs.test', 'w', encoding='utf-8')\n",
    "    for i, combinacaoEntidades in enumerate(combinacaoEntidadesTest):\n",
    "        #print(dicSentences[i])\n",
    "        if len(combinacaoEntidades)>0:\n",
    "            termo = combinacaoEntidades[0]\n",
    "            frase = combinacaoEntidades[1]\n",
    "            label = str(combinacaoEntidades[2])\n",
    "            f_test.write(termo+'\\t'+frase+'\\t'+label+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesTest=numTotalEntidadesTest+1\n",
    "    f_test.close()\n",
    "\n",
    "    print('numTotalEntidades:', numTotalEntidades)\n",
    "    print('numTotalEntidadesTrain:', numTotalEntidadesTrain)\n",
    "    print('numTotalEntidadesDev:', numTotalEntidadesDev)\n",
    "    print('numTotalEntidadesTest:', numTotalEntidadesTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 15088\n",
      "numTotalEntidadesTrain: 9696\n",
      "numTotalEntidadesDev: 2159\n",
      "numTotalEntidadesTest: 3233\n"
     ]
    }
   ],
   "source": [
    "gravarArquivosTreinamentoSentence('sentence-pairs-all',combinacaoEntidadesTrainSentence, combinacaoEntidadesDevSentence, combinacaoEntidadesTestSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - So positivos\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 2510\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - So positivos\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 703\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - So positivos\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 991\n",
      "numTotalEntidades: 4204\n",
      "numTotalEntidadesTrain: 2510\n",
      "numTotalEntidadesDev: 703\n",
      "numTotalEntidadesTest: 991\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentencePos= getCombinacaoEntidadesSentencePos(dic_sentencesTrain)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentencePos = getCombinacaoEntidadesSentencePos(dic_sentencesDev)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentencePos = getCombinacaoEntidadesSentencePos(dic_sentencesTest)\n",
    "\n",
    "gravarArquivosTreinamentoSentence('sentence-pairs-positivos',combinacaoEntidadesTrainSentencePos, combinacaoEntidadesDevSentencePos, combinacaoEntidadesTestSentencePos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 4062\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 1048\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 1555\n",
      "numTotalEntidades: 6665\n",
      "numTotalEntidadesTrain: 4062\n",
      "numTotalEntidadesDev: 1048\n",
      "numTotalEntidadesTest: 1555\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentence= getCombinacaoEntidadesSentence(dic_sentencesTrain, True, dicPosTagger, 1)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentence = getCombinacaoEntidadesSentence(dic_sentencesDev, True, dicPosTagger, 1)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, True, dicPosTagger, 1)\n",
    "gravarArquivosTreinamentoSentence('sentence-pairs-downsampling',combinacaoEntidadesTrainSentence, combinacaoEntidadesDevSentence, combinacaoEntidadesTestSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 5037\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 1264\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 1917\n"
     ]
    }
   ],
   "source": [
    "#OLD\n",
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentence= getCombinacaoEntidadesSentence(dic_sentencesTrain, True, dicPosTagger, 1)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentence = getCombinacaoEntidadesSentence(dic_sentencesDev, True, dicPosTagger, 1)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, True, dicPosTagger, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 8218\n",
      "numTotalEntidadesTrain: 5037\n",
      "numTotalEntidadesDev: 1264\n",
      "numTotalEntidadesTest: 1917\n"
     ]
    }
   ],
   "source": [
    "#gravarArquivosTreinamentoSentence('sentence-pairs-filtro',combinacaoEntidadesTrainSentence, combinacaoEntidadesDevSentence, combinacaoEntidadesTestSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 6753\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 1635\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 2478\n",
      "numTotalEntidades: 10866\n",
      "numTotalEntidadesTrain: 6753\n",
      "numTotalEntidadesDev: 1635\n",
      "numTotalEntidadesTest: 2478\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentence= getCombinacaoEntidadesSentence(dic_sentencesTrain, True, dicPosTagger, 0)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentence = getCombinacaoEntidadesSentence(dic_sentencesDev, True, dicPosTagger, 0)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, True, dicPosTagger, 0)\n",
    "gravarArquivosTreinamentoSentence('sentence-pairs-filtro',combinacaoEntidadesTrainSentence, combinacaoEntidadesDevSentence, combinacaoEntidadesTestSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidades:) 6753\n",
      "\n",
      "--Dev--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidades:) 1635\n",
      "\n",
      "--Test--\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidades:) 2478\n",
      "numTotalEntidades: 10866\n",
      "numTotalEntidadesTrain: 6753\n",
      "numTotalEntidadesDev: 1635\n",
      "numTotalEntidadesTest: 2478\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print('--Train--')\n",
    "combinacaoEntidadesTrainSentence= getCombinacaoEntidadesSentence(dic_sentencesTrain, True, dicPosTagger, 0)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDevSentence = getCombinacaoEntidadesSentence(dic_sentencesDev, True, dicPosTagger, 0)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTestSentence = getCombinacaoEntidadesSentence(dic_sentencesTest, True, dicPosTagger, 0)\n",
    "gravarArquivosTreinamentoSentence('sentence-pairs-downsampling',combinacaoEntidadesTrainSentence, combinacaoEntidadesDevSentence, combinacaoEntidadesTestSentence)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesTestSentence[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parte 2.2 - tentar tirar verbos, CC, etc do O para nao ficar com mto FP\n",
    "### depois, com nosso pos tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3484"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"pucpr-br/postagger-bio-portuguese\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('pucpr-br/postagger-bio-portuguese')\n",
    "\n",
    "nlp_token_class = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy='max')\n",
    "\n",
    "def getDicPosTagger(dic_sentencesTrainDev):\n",
    "    dicPostagger = load_obj('dic_postagger')\n",
    "    allFrases = load_obj('allFrases')\n",
    "    if dicPostagger==None or allFrases==None:\n",
    "        dicPostagger = {}\n",
    "        allFrases=[]\n",
    "        for key, value in dic_sentencesTrainDev.items():\n",
    "            tokens=value[0]\n",
    "            frase = [t[0] for t in tokens]\n",
    "            frase = ' '.join(frase)\n",
    "            allFrases.append(frase)\n",
    "            #print(frase)\n",
    "\n",
    "        #print(allFrases)\n",
    "        doc = nlp_token_class(allFrases)\n",
    "        #print(doc)\n",
    "        for frase in doc:\n",
    "            for d in frase:\n",
    "                #print(d)\n",
    "                pos = d['entity_group']\n",
    "                #print(pos)\n",
    "                token=d['word']\n",
    "                if pos=='PREP+ART':\n",
    "                    pos='ART'\n",
    "                if pos=='NPROP':\n",
    "                    pos='N'\n",
    "                if 'ADV' in pos: # ADV-KS, ADV-KS-REL\t\n",
    "                    pos='ADV'\n",
    "                if 'PRON' in pos: # PRO-KS\t, PRO-KS-REL, PROPESS, PROPSUB\n",
    "                    pos='PRON'\n",
    "                if pos=='VAUX'or pos=='PCP': #participio\n",
    "                    pos='V'\n",
    "                dicPostagger[token] = pos    \n",
    "\n",
    "        save_obj('dicPostagger', dicPostagger)\n",
    "        save_obj('allFrases', allFrases)\n",
    "    return dicPostagger, allFrases\n",
    "\n",
    "dic_sentencesTrainDev = load_obj('dic_sentencesTrainDev')\n",
    "\n",
    "dicPosTagger, _ = getDicPosTagger(dic_sentencesTrainDev)\n",
    "#dicPosTagger, _ = getDicPosTagger(dic_sentencesTest)\n",
    "len(dicPosTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-N-PREP-ART-N-ADV-PU'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tipoPostaggerTokens(entidade_token, dicPostagger):\n",
    "    postagger = ''\n",
    "    for p in entidade_token:\n",
    "        #print('p:', p)\n",
    "        if p.lower() in dicPostagger.keys():\n",
    "            postagger = postagger + '-' + dicPostagger.get(p.lower())\n",
    "        else:\n",
    "            #print('nao tem:', p)\n",
    "            # se nao tem, considera N\n",
    "            postagger = postagger + '-' + 'N'\n",
    "    return postagger\n",
    "tipoPostaggerTokens(['ola','como','aos','você','hoje', '?'], dicPosTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sentencesTrainDev = load_obj('dic_sentencesTrainDev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-N-ADJ-ART-N',\n",
       " '-N-N-N-ART-N-ART-N',\n",
       " '-N',\n",
       " '-N-ADJ',\n",
       " '-ADJ',\n",
       " '-V',\n",
       " '-N-NUM',\n",
       " '-N-PU-ADJ-N',\n",
       " '-ADJ-N-N-ADJ-PREP-N',\n",
       " '-N-PREP-N-ART-N']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getListaPostaggerEntidades(dic_sentencesTrainDev, dicPosTagger):\n",
    "    lista_postaggers_entidades = []\n",
    "    for key, value in dic_sentencesTrainDev.items():\n",
    "        entidades = value[1]\n",
    "        for entidade in entidades:\n",
    "            #print(entidade[0])\n",
    "            pos_tagger=tipoPostaggerTokens(entidade[0].split(), dicPosTagger)\n",
    "            if pos_tagger not in lista_postaggers_entidades:\n",
    "                lista_postaggers_entidades.append(pos_tagger)\n",
    "    return lista_postaggers_entidades\n",
    "\n",
    "lista_postaggers_entidades = getListaPostaggerEntidades(dic_sentencesTrainDev, dicPosTagger)\n",
    "lista_postaggers_entidades[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-N-ADJ-ADJ-N-N-N',\n",
       " '-N-ADJ-N-N-N',\n",
       " '-ADJ-N-N-N',\n",
       " '-N-ADV-N-N-PU-NUM-N',\n",
       " '-ADJ-N-PREP-N',\n",
       " '-N-PREP-N-N-ADV',\n",
       " '-V-PDEN-PREP-ADJ-N',\n",
       " '-N-N-PREP-N-PU-N-PU-N-PU-N-PREP-N',\n",
       " '-ADJ-N-PREP-N-ADJ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_postaggers_entidades[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('-KC' in lista_postaggers_entidades) # e\n",
    "print('-PREP+ART' in lista_postaggers_entidades) \n",
    "print('-PREP' in lista_postaggers_entidades)\n",
    "print('-ART' in lista_postaggers_entidades)\n",
    "print('-V' in lista_postaggers_entidades)\n",
    "print('-ADJ' in lista_postaggers_entidades)\n",
    "print('-PU' in lista_postaggers_entidades)\n",
    "print('-PCP' in lista_postaggers_entidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Com filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidadesAll:) 1319\n",
      "len(pulando_termos_postagger): 3925\n",
      "\n",
      "--Dev--\n",
      "Com filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidadesAll:) 416\n",
      "len(pulando_termos_postagger): 745\n",
      "\n",
      "--Test--\n",
      "Com filtro-postagger\n",
      "Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidadesAll:) 506\n",
      "len(pulando_termos_postagger): 1183\n"
     ]
    }
   ],
   "source": [
    "print('--Train--')\n",
    "combinacaoEntidadesTrain, pulando_termos_postaggerTrain = getCombinacaoEntidades(dic_sentencesTrain, True, dicPosTagger, 0)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDev, pulando_termos_postaggerDev= getCombinacaoEntidades(dic_sentencesDev, True, dicPosTagger, 0)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTest, pulando_termos_postaggerTest= getCombinacaoEntidades(dic_sentencesTest, True, dicPosTagger, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aumento moderado de átrio esquerdo .',\n",
       " [['aumento moderado <e1> de átrio esquerdo </e1> .', 'O'],\n",
       "  ['aumento <e1> moderado </e1> de átrio esquerdo .', 'O'],\n",
       "  ['aumento moderado <e1> de </e1> átrio esquerdo .', 'O'],\n",
       "  ['aumento <e1> moderado de </e1> átrio esquerdo .', 'O'],\n",
       "  ['<e1> aumento moderado de átrio esquerdo </e1> .', 'Problema'],\n",
       "  ['aumento moderado de <e1> átrio esquerdo </e1> .', 'Anatomia'],\n",
       "  ['aumento moderado de átrio <e1> esquerdo </e1> .', 'O'],\n",
       "  ['aumento <e1> moderado de átrio esquerdo </e1> .', 'O'],\n",
       "  ['aumento moderado <e1> de átrio </e1> esquerdo .', 'O'],\n",
       "  ['aumento <e1> moderado de átrio </e1> esquerdo .', 'O'],\n",
       "  ['<e1> aumento </e1> moderado de átrio esquerdo .', 'O'],\n",
       "  ['aumento moderado de <e1> átrio </e1> esquerdo .', 'O']]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesTest[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['25'], '-NUM'],\n",
       " [['ventrículo', 'esquerdo', 'com'], '-N-ADJ-PREP'],\n",
       " [['ventrículo', 'esquerdo', 'com', 'hipertrofia', 'concentrica', 'de'],\n",
       "  '-N-ADJ-PREP-N-N-PREP'],\n",
       " [['ventrículo',\n",
       "   'esquerdo',\n",
       "   'com',\n",
       "   'hipertrofia',\n",
       "   'concentrica',\n",
       "   'de',\n",
       "   'grau'],\n",
       "  '-N-ADJ-PREP-N-N-PREP-N'],\n",
       " [['ventrículo',\n",
       "   'esquerdo',\n",
       "   'com',\n",
       "   'hipertrofia',\n",
       "   'concentrica',\n",
       "   'de',\n",
       "   'grau',\n",
       "   'discreto'],\n",
       "  '-N-ADJ-PREP-N-N-PREP-N-ADJ'],\n",
       " [['esquerdo', 'com'], '-ADJ-PREP'],\n",
       " [['esquerdo', 'com', 'hipertrofia'], '-ADJ-PREP-N'],\n",
       " [['esquerdo', 'com', 'hipertrofia', 'concentrica'], '-ADJ-PREP-N-N'],\n",
       " [['esquerdo', 'com', 'hipertrofia', 'concentrica', 'de'],\n",
       "  '-ADJ-PREP-N-N-PREP'],\n",
       " [['esquerdo', 'com', 'hipertrofia', 'concentrica', 'de', 'grau'],\n",
       "  '-ADJ-PREP-N-N-PREP-N'],\n",
       " [['esquerdo', 'com', 'hipertrofia', 'concentrica', 'de', 'grau', 'discreto'],\n",
       "  '-ADJ-PREP-N-N-PREP-N-ADJ'],\n",
       " [['com', 'hipertrofia', 'concentrica', 'de'], '-PREP-N-N-PREP'],\n",
       " [['com', 'hipertrofia', 'concentrica', 'de', 'grau'], '-PREP-N-N-PREP-N'],\n",
       " [['com', 'hipertrofia', 'concentrica', 'de', 'grau', 'discreto'],\n",
       "  '-PREP-N-N-PREP-N-ADJ'],\n",
       " [['hipertrofia', 'concentrica', 'de'], '-N-N-PREP'],\n",
       " [['hipertrofia', 'concentrica', 'de', 'grau', 'discreto'], '-N-N-PREP-N-ADJ'],\n",
       " [['aumento', 'moderado'], '-V-N'],\n",
       " [['aumento', 'moderado', 'de'], '-V-N-PREP'],\n",
       " [['aumento', 'moderado', 'de', 'átrio'], '-V-N-PREP-N'],\n",
       " [['aumento', 'moderado', 'de', 'átrio', 'esquerdo'], '-V-N-PREP-N-ADJ'],\n",
       " [['calcificação', 'mitral', 'e'], '-N-ADJ-KC'],\n",
       " [['calcificação', 'mitral', 'e', 'aórtica'], '-N-ADJ-KC-N'],\n",
       " [['calcificação', 'mitral', 'e', 'aórtica', 'com'], '-N-ADJ-KC-N-PREP'],\n",
       " [['calcificação', 'mitral', 'e', 'aórtica', 'com', 'refluxo'],\n",
       "  '-N-ADJ-KC-N-PREP-N'],\n",
       " [['calcificação', 'mitral', 'e', 'aórtica', 'com', 'refluxo', 'leve'],\n",
       "  '-N-ADJ-KC-N-PREP-N-ADJ'],\n",
       " [['mitral', 'e'], '-ADJ-KC'],\n",
       " [['mitral', 'e', 'aórtica'], '-ADJ-KC-N'],\n",
       " [['mitral', 'e', 'aórtica', 'com'], '-ADJ-KC-N-PREP'],\n",
       " [['mitral', 'e', 'aórtica', 'com', 'refluxo'], '-ADJ-KC-N-PREP-N'],\n",
       " [['mitral', 'e', 'aórtica', 'com', 'refluxo', 'leve'],\n",
       "  '-ADJ-KC-N-PREP-N-ADJ'],\n",
       " [['e'], '-KC'],\n",
       " [['e', 'aórtica'], '-KC-N'],\n",
       " [['e', 'aórtica', 'com'], '-KC-N-PREP'],\n",
       " [['e', 'aórtica', 'com', 'refluxo'], '-KC-N-PREP-N'],\n",
       " [['e', 'aórtica', 'com', 'refluxo', 'leve'], '-KC-N-PREP-N-ADJ'],\n",
       " [['nos', 'MMII'], '-ART-N'],\n",
       " [['comprometimento', 'difuso', 'do'], '-N-N-ART'],\n",
       " [['comprometimento', 'difuso', 'do', 'VE', 'grau'], '-N-N-ART-N-N'],\n",
       " [['comprometimento', 'difuso', 'do', 'VE', 'grau', 'moderado'],\n",
       "  '-N-N-ART-N-N-N'],\n",
       " [['difuso', 'do', 'VE', 'grau', 'moderado'], '-N-ART-N-N-N'],\n",
       " [['do', 'VE'], '-ART-N'],\n",
       " [['do', 'VE', 'grau'], '-ART-N-N'],\n",
       " [['do', 'VE', 'grau', 'moderado'], '-ART-N-N-N'],\n",
       " [['fraqueza', 'intermitente', 'em'], '-N-N-PREP'],\n",
       " [['queixas', 'urinarias', 'e'], '-N-N-KC'],\n",
       " [['queixas', 'urinarias', 'e', 'gastrointestinais'], '-N-N-KC-N'],\n",
       " [['urinarias', 'e', 'gastrointestinais'], '-N-KC-N'],\n",
       " [['e'], '-KC'],\n",
       " [['e', 'gastrointestinais'], '-KC-N'],\n",
       " [['/'], '-PU']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulando_termos_postaggerTest[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Dispneia', 'importante', 'aos'], '-N-ADJ-ART'],\n",
       " [['importante', 'aos'], '-ADJ-ART'],\n",
       " [['importante', 'aos', 'esforços'], '-ADJ-ART-N'],\n",
       " [['aos', 'esforços'], '-ART-N'],\n",
       " [['dor', 'tipo', 'peso', 'no'], '-N-N-N-ART'],\n",
       " [['dor', 'tipo', 'peso', 'no', 'peito'], '-N-N-N-ART-N'],\n",
       " [['dor', 'tipo', 'peso', 'no', 'peito', 'no'], '-N-N-N-ART-N-ART'],\n",
       " [['tipo', 'peso', 'no'], '-N-N-ART'],\n",
       " [['tipo', 'peso', 'no', 'peito', 'no'], '-N-N-ART-N-ART'],\n",
       " [['tipo', 'peso', 'no', 'peito', 'no', 'esforço'], '-N-N-ART-N-ART-N'],\n",
       " [['peso', 'no', 'peito', 'no'], '-N-ART-N-ART'],\n",
       " [['no', 'peito'], '-ART-N'],\n",
       " [['no', 'peito', 'no'], '-ART-N-ART'],\n",
       " [['no', 'peito', 'no', 'esforço'], '-ART-N-ART-N'],\n",
       " [['no', 'esforço'], '-ART-N'],\n",
       " [['100'], '-NUM'],\n",
       " [['25'], '-NUM'],\n",
       " [['175'], '-NUM'],\n",
       " [['40'], '-NUM'],\n",
       " [['20'], '-NUM']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulando_termos_postaggerTrain[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 10626\n",
      "numTotalEntidadesTrain: 6578\n",
      "numTotalEntidadesDev: 1611\n",
      "numTotalEntidadesTest: 2437\n"
     ]
    }
   ],
   "source": [
    "gravarArquivosTreinamento('com_filtro',combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTotalEntidades: 8965\n",
      "numTotalEntidadesTrain: 5533\n",
      "numTotalEntidadesDev: 1389\n",
      "numTotalEntidadesTest: 2043\n"
     ]
    }
   ],
   "source": [
    "#OLD\n",
    "#gravarArquivosTreinamento('com_filtro',combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train--\n",
      "Com filtro-postagger\n",
      "Com taxa de Downsampling de  1\n",
      "key: 999\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 237\n",
      "len(combinacaoEntidadesAll:) 1319\n",
      "len(pulando_termos_postagger): 3925\n",
      "\n",
      "--Dev--\n",
      "Com filtro-postagger\n",
      "Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 89\n",
      "len(combinacaoEntidadesAll:) 416\n",
      "len(pulando_termos_postagger): 745\n",
      "\n",
      "--Test--\n",
      "Com filtro-postagger\n",
      "Com taxa de Downsampling de  1\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 107\n",
      "len(combinacaoEntidadesAll:) 506\n",
      "len(pulando_termos_postagger): 1183\n",
      "numTotalEntidades: 6664\n",
      "numTotalEntidadesTrain: 4055\n",
      "numTotalEntidadesDev: 1050\n",
      "numTotalEntidadesTest: 1559\n"
     ]
    }
   ],
   "source": [
    "# com downsampling\n",
    "print('--Train--')\n",
    "combinacaoEntidadesTrain, pulando_termos_postaggerTrain = getCombinacaoEntidades(dic_sentencesTrain, True, dicPosTagger, 1)\n",
    "print('\\n--Dev--')\n",
    "combinacaoEntidadesDev, pulando_termos_postaggerDev= getCombinacaoEntidades(dic_sentencesDev, True, dicPosTagger, 1)\n",
    "print('\\n--Test--')\n",
    "combinacaoEntidadesTest, pulando_termos_postaggerTest= getCombinacaoEntidades(dic_sentencesTest, True, dicPosTagger, 1)\n",
    "\n",
    "gravarArquivosTreinamento('com-filtro-downsampling',combinacaoEntidadesTrain, combinacaoEntidadesDev, combinacaoEntidadesTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, tratar descontinuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinacaoEntidadesAll_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16614"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinacaoEntidadesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTreinamento: 13291\n",
      "numTeste: 1661\n",
      "numTotalEntidades: 165571\n",
      "numTotalEntidadesTrain: 131376\n",
      "numTotalEntidadesDev: 16986\n",
      "numTotalEntidadesTest: 17209\n"
     ]
    }
   ],
   "source": [
    "# já ir gravando arquivos treinamento, test e dev...\n",
    "# pra fazer um teste sem descontinuas\n",
    "numTreinamento = len(combinacaoEntidadesAll)*0.8\n",
    "numTreinamento = int(numTreinamento)\n",
    "numTeste = (len(combinacaoEntidadesAll) - numTreinamento)/2\n",
    "numTeste = int(numTeste)\n",
    "numTotalEntidades=0\n",
    "numTotalEntidadesTrain=0\n",
    "numTotalEntidadesDev=0\n",
    "numTotalEntidadesTest=0\n",
    "\n",
    "print('numTreinamento:', numTreinamento)\n",
    "print('numTeste:', numTeste)\n",
    "\n",
    "f_train = open('genia.train', 'w')\n",
    "f_dev = open('genia.dev', 'w')\n",
    "f_test = open('genia.test', 'w')\n",
    "f_dev_entidades = open('genia_entidades.dev', 'w')\n",
    "f_test_entidades = open('genia_entidades.test', 'w')\n",
    "\n",
    "for i, combinacaoEntidades in enumerate(combinacaoEntidadesAll):\n",
    "    #print(dicSentences[i])\n",
    "    frase = combinacaoEntidades[0]\n",
    "    frases_entidade = combinacaoEntidades[1]\n",
    "    if i<=numTreinamento:\n",
    "        f_train.write(frase+'\\n')\n",
    "        for frase_entidade in frases_entidade:\n",
    "            f_train.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesTrain=numTotalEntidadesTrain+1\n",
    "    elif i <= numTreinamento + numTeste:\n",
    "        f_dev.write(frase+'\\n')\n",
    "        for frase_entidade in frases_entidade:\n",
    "            f_dev.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "            f_dev_entidades.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesDev=numTotalEntidadesDev+1\n",
    "    else:\n",
    "        f_test.write(frase+'\\n')\n",
    "        for frase_entidade in frases_entidade:\n",
    "            f_test.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "            f_test_entidades.write(frase_entidade[1]+'\\t'+frase_entidade[0]+'\\n')\n",
    "            numTotalEntidades=numTotalEntidades+1\n",
    "            numTotalEntidadesTest=numTotalEntidadesTest+1\n",
    "\n",
    "f_train.close()\n",
    "f_test.close()\n",
    "f_dev.close()\n",
    "f_test_entidades.close()\n",
    "f_dev_entidades.close()\n",
    "\n",
    "print('numTotalEntidades:', numTotalEntidades)\n",
    "print('numTotalEntidadesTrain:', numTotalEntidadesTrain)\n",
    "print('numTotalEntidadesDev:', numTotalEntidadesDev)\n",
    "print('numTotalEntidadesTest:', numTotalEntidadesTest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
