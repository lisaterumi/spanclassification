{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando arquivo para NER-NestedClinBr\n",
    "\n",
    "Teste com formato QA.. tem como retornar as entidades descontinuas tbm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTiposEntidade():\n",
    "    return ['Problema','Teste','Tratamento','Anatomia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceWhiteSpaces(str):\n",
    "    return re.sub('\\s{2,}',' ',str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(name, obj):\n",
    "    existeDir = os.path.exists('../obj')\n",
    "    if not existeDir:\n",
    "        os.makedirs('../obj')\n",
    "    with open('../obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    existeDir = os.path.exists('../obj')\n",
    "    if not existeDir:\n",
    "        os.makedirs('../obj')\n",
    "    try:\n",
    "        with open('../obj/' + name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastasCorpus = [r'corpus\\test',r'corpus\\train']\n",
    "#pastasCorpus = [r'corpus\\test']\n",
    "#pastasCorpus = [r'corpus\\TESTE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make the World a 2y4Better Place2y0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = 'Make the World a 2.4Better Place2.0'\n",
    "pattern = r'([0-9])\\.([0-9])'\n",
    "replacement = r'\\1y\\2'\n",
    "html = re.sub(pattern, replacement, s)\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicSentences(pastaCorpus):\n",
    "    #devePrintar=True\n",
    "    devePrintar=False\n",
    "    dic_sentences = {}\n",
    "    numMaxTokensPorFrase=0 # numero tokens da maior frase\n",
    "    num=0\n",
    "    listaEntidades=[]\n",
    "    frasesComDescontinuas=[]\n",
    "    for filename in os.listdir(pastaCorpus):\n",
    "        f = os.path.join(pastaCorpus, filename)\n",
    "        if os.path.isfile(f):\n",
    "            fileNameSemExtensao=os.path.splitext(filename)[0]\n",
    "            if devePrintar:\n",
    "                print('\\n\\n--fileName (sem extensao):--', fileNameSemExtensao)\n",
    "                pass\n",
    "            extension = os.path.splitext(filename)[1][1:]\n",
    "            if extension=='ann':\n",
    "                # tokens da frase\n",
    "                fileTxt = open(os.path.join(pastaCorpus, fileNameSemExtensao)+'.txt', \"r\", encoding='utf-8')\n",
    "                linha=fileTxt.readlines()\n",
    "                fileTxt.close()\n",
    "                if devePrintar:\n",
    "                    print('linha:', linha)\n",
    "                    pass\n",
    "                frases=[]\n",
    "                allFrasesString=''\n",
    "                numL=0\n",
    "                for l in linha:\n",
    "                    numL=numL+1\n",
    "                    allFrasesString = allFrasesString+l\n",
    "                    if numL==1: # descarta primeira frase, que é data de criação do doc\n",
    "                        #print('descartando frase:', l)\n",
    "                        continue\n",
    "                    if l.strip() and l.strip()!='\\n':\n",
    "                        #print('l:', l)\n",
    "                        pattern = r'([0-9])\\.([0-9])'\n",
    "                        replacement = r'\\1==\\2'\n",
    "                        novoL = re.sub(pattern, replacement, l.strip())\n",
    "                        l2 = novoL.split('.') # quebrando frases\n",
    "                        for l3 in l2:\n",
    "                            if l3.strip() and l3.strip()!='\\n':\n",
    "                                novaFrase = l3.replace('\\n','').replace('==','.').strip()+'.'\n",
    "                                frases.append(novaFrase)\n",
    "                #print('frases:', frases)\n",
    "                # para cada frase\n",
    "                # para tokenizar nesses tokens\n",
    "                #print('allFrasesString:', allFrasesString)\n",
    "                frasesTokens={}\n",
    "                #numCaracteresTotal=42 # primeira frase ignorada\n",
    "                numIndiceAnterior=0\n",
    "                for frase in frases:\n",
    "                    tokens=[]\n",
    "                    frase2 = frase.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                    frase2 = replaceWhiteSpaces(frase2)\n",
    "                    frase2 = frase2.split()\n",
    "                    for numtoken, token in enumerate(frase2):\n",
    "                        if devePrintar:\n",
    "                            print('token:', token)\n",
    "                            print('numIndiceAnterior:', numIndiceAnterior)\n",
    "                        if token!='.':\n",
    "                            numCaracteresTotal = allFrasesString.find(token, numIndiceAnterior, len(allFrasesString))\n",
    "                        else:\n",
    "                            numCaracteresTotal=numIndiceAnterior+1\n",
    "                        #tokens.append([token,numtoken])\n",
    "                        tokens.append([token,numtoken, numCaracteresTotal])\n",
    "                        numIndiceAnterior = numCaracteresTotal+len(token)-1\n",
    "                        if numMaxTokensPorFrase<len(tokens):\n",
    "                            numMaxTokensPorFrase = len(tokens)\n",
    "                    frasesTokens[frase]=tokens\n",
    "                    #linhaTokens=linha.copy()    \n",
    "                if devePrintar:\n",
    "                    print('frasesTokens:', frasesTokens)\n",
    "                # agora, as entidades\n",
    "                fileAnn = open(f, \"r\", encoding='utf-8')\n",
    "                linha=fileAnn.readlines()\n",
    "                fileAnn.close()\n",
    "\n",
    "                dicEntidades={}\n",
    "                for entidade_linha in linha:\n",
    "                    if ';' not in entidade_linha: # tem descontinua?\n",
    "                        entidade = entidade_linha.split('\\t')\n",
    "                        tipo_entidade = entidade[1]\n",
    "                        inicio, fim = tipo_entidade.split()[1:3]\n",
    "                        tipo_entidade = tipo_entidade.split()[0]\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        dicEntidades[(int(inicio), int(fim))]=[tipo_entidade, replaceWhiteSpaces(termos_entidade)]\n",
    "                    else:\n",
    "                        frasesComDescontinuas.append(num)\n",
    "                        #print('descontinua, linha: {}, num: {}'.format(linha, num))\n",
    "                        #print('descontinua, file: {}, num: {}'.format(filename, num))\n",
    "                        entidade = entidade_linha.split('\\t')\n",
    "                        # ex T10\tProblema 244 252;279 306\tdispneia aos mdoeardos-leves esforço\n",
    "                        #Problema 244 252;279 306\n",
    "                        entidade_temp=entidade[1].split(';')\n",
    "                        entidade1=entidade_temp[0]\n",
    "                        tipo_entidade = entidade1\n",
    "                        inicio1, fim1 = tipo_entidade.split()[1:3]\n",
    "                        tipo_entidade_string = tipo_entidade.split()[0]\n",
    "                        # mandar só os termos referentes...\n",
    "                        tamTermo1=int(fim1)-int(inicio1)\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade=termos_entidade[:tamTermo1]\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        #print('aaaaaaaaaaaaaaaaa')\n",
    "                        dicEntidades[(int(inicio1), int(fim1))]=[tipo_entidade_string, replaceWhiteSpaces(termos_entidade)]\n",
    "                        #print(\"(int(inicio1), int(fim1)):\", (int(inicio1), int(fim1)))\n",
    "                        #print(\"tipo_entidade_string, replaceWhiteSpaces(termos_entidade):\", tipo_entidade_string, replaceWhiteSpaces(termos_entidade))\n",
    "                        \n",
    "                        entidade2=entidade_temp[1]\n",
    "                        inicio2, fim2 = entidade2.split()[0:2]\n",
    "                        termos_entidade = entidade[2].replace('\\n','')\n",
    "                        termos_entidade=termos_entidade[tamTermo1:len(termos_entidade)]\n",
    "                        termos_entidade = termos_entidade.strip().replace('/',' / ').replace(')',' ) ').replace('(',' ( ').replace(']',' ] ').replace('[',' [ ').replace(',',' , ').replace('.',' . ').replace(';',' ; ').replace('-',' - ').replace('+',' + ').replace(\"'\",\" ' \").replace(\" = \",\" = \").replace(\"#\",\" # \").replace(\" $ \",\" $ \").replace(\" ! \",\" ! \").replace(\"?\",\" ? \").replace(\"%\",\" % \").replace(\":\",\" : \").replace(\">\",\" > \").replace(\"<\",\" < \")\n",
    "                        dicEntidades[(int(inicio2), int(fim2))]=[tipo_entidade_string, replaceWhiteSpaces(termos_entidade)]\n",
    "                        #print(\"(int(inicio2), int(fim2)):\", (int(inicio2), int(fim2)))\n",
    "                        #print(\"tipo_entidade_string, replaceWhiteSpaces(termos_entidade):\", tipo_entidade_string, replaceWhiteSpaces(termos_entidade))\n",
    "\n",
    "\n",
    "                #print('frasesTokens:', frasesTokens)\n",
    "                indicesDic = sorted(dicEntidades.keys(), key = lambda item: item[0])\n",
    "                listaIndicesJaUsados = []\n",
    "                #list_students.sort(key = lambda x: x[1])   #index 1 means second element\n",
    "                #print(indicesDic)\n",
    "                #print('dicEntidades:', dicEntidades)\n",
    "                \n",
    "                for key, value in frasesTokens.items():\n",
    "                    for i in indicesDic:\n",
    "                        tipo_entidade,termos_entidade = dicEntidades[i]\n",
    "                        ##key (i) = indices old a comparar\n",
    "                        #print('key:', key)\n",
    "                        #print('value:', value)\n",
    "                        #print('i:', i)\n",
    "                        for token in value:\n",
    "                            #print('token:', token)\n",
    "                            if i[0]==token[2]:\n",
    "                                novo_inicio, novo_fim = [token[1],token[1]+len(termos_entidade.split())]\n",
    "                                novos_indices=[]\n",
    "                                for k in range(novo_inicio,novo_fim):\n",
    "                                    novos_indices.append(k)\n",
    "                                listaEntidades.append([termos_entidade, novos_indices, tipo_entidade])\n",
    "                                #print(\"[termos_entidade, novos_indices, tipo_entidade]:\", [termos_entidade, novos_indices, tipo_entidade])\n",
    "                            else:\n",
    "                                #print('else, i[0]:',i[0])\n",
    "                                pass\n",
    "                        \n",
    "                    if len(value)>0:\n",
    "                        #print('incluindo:', key)\n",
    "                        dic_sentences[num]=[value, listaEntidades]\n",
    "                        listaEntidades=[]\n",
    "                        num=num+1 \n",
    "\n",
    "        #print(num)\n",
    "        #if num>318:\n",
    "        #    break\n",
    "\n",
    "        #if num>3:\n",
    "        #    break\n",
    "    print('numMaxTokensPorFrase:', numMaxTokensPorFrase)\n",
    "    return dic_sentences, frasesComDescontinuas\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numMaxTokensPorFrase: 146\n"
     ]
    }
   ],
   "source": [
    "dic_sentencesTest, frasesComDescontinuasTest = getDicSentences(pastasCorpus[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Paciente', 0, 43],\n",
       "  ['em', 1, 52],\n",
       "  ['tratamento', 2, 55],\n",
       "  ['para', 3, 66],\n",
       "  ['ICC', 4, 71],\n",
       "  ['diastólica', 5, 75],\n",
       "  ['há', 6, 86],\n",
       "  ['cerca', 7, 89],\n",
       "  ['de', 8, 95],\n",
       "  ['5', 9, 98],\n",
       "  ['a', 10, 100],\n",
       "  ['com', 11, 102],\n",
       "  ['melhora', 12, 106],\n",
       "  ['importante', 13, 114],\n",
       "  ['dos', 14, 125],\n",
       "  ['sintomas', 15, 129],\n",
       "  ['após', 16, 138],\n",
       "  ['início', 17, 143],\n",
       "  ['do', 18, 150],\n",
       "  ['tratamento', 19, 153],\n",
       "  ['.', 20, 163]],\n",
       " [['tratamento', [2], 'Tratamento'],\n",
       "  ['ICC diastólica', [4, 5], 'Problema'],\n",
       "  ['melhora importante dos sintomas após início do tratamento',\n",
       "   [12, 13, 14, 15, 16, 17, 18, 19],\n",
       "   'Problema'],\n",
       "  ['tratamento', [19], 'Tratamento']]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTest[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numMaxTokensPorFrase: 192\n"
     ]
    }
   ],
   "source": [
    "dic_sentencesTrain, frasesComDescontinuasTrain = getDicSentences(pastasCorpus[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Treinamento:-- corpus\\train\n",
      "numMaxTokensPorFrase: 192\n",
      "len(sentences): 1736\n",
      "len(Descontinuas): 91\n",
      "len(frasesComDescontinuas): 51\n",
      "--Teste:-- corpus\\test\n",
      "numMaxTokensPorFrase: 146\n",
      "len(sentences): 506\n",
      "len(Descontinuas): 44\n",
      "len(frasesComDescontinuas): 17\n"
     ]
    }
   ],
   "source": [
    "print('--Treinamento:--', pastasCorpus[1])\n",
    "dic_sentencesTrain, frasesComDescontinuasTrain = getDicSentences(pastasCorpus[1])\n",
    "print('len(sentences):', len(dic_sentencesTrain))\n",
    "print('len(Descontinuas):',len(frasesComDescontinuasTrain))\n",
    "print('len(frasesComDescontinuas):',len(set(frasesComDescontinuasTrain)))\n",
    "\n",
    "\n",
    "print('--Teste:--', pastasCorpus[0])\n",
    "dic_sentencesTest, frasesComDescontinuasTest = getDicSentences(pastasCorpus[0])\n",
    "print('len(sentences):', len(dic_sentencesTest))\n",
    "print('len(Descontinuas):',len(frasesComDescontinuasTest))\n",
    "print('len(frasesComDescontinuas):',len(set(frasesComDescontinuasTest)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Abd', 0, 644],\n",
       "  ['globoso', 1, 648],\n",
       "  [',', 2, 655],\n",
       "  ['flacido', 3, 657],\n",
       "  [',', 4, 664],\n",
       "  ['indolor', 5, 666],\n",
       "  ['a', 6, 674],\n",
       "  ['palpacao', 7, 676],\n",
       "  [',', 8, 684],\n",
       "  ['sem', 9, 686],\n",
       "  ['VCM', 10, 690],\n",
       "  ['.', 11, 693]],\n",
       " [['Abd', [0], 'Anatomia'], ['VCM', [10], 'Problema']]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTest[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['CONTRAÇÃO', 0, 507],\n",
       "  ['SEGMENTAR', 1, 517],\n",
       "  ['DO', 2, 527],\n",
       "  ['VE', 3, 530],\n",
       "  ['ALTERADA', 4, 533],\n",
       "  ['.', 5, 541]],\n",
       " [['CONTRAÇÃO SEGMENTAR DO VE ALTERADA', [0, 1, 2, 3, 4], 'Problema'],\n",
       "  ['VE', [3], 'Anatomia']]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTrain[861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 15, 30, 30, 30, 30, 55, 55, 65, 65]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frasesComDescontinuasTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# frases com entidades descontinuas\n",
    "print(len(set(frasesComDescontinuasTrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 49,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 91,\n",
       " 131,\n",
       " 147,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 227,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 241,\n",
       " 263,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 316,\n",
       " 329,\n",
       " 367,\n",
       " 367,\n",
       " 367,\n",
       " 367,\n",
       " 406,\n",
       " 468]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frasesComDescontinuasTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Comorbidades', 0, 142], [':', 1, 154], ['DM', 2, 156], ['há', 3, 159], ['10', 4, 162], ['anos', 5, 165], ['em', 6, 170], ['uso', 7, 173], ['de', 8, 177], ['metformina', 9, 180], ['850mg', 10, 191], ['3', 11, 197], ['cp', 12, 199], ['/', 13, 201], ['dia', 14, 202], [',', 15, 205], ['acarbose', 16, 207], ['1', 17, 216], ['cp', 18, 218], ['/', 19, 220], ['dia', 20, 221], ['e', 21, 225], ['glicazida', 22, 227], ['60mg', 23, 237], ['2', 24, 242], ['cp', 25, 244], ['/', 26, 246], ['dia', 27, 247], ['e', 28, 251], ['insulina', 29, 253], ['(', 30, 262], ['24', 31, 263], ['-', 32, 266], ['0', 33, 268], ['-', 34, 270], ['24', 35, 272], [')', 36, 274], ['.', 37, 275]], [['Comorbidades', [0], 'Problema'], ['DM', [2], 'Problema'], ['metformina 850mg', [9, 10], 'Tratamento'], ['acarbose', [16], 'Tratamento'], ['glicazida 60mg', [22, 23], 'Tratamento'], ['insulina', [29], 'Tratamento']]]\n"
     ]
    }
   ],
   "source": [
    "print(dic_sentencesTest[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanhoTrain 1319\n",
      "tamanhoDev 417\n",
      "len(dic_sentencesTrain): 1319\n",
      "len(dic_sentencesDev): 416\n",
      "[[['Paciente', 0, 151], ['relata', 1, 160], ['apenas', 2, 167], ['um', 3, 174], ['episodio', 4, 177], ['no', 5, 186], ['momento', 6, 189], ['de', 7, 197], ['gripe', 8, 200], ['.', 9, 205]], [['gripe', [8], 'Problema']]]\n",
      "[[['HAS', 0, 207], [',', 1, 210], ['ICC', 2, 212], [',', 3, 215], ['nega', 4, 217], ['DM', 5, 222], ['.', 6, 224]], [['HAS', [0], 'Problema'], ['ICC', [2], 'Problema'], ['DM', [5], 'Problema']]]\n"
     ]
    }
   ],
   "source": [
    "save_obj('dic_sentencesTrainDev',dic_sentencesTrain)\n",
    "porc=0.76\n",
    "tamanhoTotal = len(dic_sentencesTrain)\n",
    "tamanhoTrain = int(tamanhoTotal*porc)\n",
    "print('tamanhoTrain', tamanhoTrain)\n",
    "tamanhoDev = tamanhoTotal - tamanhoTrain\n",
    "print('tamanhoDev', tamanhoDev)\n",
    "dic_sentencesDev_temp = {k: dic_sentencesTrain[k] for k in list(dic_sentencesTrain)[tamanhoTrain:-1]}\n",
    "dic_sentencesTrain = {k: dic_sentencesTrain[k] for k in list(dic_sentencesTrain)[:tamanhoTrain]}\n",
    "num=0\n",
    "dic_sentencesDev = {}\n",
    "for key, value in dic_sentencesDev_temp.items():\n",
    "    dic_sentencesDev[num] = value\n",
    "    num=num+1\n",
    "\n",
    "print('len(dic_sentencesTrain):', len(dic_sentencesTrain))\n",
    "print('len(dic_sentencesDev):', len(dic_sentencesDev))\n",
    "print(dic_sentencesTrain[tamanhoTrain-1])\n",
    "print(dic_sentencesDev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', 0, 207],\n",
       "  [',', 1, 210],\n",
       "  ['ICC', 2, 212],\n",
       "  [',', 3, 215],\n",
       "  ['nega', 4, 217],\n",
       "  ['DM', 5, 222],\n",
       "  ['.', 6, 224]],\n",
       " [['HAS', [0], 'Problema'], ['ICC', [2], 'Problema'], ['DM', [5], 'Problema']]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesDev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['carvedilol', 0, 226],\n",
       "  ['1', 1, 237],\n",
       "  ['cp', 2, 239],\n",
       "  ['12', 3, 242],\n",
       "  ['/', 4, 244],\n",
       "  ['12', 5, 245],\n",
       "  [',', 6, 247],\n",
       "  ['furosemida', 7, 249],\n",
       "  ['20mg', 8, 260],\n",
       "  ['2', 9, 265],\n",
       "  ['cp', 10, 267],\n",
       "  ['de', 11, 270],\n",
       "  ['12', 12, 273],\n",
       "  ['/', 13, 275],\n",
       "  ['12', 14, 276],\n",
       "  [',', 15, 278],\n",
       "  ['sinvastatina', 16, 280],\n",
       "  ['1cp', 17, 293],\n",
       "  ['a', 18, 297],\n",
       "  ['noite', 19, 299],\n",
       "  [',', 20, 304],\n",
       "  ['AAS', 21, 306],\n",
       "  ['100mg', 22, 310],\n",
       "  ['apos', 23, 316],\n",
       "  ['almoço', 24, 321],\n",
       "  ['e', 25, 328],\n",
       "  ['Omeprazol', 26, 330],\n",
       "  ['20mg', 27, 340],\n",
       "  ['1', 28, 345],\n",
       "  ['xdia', 29, 347],\n",
       "  ['.', 30, 351]],\n",
       " [['carvedilol', [0], 'Tratamento'],\n",
       "  ['furosemida 20mg', [7, 8], 'Tratamento'],\n",
       "  ['sinvastatina', [16], 'Tratamento'],\n",
       "  ['AAS 100mg', [21, 22], 'Tratamento'],\n",
       "  ['Omeprazol 20mg', [26, 27], 'Tratamento']]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesDev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[280]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i[2] for i in dic_sentencesDev[1][0] if i[1]==16]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i[0]) for i in dic_sentencesDev[1][0] if i[1]==1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravaArquivoQA(dic_sentencesTest, name):\n",
    "    tipos= ['Problema','Teste','Tratamento','Anatomia']\n",
    "\n",
    "    texto='{\"data\": ['\n",
    "    # title\n",
    "    # paragraphs\n",
    "        #context, qas (answers (answer_start_original, text_original)), question (id, question_original)\n",
    "    for i in range(len(dic_sentencesTest)):\n",
    "        ents = dic_sentencesTest[i][1]\n",
    "\n",
    "        listaEntidadesProblema=list()\n",
    "        listaEntidadesTeste=list()\n",
    "        listaEntidadesTratamento=list()\n",
    "        listaEntidadesAnatomia=list()\n",
    "\n",
    "\n",
    "        #print(contexto)\n",
    "        for entidade in ents:\n",
    "            if entidade[2] == 'Problema':\n",
    "                listaEntidadesProblema.append(entidade)\n",
    "            elif entidade[2] == 'Teste':\n",
    "                listaEntidadesTeste.append(entidade)\n",
    "            elif entidade[2] == 'Tratamento':\n",
    "                listaEntidadesTratamento.append(entidade)\n",
    "            elif entidade[2] == 'Anatomia':\n",
    "                listaEntidadesAnatomia.append(entidade)\n",
    "\n",
    "        if len(listaEntidadesProblema)==0 and len(listaEntidadesTeste)==0 and len(listaEntidadesTratamento)==0 and len(listaEntidadesAnatomia)==0:\n",
    "            continue\n",
    "\n",
    "        title='texto_'+str(i)\n",
    "        texto = texto+'{\"title\":'+title+'\",\"paragraphs\": [{\"context\": \"'\n",
    "\n",
    "        tokens = dic_sentencesTest[i][0]\n",
    "        frase=[t[0] for t in tokens]\n",
    "        contexto = ' '.join(frase)\n",
    "        texto = texto+contexto+'\", \"qas\": [{\"answers\": ['\n",
    "\n",
    "\n",
    "        if len(listaEntidadesProblema)>0:\n",
    "            for entidade in listaEntidadesProblema:\n",
    "                texto = texto+'{\"answer_start\":'\n",
    "                indices = entidade[1]\n",
    "                start =indices[0]\n",
    "                fim = indices[-1]\n",
    "                start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "                fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "                fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "                texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "            texto = texto+' \"question\": \"Problema\"},'\n",
    "\n",
    "        if len(listaEntidadesTeste)>0:\n",
    "\n",
    "            texto = texto+'{\"answers\": ['\n",
    "            for entidade in listaEntidadesTeste:\n",
    "                texto = texto+'{\"answer_start\":'\n",
    "                indices = entidade[1]\n",
    "                start =indices[0]\n",
    "                fim = indices[-1]\n",
    "                try:\n",
    "                    start_string = [j[2] for j in dic_sentencesTest[i][0] if j[1]==start][0]\n",
    "                except:\n",
    "                    print()\n",
    "                    raise\n",
    "                fim_string = [j[2] for j in dic_sentencesTest[i][0] if j[1]==fim][0]\n",
    "                fim_string = fim_string+[len(j[0]) for j in dic_sentencesTest[i][0] if j[1]==fim][0]\n",
    "\n",
    "                texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "            texto = texto+' \"question\": \"Teste\"},'\n",
    "\n",
    "        if len(listaEntidadesTratamento)>0:\n",
    "\n",
    "            texto = texto+'{\"answers\": ['\n",
    "            for entidade in listaEntidadesTratamento:\n",
    "                texto = texto+'{\"answer_start\":'\n",
    "                indices = entidade[1]\n",
    "                start =indices[0]\n",
    "                fim = indices[-1]\n",
    "                start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "                fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "                fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "                texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "            texto = texto+' \"question\": \"Tratamento\"},'\n",
    "\n",
    "        if len(listaEntidadesAnatomia)>0:\n",
    "\n",
    "            texto = texto+'{\"answers\": ['\n",
    "            for entidade in listaEntidadesAnatomia:\n",
    "                texto = texto+'{\"answer_start\":'\n",
    "                indices = entidade[1]\n",
    "                start =indices[0]\n",
    "                fim = indices[-1]\n",
    "                start_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==start][0]\n",
    "                fim_string = [i[2] for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "                fim_string = fim_string+[len(i[0]) for i in dic_sentencesTest[i][0] if i[1]==fim][0]\n",
    "\n",
    "                texto = texto+str(start_string)+', \"text\": \"'+entidade[0]+'\"},'\n",
    "\n",
    "            texto = texto+' \"question\": \"Anatomia\"},'\n",
    "\n",
    "    arq = open(name, 'w')\n",
    "    arq.write(texto)\n",
    "    arq.close()\n",
    "    #print(texto)\n",
    "  \n",
    "gravaArquivoQA(dic_sentencesTest, 'data_qa/nested_test.json')\n",
    "gravaArquivoQA(dic_sentencesTrain, 'data_qa/nested_train.json')\n",
    "gravaArquivoQA(dic_sentencesDev, 'data_qa/nested_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
