{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "# ver qtos o modelo apenas de ner acertaria\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import nltk    \n",
    "from nltk import tokenize \n",
    "import torch\n",
    "from transformers import BertTokenizer,BertForTokenClassification\n",
    "import numpy as np\n",
    "import json   \n",
    "from importlib import reload  # Python 3.4+\n",
    "import random\n",
    "import model as mod\n",
    "from model import BertForChunkClassification\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload \n",
    "#from eval import predict\n",
    "import eval\n",
    "#import importlib\n",
    "#importlib.reload(module)\n",
    "import dataset\n",
    "from dataset import InputFeatures, load_and_cache_examples\n",
    "import functionsAval as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\n"
     ]
    }
   ],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n",
    "reload(mod)\n",
    "\n",
    "# em numero de frases\n",
    "BATCH=100\n",
    "#BATCH=5\n",
    "#BATCH=800\n",
    "#BATCH=8000 \n",
    "print('BATCH:', BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegando sentencas de teste gabarito: dic_sentencesTest.pkl\n",
      "506\n",
      "[[['Lucas', 0, 43], [',', 1, 48], ['74', 2, 50], ['anos', 3, 53], ['.', 4, 57]], []]\n",
      "numero de sentencas no total: 100\n",
      "idx2tag: {0: 'Teste', 1: 'Anatomia', 2: 'O', 3: 'Problema', 4: 'Tratamento', 5: '<pad>'}\n",
      "len(dic_predictions): 100\n",
      "verificando dados:\n",
      "len(dicSentences_new_test): 100\n",
      "len(dic_predictions): 100\n",
      "region_pred_list[:4]: ['Problema', 'Tratamento', 'Problema', 'Problema']\n",
      "region_true_list[:4]: ['Problema', 'Tratamento', 'Problema', 'Problema']\n",
      "lista_erros[:8]: [7, 8, 13, 13, 14, 15, 15, 15]\n",
      "len(lista_erros): 114\n",
      "len(set(lista_erros)): 45\n",
      "len(region_true_list): 352\n",
      "len(region_pred_list): 352\n",
      "-----Avaliando só modelo de NER:-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.789474  0.277778  0.410959        54\n",
      "           O   0.000000  0.000000  0.000000        38\n",
      "    Problema   0.853211  0.823009  0.837838       113\n",
      "       Teste   0.880952  0.891566  0.886228        83\n",
      "  Tratamento   0.828125  0.828125  0.828125        64\n",
      "\n",
      "    accuracy                       0.667614       352\n",
      "   macro avg   0.670352  0.564096  0.592630       352\n",
      "weighted avg   0.753305  0.667614  0.691546       352\n",
      "\n",
      "[[15 36  1  1  1]\n",
      " [ 4  0 15  9 10]\n",
      " [ 0 20 93  0  0]\n",
      " [ 0  9  0 74  0]\n",
      " [ 0 11  0  0 53]]\n"
     ]
    }
   ],
   "source": [
    "dicSentences_new_test = f.loadSentencesTest()\n",
    "print(len(dicSentences_new_test))\n",
    "dicSentences_new_test = {k: v for k, v in dicSentences_new_test.items() if k<BATCH}\n",
    "print(dicSentences_new_test[0])\n",
    "#print(dicSentences_new_test[27])\n",
    "print('numero de sentencas no total:', len(dicSentences_new_test))\n",
    "\n",
    "sentences=list()\n",
    "for key, value in dicSentences_new_test.items():\n",
    "    if key<BATCH:\n",
    "        tokens = value[0]\n",
    "        tokens = [tok[0] for tok in tokens]\n",
    "        sentences.append(' '.join(tokens).strip())\n",
    "#print(sentences[0])\n",
    "\n",
    "tags, tokens = f.predictBERTNER_IO(sentences, 'all')\n",
    "dic_predictions = f.getDicPredictions(tags, tokens)\n",
    "#print(dic_predictions[0])\n",
    "print('len(dic_predictions):', len(dic_predictions))\n",
    "#print(dic_predictions[9])\n",
    "f.save_obj('dic_predictions_results_ner_'+str(BATCH), dic_predictions)\n",
    "#dic_predictions = f.load_obj('dic_predictions_results_ner_'+str(BATCH))\n",
    "print('verificando dados:')\n",
    "#for key, value in dic_predictions.items():\n",
    "#    print('key:',key)\n",
    "#    print(dic_predictions[key])\n",
    "#    if key>2:\n",
    "#        break\n",
    "        \n",
    "print('len(dicSentences_new_test):', len(dicSentences_new_test))\n",
    "print('len(dic_predictions):', len(dic_predictions))\n",
    "\n",
    "region_true_list, region_pred_list, lista_erros = f.getListaRegionsTruePred(BATCH, dicSentences_new_test, dic_predictions)\n",
    "f.save_obj('region_true_list'+str(BATCH), region_true_list)\n",
    "print('region_pred_list[:4]:', region_pred_list[:4])\n",
    "print('region_true_list[:4]:', region_true_list[:4])\n",
    "print('lista_erros[:8]:', lista_erros[:8])\n",
    "print('len(lista_erros):', len(lista_erros))\n",
    "print('len(set(lista_erros)):', len(set(lista_erros)))\n",
    "#print(dic_predictions[8])\n",
    "#print(dicSentences_new_test[8][1])\n",
    "print('len(region_true_list):', len(region_true_list))\n",
    "print('len(region_pred_list):', len(region_pred_list))\n",
    "#print('pred:',region_pred_list[:15])\n",
    "#print('true:',region_true_list[:15])\n",
    "\n",
    "print('-----Avaliando só modelo de NER:-----')\n",
    "\n",
    "print(classification_report(region_true_list, region_pred_list, digits=6))\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando modelo de sentence-pais\n",
    "#### primeiro sozinho...\n",
    "1) Com filtro + downsampling\n",
    "\n",
    "2) Com filtro\n",
    "\n",
    "3) Só positivos (dai preciso de um CRF pro filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando só com modelo de Sentence Pairs:-----\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "print('-----Avaliando só com modelo de Sentence Pairs:-----')\n",
    "model = ClassificationModel('bert', 'lisaterumi/sentence_pairs_nested_filtro_downsampling', use_cuda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[0,0]\n",
    "[num for num in range(a[0], a[1]+1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = reload(f)\n",
    "#combinacaoEntidadesAll = f.getCombinacaoEntidadesSentence(dic_predictions, True, dicPosTagger, 0, lista_postaggers_entidades)\n",
    "#combinacaoEntidadesAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de sentenças de test: 1,913\n",
      "\n",
      "         text_b                                             text_a  labels\n",
      "0   marevan 5mg  Em acompanhamento no ambualtorio há 5 anos por...       2\n",
      "1       marevan  Em acompanhamento no ambualtorio há 5 anos por...       0\n",
      "2  Comorbidades  Comorbidades : DM há 10 anos em uso de metform...       1\n",
      "Primeiro, com filtro postagger:\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 14\n",
      "len(combinacaoEntidadesAll:) 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"..\\preProcessamento\\sentence-pairs-filtro\\sentence_pairs.test\", delimiter='\\t', header=0, names=['text_b', 'text_a', 'labels'])\n",
    "df = df.dropna(axis=0, how='any')\n",
    "print('Número de sentenças de test: {:,}\\n'.format(df.shape[0]))\n",
    "#df=df[:50]\n",
    "test_df = df\n",
    "print(test_df[:3])\n",
    "lista=list()\n",
    "#for index, row in test_df.iterrows():\n",
    "#    lista.append([row['text_b'], row['text_a']])\n",
    "#predictions, raw_outputs = model.predict(\n",
    "#  lista\n",
    "#)\n",
    "dic_sentencesTrainDev = f.load_obj('dic_sentencesTrainDev')\n",
    "dicPosTagger, _ = f.getDicPosTagger(dic_sentencesTrainDev)\n",
    "lista_postaggers_entidades = f.getListaPostaggerEntidades(dic_predictions, dicPosTagger)\n",
    "# para gerar arquivo de predicoes (com as tags <e1>)\n",
    "print('Primeiro, com filtro postagger:')\n",
    "combinacaoEntidadesAll = f.getCombinacaoEntidadesSentence(dic_predictions, True, dicPosTagger, 0, lista_postaggers_entidades)\n",
    "f.save_obj('combinacaoEntidadesAllSentence_'+str(BATCH), combinacaoEntidadesAll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# para suprimir output\n",
    "#combinacaoEntidadesAll = f.load_obj('combinacaoEntidadesAll_'+str(BATCH))\n",
    "print('Chamando predict')\n",
    "pred_region_labels = list()\n",
    "for key, combinacao in enumerate(combinacaoEntidadesAll):\n",
    "    if key<BATCH:    \n",
    "        if len(combinacao)>0:\n",
    "            lista = [l[0:2] for l in combinacao]\n",
    "            predictions, _ = model.predict(lista) \n",
    "            pred_region_labels.append(predictions)\n",
    "            for comb, label in zip(combinacao, predictions):\n",
    "                comb.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "pred_region_labels2 = list()\n",
    "for a in pred_region_labels:\n",
    "    for b in a:\n",
    "        pred_region_labels2.append(labels[b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problema', 'Tratamento', 'Tratamento', 'Problema', 'Problema', 'Tratamento', 'Tratamento', 'Tratamento', 'Tratamento', 'O']\n",
      "['Problema', 'Tratamento', 'Problema', 'Problema', 'Tratamento', 'Tratamento', 'Tratamento', 'Tratamento', 'Problema', 'Tratamento']\n",
      "564\n",
      "352\n"
     ]
    }
   ],
   "source": [
    "print(pred_region_labels2[:10])\n",
    "print(region_true_list[:10])\n",
    "print(len(pred_region_labels2))\n",
    "print(len(region_true_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', 0],\n",
       "  ['há', 1],\n",
       "  ['15', 2],\n",
       "  ['anos', 3],\n",
       "  ['em', 4],\n",
       "  ['uso', 5],\n",
       "  ['de', 6],\n",
       "  ['losartana', 7],\n",
       "  ['50mg', 8],\n",
       "  ['/', 9],\n",
       "  ['dia', 10],\n",
       "  ['e', 11],\n",
       "  ['digoxina', 12],\n",
       "  ['1', 13],\n",
       "  ['/', 14],\n",
       "  ['2', 15],\n",
       "  ['cp', 16],\n",
       "  ['/', 17],\n",
       "  ['dia', 18],\n",
       "  [',', 19],\n",
       "  ['carvedilol', 20],\n",
       "  ['25', 21],\n",
       "  ['12', 22],\n",
       "  ['/', 23],\n",
       "  ['12', 24],\n",
       "  [',', 25],\n",
       "  ['HCTZ', 26],\n",
       "  ['.', 27]],\n",
       " [['HAS', [0], 'Problema'],\n",
       "  ['losartana 50mg', [7, 8], 'Tratamento'],\n",
       "  ['digoxina', [12], 'Tratamento'],\n",
       "  ['carvedilol 25', [20, 21], 'Tratamento'],\n",
       "  ['HCTZ', [26], 'Tratamento']]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicPredictionsSentence(combinacaoEntidadesAll_pred, dic_predictions):\n",
    "    labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "    num=-1\n",
    "    dic_predictions_sentence={}\n",
    "    entidades=list()\n",
    "    numAcrescentou=0\n",
    "    for frases in combinacaoEntidadesAll_pred:\n",
    "        num=num+1\n",
    "        for valor in frases:\n",
    "            #print('num:', num)\n",
    "            #print('valor:', valor)\n",
    "            #print('valor[1]:', valor[1])\n",
    "            tokens_entidade = valor[0]\n",
    "            #frase = valor[1]\n",
    "            indices = valor[2]\n",
    "            tipo_previsto=valor[4]\n",
    "            #print('tokens_entidade:', tokens_entidade)\n",
    "            #print('frase:', frase)\n",
    "            #print('indices:', indices)\n",
    "            #print('tipo_previsto:', tipo_previsto)\n",
    "            entidades.append([tokens_entidade, indices, labels[tipo_previsto]])\n",
    "            # ver se entidade está na dic_prediction\n",
    "        frase = dic_predictions[num].copy()[0]\n",
    "        dic_predictions_sentence[num] = [frase, entidades]\n",
    "        entidades = list()\n",
    "                     \n",
    "    return dic_predictions_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', 0],\n",
       "  ['há', 1],\n",
       "  ['15', 2],\n",
       "  ['anos', 3],\n",
       "  ['em', 4],\n",
       "  ['uso', 5],\n",
       "  ['de', 6],\n",
       "  ['losartana', 7],\n",
       "  ['50mg', 8],\n",
       "  ['/', 9],\n",
       "  ['dia', 10],\n",
       "  ['e', 11],\n",
       "  ['digoxina', 12],\n",
       "  ['1', 13],\n",
       "  ['/', 14],\n",
       "  ['2', 15],\n",
       "  ['cp', 16],\n",
       "  ['/', 17],\n",
       "  ['dia', 18],\n",
       "  [',', 19],\n",
       "  ['carvedilol', 20],\n",
       "  ['25', 21],\n",
       "  ['12', 22],\n",
       "  ['/', 23],\n",
       "  ['12', 24],\n",
       "  [',', 25],\n",
       "  ['HCTZ', 26],\n",
       "  ['.', 27]],\n",
       " [['HAS', [0], 'Problema'],\n",
       "  ['losartana 50mg', [7, 8], 'Tratamento'],\n",
       "  ['digoxina', [12], 'Tratamento'],\n",
       "  ['carvedilol 25', [20, 21], 'Tratamento'],\n",
       "  ['HCTZ', [26], 'Tratamento'],\n",
       "  ['losartana', [7], 'O'],\n",
       "  ['carvedilol', [20], 'O']]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_sentence = getDicPredictionsSentence(combinacaoEntidadesAll, dic_predictions)\n",
    "dic_predictions_sentence[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando (Região):-----\n",
      "numErro1: 38\n",
      "numErro2: 288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.829268  0.629630  0.715789        54\n",
      "           O   0.668675  0.385417  0.488987       288\n",
      "    Problema   0.411765  0.743363  0.529968       113\n",
      "       Teste   0.831461  0.891566  0.860465        83\n",
      "  Tratamento   0.578431  0.921875  0.710843        64\n",
      "\n",
      "    accuracy                       0.601329       602\n",
      "   macro avg   0.663920  0.714370  0.661211       602\n",
      "weighted avg   0.647706  0.601329  0.591827       602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avaliar por regiao.. \n",
    "print('-----Avaliando modelo com filtro + downsampling (Região):-----')\n",
    "\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_sentence, BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avaliar por regiao.. \n",
    "print('-----Avaliando modelo com filtro (Região):-----')\n",
    "\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_sentence, BATCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
