{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "# ver qtos o modelo apenas de ner acertaria\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import nltk    \n",
    "from nltk import tokenize \n",
    "import torch\n",
    "from transformers import BertTokenizer,BertForTokenClassification\n",
    "import numpy as np\n",
    "import json   \n",
    "from importlib import reload  # Python 3.4+\n",
    "import random\n",
    "from model import BertForChunkClassification\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload \n",
    "#from eval import predict\n",
    "import eval\n",
    "#import importlib\n",
    "#importlib.reload(module)\n",
    "from dataset import InputFeatures, load_and_cache_examples\n",
    "import dataset\n",
    "import functionsAval as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval' from 'C:\\\\Users\\\\lisat\\\\OneDrive\\\\jupyter notebook\\\\spanclassification\\\\avaliacao\\\\eval.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 800\n",
      "Pegando sentencas de teste gabarito: dic_sentencesTest.pkl\n",
      "506\n",
      "[[['Nega', 0, 422], ['sincope', 1, 427], ['.', 2, 434]], [['sincope', [1], 'Problema']]]\n",
      "numero de sentencas no total: 506\n"
     ]
    }
   ],
   "source": [
    "# em numero de frases\n",
    "#BATCH=30\n",
    "#BATCH=100 \n",
    "BATCH=800\n",
    "#BATCH=8000 \n",
    "print('BATCH:', BATCH)\n",
    "\n",
    "dicSentences_new_test = f.loadSentencesTest()\n",
    "print(len(dicSentences_new_test))\n",
    "dicSentences_new_test = {k: v for k, v in dicSentences_new_test.items() if k<=BATCH}\n",
    "#print(dicSentences_new_test[0])\n",
    "print(dicSentences_new_test[27])\n",
    "print('numero de sentencas no total:', len(dicSentences_new_test))\n",
    "\n",
    "\n",
    "sentences=list()\n",
    "for key, value in dicSentences_new_test.items():\n",
    "    if key<BATCH:\n",
    "        tokens = value[0]\n",
    "        tokens = [tok[0] for tok in tokens]\n",
    "        sentences.append(' '.join(tokens).strip())\n",
    "#print(sentences[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx2tag: {0: 'O', 1: 'Anatomia', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'Problema', 1: 'O', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'O', 1: 'Tratamento', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'O', 1: 'Teste', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n"
     ]
    }
   ],
   "source": [
    "tipos_entidade = ['Anatomia','Problema','Tratamento','Teste']\n",
    "#tipos_entidade = ['Anatomia']\n",
    "all_predictions = list()\n",
    "for tipo_entidade in tipos_entidade:\n",
    "    tags, tokens = f.predictBERTNER_IO(sentences, tipo_entidade)\n",
    "    dic_predictions = f.getDicPredictions(tags, tokens)\n",
    "    print(dic_predictions[0])\n",
    "    print('len(dic_predictions):', len(dic_predictions))\n",
    "    all_predictions.append(dic_predictions)\n",
    "    #f.save_obj('dic_predictions_io_bkp', dic_predictions)\n",
    "#dic_predictions = load_obj('dic_predictions_io_bkp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Abd', 0],\n",
       "  ['globoso', 1],\n",
       "  [',', 2],\n",
       "  ['flacido', 3],\n",
       "  [',', 4],\n",
       "  ['indolor', 5],\n",
       "  ['a', 6],\n",
       "  ['palpacao', 7],\n",
       "  [',', 8],\n",
       "  ['sem', 9],\n",
       "  ['VCM', 10],\n",
       "  ['.', 11]],\n",
       " [[['Abd'], [0], 'Anatomia']]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_obj('all_predictions_results_binarios_'+str(BATCH), all_predictions)\n",
    "#all_predictions = f.load_obj('all_predictions_results_binarios_batch_'+str(BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntar all_predictions\n",
    "dic_predictions = {}\n",
    "for num, prediction in enumerate(all_predictions):\n",
    "    if num==0:\n",
    "        dic_predictions = prediction.copy()\n",
    "        continue\n",
    "    for key, value in prediction.items():\n",
    "        entidadesJaEstavam=dic_predictions[key][1]\n",
    "        tokens=dic_predictions[key][0]\n",
    "        lista_entidade = [e for e in entidadesJaEstavam]\n",
    "        #print('lista_entidade:', lista_entidade)\n",
    "        entidades = value[1].copy()\n",
    "        if len(entidades)>0:\n",
    "            #print(entidades)\n",
    "            for entidade in entidades:\n",
    "                lista_entidade.append(entidade)\n",
    "            dic_predictions[key]=[tokens,lista_entidade]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "key: 1\n",
      "[[['Em', 0], ['acompanhamento', 1], ['no', 2], ['ambualtorio', 3], ['há', 4], ['5', 5], ['anos', 6], ['por', 7], ['FA', 8], [',', 9], ['uso', 10], ['de', 11], ['marevan', 12], ['5mg', 13], ['1', 14], ['x', 15], ['ao', 16], ['dia', 17], ['.', 18]], [[['FA'], [8], 'Problema'], [['marevan', '5mg'], [12, 13], 'Tratamento']]]\n",
      "key: 2\n",
      "[[['Comorbidades', 0], [':', 1], ['DM', 2], ['há', 3], ['10', 4], ['anos', 5], ['em', 6], ['uso', 7], ['de', 8], ['metformina', 9], ['850mg', 10], ['3', 11], ['cp', 12], ['/', 13], ['dia', 14], [',', 15], ['acarbose', 16], ['1', 17], ['cp', 18], ['/', 19], ['dia', 20], ['e', 21], ['glicazida', 22], ['60mg', 23], ['2', 24], ['cp', 25], ['/', 26], ['dia', 27], ['e', 28], ['insulina', 29], ['(', 30], ['24', 31], ['-', 32], ['0', 33], ['-', 34], ['24', 35], [')', 36], ['.', 37]], [[['Comorbidades'], [0], 'Problema'], [['DM'], [2], 'Problema'], [['metformina', '850mg'], [9, 10], 'Tratamento'], [['acarbose'], [16], 'Tratamento'], [['glicazida', '60mg'], [22, 23], 'Tratamento'], [['insulina'], [29], 'Tratamento']]]\n",
      "key: 3\n",
      "[[['HAS', 0], ['há', 1], ['15', 2], ['anos', 3], ['em', 4], ['uso', 5], ['de', 6], ['losartana', 7], ['50mg', 8], ['/', 9], ['dia', 10], ['e', 11], ['digoxina', 12], ['1', 13], ['/', 14], ['2', 15], ['cp', 16], ['/', 17], ['dia', 18], [',', 19], ['carvedilol', 20], ['25', 21], ['12', 22], ['/', 23], ['12', 24], [',', 25], ['HCTZ', 26], ['.', 27]], [[['HAS'], [0], 'Problema'], [['losartana', '50mg'], [7, 8], 'Tratamento'], [['digoxina'], [12], 'Tratamento'], [['carvedilol', '25'], [20, 21], 'Tratamento'], [['HCTZ'], [26], 'Tratamento']]]\n",
      "key: 4\n",
      "[[['DSLP', 0], ['em', 1], ['uso', 2], ['de', 3], ['sinvastatina', 4], [',', 5], ['marevan', 6], ['1', 7], ['cp', 8], ['/', 9], ['dia', 10], ['seg', 11], ['-', 12], ['sab', 13], ['para', 14], ['no', 15], ['alvo', 16], ['sic', 17], ['.', 18]], [[['DSLP'], [0], 'Problema'], [['sinvastatina'], [4], 'Tratamento'], [['marevan'], [6], 'Tratamento']]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in dic_predictions.items():\n",
    "    print('key:',key)\n",
    "    print(dic_predictions[key])\n",
    "    if key>3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval' from 'C:\\\\Users\\\\lisat\\\\OneDrive\\\\jupyter notebook\\\\spanclassification\\\\avaliacao\\\\eval.py'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['FA'], [8], 'Problema'], [['marevan', '5mg'], [12, 13], 'Tratamento']]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n"
     ]
    }
   ],
   "source": [
    "print(len(dicSentences_new_test))\n",
    "print(len(dic_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_true_list, region_pred_list, lista_erros = f.getListaRegionsTruePred(BATCH, dicSentences_new_test, dic_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema', 'Tratamento', 'Problema', 'Problema']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_pred_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema', 'Tratamento', 'Problema', 'Problema']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_true_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 11, 11, 13, 13]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_erros[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['BC', 0], ['arritmicas', 1], [',', 2], ['NF', 3], ['SS', 4], ['2T', 5], ['.', 6]], [[['arritmicas'], [1], 'Problema'], [['NF', 'SS'], [3, 4], 'Problema']]]\n",
      "[['BC arritmicas', [0, 1], 'Problema'], ['SS', [4], 'Problema']]\n"
     ]
    }
   ],
   "source": [
    "print(dic_predictions[8])\n",
    "print(dicSentences_new_test[8][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Exames', 0], ['-', 1], ['Holter', 2], [':', 3], ['FC', 4], ['controlada', 5], [',', 6], ['media', 7], ['92', 8], ['.', 9]], [[['controlada'], [5], 'Problema'], [['Exames'], [0], 'Teste'], [['Holter'], [2], 'Teste'], [['FC'], [4], 'Teste']]]\n",
      "[['Exames', [0], 'Teste'], ['Holter', [2], 'Teste']]\n"
     ]
    }
   ],
   "source": [
    "print(dic_predictions[11])\n",
    "print(dicSentences_new_test[11][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(region_true_list): 1190\n",
      "len(region_pred_list): 1190\n",
      "-----Avaliando só modelo de NER:-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.786730  0.846939  0.815725       196\n",
      "           O   0.000000  0.000000  0.000000       199\n",
      "    Problema   0.760753  0.837278  0.797183       338\n",
      "       Teste   0.867769  0.864198  0.865979       243\n",
      "  Tratamento   0.810185  0.817757  0.813953       214\n",
      "\n",
      "    accuracy                       0.700840      1190\n",
      "   macro avg   0.645087  0.673234  0.658568      1190\n",
      "weighted avg   0.668555  0.700840  0.683991      1190\n",
      "\n",
      "[[166  27   3   0   0]\n",
      " [ 44   0  83  32  40]\n",
      " [  0  55 283   0   0]\n",
      " [  1  31   0 210   1]\n",
      " [  0  36   3   0 175]]\n"
     ]
    }
   ],
   "source": [
    "print('len(region_true_list):', len(region_true_list))\n",
    "print('len(region_pred_list):', len(region_pred_list))\n",
    "#print('pred:',region_pred_list[:15])\n",
    "#print('true:',region_true_list[:15])\n",
    "\n",
    "print('-----Avaliando só modelo de NER:-----')\n",
    "\n",
    "print(classification_report(region_true_list, region_pred_list, digits=6))\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
