{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "# ver qtos o modelo apenas de ner acertaria\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import nltk    \n",
    "from nltk import tokenize \n",
    "import torch\n",
    "from transformers import BertTokenizer,BertForTokenClassification\n",
    "import numpy as np\n",
    "import json   \n",
    "from importlib import reload  # Python 3.4+\n",
    "import random\n",
    "import model as mod\n",
    "from model import BertForChunkClassification\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload \n",
    "#from eval import predict\n",
    "import eval\n",
    "#import importlib\n",
    "#importlib.reload(module)\n",
    "import dataset\n",
    "from dataset import InputFeatures, load_and_cache_examples\n",
    "import functionsAval as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\n"
     ]
    }
   ],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n",
    "reload(mod)\n",
    "\n",
    "# em numero de frases\n",
    "BATCH=100\n",
    "#BATCH=5\n",
    "#BATCH=800\n",
    "#BATCH=8000 \n",
    "print('BATCH:', BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegando sentencas de teste gabarito: dic_sentencesTest.pkl\n",
      "506\n",
      "[[['Lucas', 0, 43], [',', 1, 48], ['74', 2, 50], ['anos', 3, 53], ['.', 4, 57]], []]\n",
      "numero de sentencas no total: 100\n",
      "idx2tag: {0: 'Teste', 1: 'Anatomia', 2: 'O', 3: 'Problema', 4: 'Tratamento', 5: '<pad>'}\n",
      "len(dic_predictions): 100\n",
      "verificando dados:\n",
      "len(dicSentences_new_test): 100\n",
      "len(dic_predictions): 100\n",
      "region_pred_list[:4]: ['Problema', 'Tratamento', 'Problema', 'Problema']\n",
      "region_true_list[:4]: ['Problema', 'Tratamento', 'Problema', 'Problema']\n",
      "lista_erros[:8]: [7, 8, 13, 13, 14, 15, 15, 15]\n",
      "len(lista_erros): 114\n",
      "len(set(lista_erros)): 45\n",
      "len(region_true_list): 352\n",
      "len(region_pred_list): 352\n",
      "-----Avaliando só modelo de NER:-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.789474  0.277778  0.410959        54\n",
      "           O   0.000000  0.000000  0.000000        38\n",
      "    Problema   0.853211  0.823009  0.837838       113\n",
      "       Teste   0.880952  0.891566  0.886228        83\n",
      "  Tratamento   0.828125  0.828125  0.828125        64\n",
      "\n",
      "    accuracy                       0.667614       352\n",
      "   macro avg   0.670352  0.564096  0.592630       352\n",
      "weighted avg   0.753305  0.667614  0.691546       352\n",
      "\n",
      "[[15 36  1  1  1]\n",
      " [ 4  0 15  9 10]\n",
      " [ 0 20 93  0  0]\n",
      " [ 0  9  0 74  0]\n",
      " [ 0 11  0  0 53]]\n"
     ]
    }
   ],
   "source": [
    "dicSentences_new_test = f.loadSentencesTest()\n",
    "print(len(dicSentences_new_test))\n",
    "dicSentences_new_test = {k: v for k, v in dicSentences_new_test.items() if k<BATCH}\n",
    "print(dicSentences_new_test[0])\n",
    "#print(dicSentences_new_test[27])\n",
    "print('numero de sentencas no total:', len(dicSentences_new_test))\n",
    "\n",
    "sentences=list()\n",
    "for key, value in dicSentences_new_test.items():\n",
    "    if key<BATCH:\n",
    "        tokens = value[0]\n",
    "        tokens = [tok[0] for tok in tokens]\n",
    "        sentences.append(' '.join(tokens).strip())\n",
    "#print(sentences[0])\n",
    "\n",
    "tags, tokens = f.predictBERTNER_IO(sentences, 'all')\n",
    "dic_predictions = f.getDicPredictions(tags, tokens)\n",
    "#print(dic_predictions[0])\n",
    "print('len(dic_predictions):', len(dic_predictions))\n",
    "#print(dic_predictions[9])\n",
    "f.save_obj('dic_predictions_results_ner_'+str(BATCH), dic_predictions)\n",
    "#dic_predictions = f.load_obj('dic_predictions_results_ner_'+str(BATCH))\n",
    "print('verificando dados:')\n",
    "#for key, value in dic_predictions.items():\n",
    "#    print('key:',key)\n",
    "#    print(dic_predictions[key])\n",
    "#    if key>2:\n",
    "#        break\n",
    "        \n",
    "print('len(dicSentences_new_test):', len(dicSentences_new_test))\n",
    "print('len(dic_predictions):', len(dic_predictions))\n",
    "\n",
    "region_true_list, region_pred_list, lista_erros = f.getListaRegionsTruePred(BATCH, dicSentences_new_test, dic_predictions)\n",
    "f.save_obj('region_true_list'+str(BATCH), region_true_list)\n",
    "print('region_pred_list[:4]:', region_pred_list[:4])\n",
    "print('region_true_list[:4]:', region_true_list[:4])\n",
    "print('lista_erros[:8]:', lista_erros[:8])\n",
    "print('len(lista_erros):', len(lista_erros))\n",
    "print('len(set(lista_erros)):', len(set(lista_erros)))\n",
    "#print(dic_predictions[8])\n",
    "#print(dicSentences_new_test[8][1])\n",
    "print('len(region_true_list):', len(region_true_list))\n",
    "print('len(region_pred_list):', len(region_pred_list))\n",
    "#print('pred:',region_pred_list[:15])\n",
    "#print('true:',region_true_list[:15])\n",
    "\n",
    "print('-----Avaliando só modelo de NER:-----')\n",
    "\n",
    "print(classification_report(region_true_list, region_pred_list, digits=6))\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando modelo de sentence-pais\n",
    "#### primeiro sozinho...\n",
    "1) Com filtro + downsampling\n",
    "\n",
    "2) Com filtro\n",
    "\n",
    "3) Só positivos (dai preciso de um CRF pro filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando só com modelo de Sentence Pairs:-----\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "print('-----Avaliando só com modelo de Sentence Pairs:-----')\n",
    "model = ClassificationModel('bert', 'lisaterumi/sentence_pairs_nested_filtro_downsampling', use_cuda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[0,0]\n",
    "[num for num in range(a[0], a[1]+1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = reload(f)\n",
    "#combinacaoEntidadesAll = f.getCombinacaoEntidadesSentence(dic_predictions, True, dicPosTagger, 0, lista_postaggers_entidades)\n",
    "#combinacaoEntidadesAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Otimizo', 0],\n",
       "  ['dose', 1],\n",
       "  ['da', 2],\n",
       "  ['sinvastatina', 3],\n",
       "  ['para', 4],\n",
       "  ['40mg', 5],\n",
       "  ['/', 6],\n",
       "  ['dia', 7],\n",
       "  ['.', 8]],\n",
       " [['dose da sinvastatina para 40mg', [1, 2, 3, 4, 5], 'Tratamento']]]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de sentenças de test: 1,913\n",
      "\n",
      "         text_b                                             text_a  labels\n",
      "0   marevan 5mg  Em acompanhamento no ambualtorio há 5 anos por...       2\n",
      "1       marevan  Em acompanhamento no ambualtorio há 5 anos por...       0\n",
      "2  Comorbidades  Comorbidades : DM há 10 anos em uso de metform...       1\n",
      "Primeiro, com filtro postagger:\n",
      "Sentence Pairs - Com filtro-postagger\n",
      "Sentence Pairs - Sem taxa de Downsampling\n",
      "erro_corpus: 0\n",
      "num_frases_sem_entidade: 14\n",
      "len(combinacaoEntidadesAll:) 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"..\\preProcessamento\\sentence-pairs-filtro\\sentence_pairs.test\", delimiter='\\t', header=0, names=['text_b', 'text_a', 'labels'])\n",
    "df = df.dropna(axis=0, how='any')\n",
    "print('Número de sentenças de test: {:,}\\n'.format(df.shape[0]))\n",
    "#df=df[:50]\n",
    "test_df = df\n",
    "print(test_df[:3])\n",
    "lista=list()\n",
    "#for index, row in test_df.iterrows():\n",
    "#    lista.append([row['text_b'], row['text_a']])\n",
    "#predictions, raw_outputs = model.predict(\n",
    "#  lista\n",
    "#)\n",
    "dic_sentencesTrainDev = f.load_obj('dic_sentencesTrainDev')\n",
    "dicPosTagger, _ = f.getDicPosTagger(dic_sentencesTrainDev)\n",
    "lista_postaggers_entidades = f.getListaPostaggerEntidades(dic_predictions, dicPosTagger)\n",
    "# para gerar arquivo de predicoes (com as tags <e1>)\n",
    "print('Primeiro, com filtro postagger:')\n",
    "combinacaoEntidadesAll = f.getCombinacaoEntidadesSentence(dic_predictions, True, dicPosTagger, 0, lista_postaggers_entidades)\n",
    "f.save_obj('combinacaoEntidadesAllSentence_'+str(BATCH), combinacaoEntidadesAll)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dose da sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3, 4, 5],\n",
       "  2],\n",
       " ['sinvastatina', 'Otimizo dose da sinvastatina para 40mg / dia .', [3], 0],\n",
       " ['dose', 'Otimizo dose da sinvastatina para 40mg / dia .', [1], 0],\n",
       " ['dose da sinvastatina',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3],\n",
       "  0],\n",
       " ['da', 'Otimizo dose da sinvastatina para 40mg / dia .', [2], 0],\n",
       " ['para', 'Otimizo dose da sinvastatina para 40mg / dia .', [4], 0],\n",
       " ['sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [3, 4, 5],\n",
       "  0]]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesAll[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# para suprimir output\n",
    "#combinacaoEntidadesAll = f.load_obj('combinacaoEntidadesAll_'+str(BATCH))\n",
    "print('Chamando predict')\n",
    "pred_region_labels = list()\n",
    "for key, combinacao in enumerate(combinacaoEntidadesAll):\n",
    "    if key<BATCH:    \n",
    "        if len(combinacao)>0:\n",
    "            lista = [l[0:2] for l in combinacao]\n",
    "            predictions, _ = model.predict(lista) \n",
    "            pred_region_labels.append(predictions)\n",
    "            for comb, label in zip(combinacao, predictions):\n",
    "                comb.append(label)\n",
    "f.save_obj('combinacaoEntidadesAllSentenceComLabel1_'+str(BATCH), combinacaoEntidadesAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "pred_region_labels2 = list()\n",
    "for a in pred_region_labels:\n",
    "    for b in a:\n",
    "        pred_region_labels2.append(labels[b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problema', 'Tratamento', 'Tratamento', 'Problema', 'Problema', 'Tratamento', 'Tratamento', 'Tratamento', 'Tratamento', 'O']\n",
      "['Problema', 'Tratamento', 'Problema', 'Problema', 'Tratamento', 'Tratamento', 'Tratamento', 'Tratamento', 'Problema', 'Tratamento']\n",
      "564\n",
      "352\n"
     ]
    }
   ],
   "source": [
    "print(pred_region_labels2[:10])\n",
    "print(region_true_list[:10])\n",
    "print(len(pred_region_labels2))\n",
    "print(len(region_true_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', 0],\n",
       "  ['há', 1],\n",
       "  ['15', 2],\n",
       "  ['anos', 3],\n",
       "  ['em', 4],\n",
       "  ['uso', 5],\n",
       "  ['de', 6],\n",
       "  ['losartana', 7],\n",
       "  ['50mg', 8],\n",
       "  ['/', 9],\n",
       "  ['dia', 10],\n",
       "  ['e', 11],\n",
       "  ['digoxina', 12],\n",
       "  ['1', 13],\n",
       "  ['/', 14],\n",
       "  ['2', 15],\n",
       "  ['cp', 16],\n",
       "  ['/', 17],\n",
       "  ['dia', 18],\n",
       "  [',', 19],\n",
       "  ['carvedilol', 20],\n",
       "  ['25', 21],\n",
       "  ['12', 22],\n",
       "  ['/', 23],\n",
       "  ['12', 24],\n",
       "  [',', 25],\n",
       "  ['HCTZ', 26],\n",
       "  ['.', 27]],\n",
       " [['HAS', [0], 'Problema'],\n",
       "  ['losartana 50mg', [7, 8], 'Tratamento'],\n",
       "  ['digoxina', [12], 'Tratamento'],\n",
       "  ['carvedilol 25', [20, 21], 'Tratamento'],\n",
       "  ['HCTZ', [26], 'Tratamento']]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dose da sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3, 4, 5],\n",
       "  2,\n",
       "  2],\n",
       " ['sinvastatina', 'Otimizo dose da sinvastatina para 40mg / dia .', [3], 0, 0],\n",
       " ['dose', 'Otimizo dose da sinvastatina para 40mg / dia .', [1], 0, 0],\n",
       " ['dose da sinvastatina',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3],\n",
       "  0,\n",
       "  2],\n",
       " ['da', 'Otimizo dose da sinvastatina para 40mg / dia .', [2], 0, 0],\n",
       " ['para', 'Otimizo dose da sinvastatina para 40mg / dia .', [4], 0, 0],\n",
       " ['sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [3, 4, 5],\n",
       "  0,\n",
       "  2]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesAll[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicPredictionsSentence(combinacaoEntidadesAll_pred, dic_predictions):\n",
    "    labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "    num=-1\n",
    "    dic_predictions_sentence={}\n",
    "    entidades=list()\n",
    "    numAcrescentou=0\n",
    "    for frases in combinacaoEntidadesAll_pred:\n",
    "        num=num+1\n",
    "        for valor in frases:\n",
    "            #print('num:', num)\n",
    "            #print('valor:', valor)\n",
    "            #print('valor[1]:', valor[1])\n",
    "            tokens_entidade = valor[0]\n",
    "            #frase = valor[1]\n",
    "            indices = valor[2]\n",
    "            tipo_previsto=valor[4]\n",
    "            #print('tokens_entidade:', tokens_entidade)\n",
    "            #print('frase:', frase)\n",
    "            #print('indices:', indices)\n",
    "            #print('tipo_previsto:', tipo_previsto)\n",
    "            entidades.append([tokens_entidade, indices, labels[tipo_previsto]])\n",
    "            # ver se entidade está na dic_prediction\n",
    "        frase = dic_predictions[num].copy()[0]\n",
    "        dic_predictions_sentence[num] = [frase, entidades]\n",
    "        entidades = list()\n",
    "                     \n",
    "    return dic_predictions_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Otimizo', 0],\n",
       "  ['dose', 1],\n",
       "  ['da', 2],\n",
       "  ['sinvastatina', 3],\n",
       "  ['para', 4],\n",
       "  ['40mg', 5],\n",
       "  ['/', 6],\n",
       "  ['dia', 7],\n",
       "  ['.', 8]],\n",
       " [['dose da sinvastatina para 40mg', [1, 2, 3, 4, 5], 'Tratamento'],\n",
       "  ['sinvastatina', [3], 'O'],\n",
       "  ['dose', [1], 'O'],\n",
       "  ['dose da sinvastatina', [1, 2, 3], 'Tratamento'],\n",
       "  ['da', [2], 'O'],\n",
       "  ['para', [4], 'O'],\n",
       "  ['sinvastatina para 40mg', [3, 4, 5], 'Tratamento']]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_sentence = getDicPredictionsSentence(combinacaoEntidadesAll, dic_predictions)\n",
    "dic_predictions_sentence[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando modelo com filtro + downsampling (Região):-----\n",
      "numErro1: 35\n",
      "numErro2: 285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.815789  0.574074  0.673913        54\n",
      "           O   0.747423  0.508772  0.605428       285\n",
      "    Problema   0.530387  0.849558  0.653061       113\n",
      "       Teste   0.742574  0.903614  0.815217        83\n",
      "  Tratamento   0.658824  0.875000  0.751678        64\n",
      "\n",
      "    accuracy                       0.672788       599\n",
      "   macro avg   0.698999  0.742204  0.699859       599\n",
      "weighted avg   0.702504  0.672788  0.665283       599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avaliar por regiao.. \n",
    "print('-----Avaliando modelo com filtro + downsampling (Região):-----')\n",
    "\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_sentence, BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando modelo com filtro (Região):-----\n",
      "Chamando predict\n"
     ]
    }
   ],
   "source": [
    "# avaliar por regiao.. \n",
    "print('-----Avaliando modelo com filtro (Região):-----')\n",
    "# para suprimir output\n",
    "#model = ClassificationModel('bert', 'lisaterumi/sentence_pairs_nested_filtro', use_cuda=False)\n",
    "model = ClassificationModel('bert', r'C:\\Users\\lisat\\Downloads\\sentece-filtro', use_cuda=False)\n",
    "#combinacaoEntidadesAll = f.load_obj('combinacaoEntidadesAll_'+str(BATCH))\n",
    "print('Chamando predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "pred_region_labels = list()\n",
    "for key, combinacao in enumerate(combinacaoEntidadesAll):\n",
    "    if key<BATCH:    \n",
    "        if len(combinacao)>0:\n",
    "            lista = [l[0:2] for l in combinacao]\n",
    "            predictions, _ = model.predict(lista) \n",
    "            pred_region_labels.append(predictions)\n",
    "            for comb, label in zip(combinacao, predictions):\n",
    "                comb.append(label)\n",
    "f.save_obj('combinacaoEntidadesAllSentenceComLabel2_'+str(BATCH), combinacaoEntidadesAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dose da sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3, 4, 5],\n",
       "  2,\n",
       "  2,\n",
       "  2],\n",
       " ['sinvastatina',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [3],\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " ['dose', 'Otimizo dose da sinvastatina para 40mg / dia .', [1], 0, 0, 0],\n",
       " ['dose da sinvastatina',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [1, 2, 3],\n",
       "  0,\n",
       "  2,\n",
       "  2],\n",
       " ['da', 'Otimizo dose da sinvastatina para 40mg / dia .', [2], 0, 0, 0],\n",
       " ['para', 'Otimizo dose da sinvastatina para 40mg / dia .', [4], 0, 0, 0],\n",
       " ['sinvastatina para 40mg',\n",
       "  'Otimizo dose da sinvastatina para 40mg / dia .',\n",
       "  [3, 4, 5],\n",
       "  0,\n",
       "  2,\n",
       "  2]]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacaoEntidadesAll[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDicPredictionsSentence2(combinacaoEntidadesAll_pred, dic_predictions):\n",
    "    labels = {0:'O', 1:'Problema', 2:'Tratamento', 3:'Teste', 4:'Anatomia'}\n",
    "    num=-1\n",
    "    dic_predictions_sentence={}\n",
    "    entidades=list()\n",
    "    numAcrescentou=0\n",
    "    for frases in combinacaoEntidadesAll_pred:\n",
    "        num=num+1\n",
    "        for valor in frases:\n",
    "            #print('num:', num)\n",
    "            #print('valor:', valor)\n",
    "            #print('valor[1]:', valor[1])\n",
    "            tokens_entidade = valor[0]\n",
    "            #frase = valor[1]\n",
    "            indices = valor[2]\n",
    "            tipo_previsto=valor[5]\n",
    "            #print('tokens_entidade:', tokens_entidade)\n",
    "            #print('frase:', frase)\n",
    "            #print('indices:', indices)\n",
    "            #print('tipo_previsto:', tipo_previsto)\n",
    "            entidades.append([tokens_entidade, indices, labels[tipo_previsto]])\n",
    "            # ver se entidade está na dic_prediction\n",
    "        frase = dic_predictions[num].copy()[0]\n",
    "        dic_predictions_sentence[num] = [frase, entidades]\n",
    "        entidades = list()\n",
    "                     \n",
    "    return dic_predictions_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numErro1: 35\n",
      "numErro2: 285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.815789  0.574074  0.673913        54\n",
      "           O   0.747423  0.508772  0.605428       285\n",
      "    Problema   0.530387  0.849558  0.653061       113\n",
      "       Teste   0.742574  0.903614  0.815217        83\n",
      "  Tratamento   0.658824  0.875000  0.751678        64\n",
      "\n",
      "    accuracy                       0.672788       599\n",
      "   macro avg   0.698999  0.742204  0.699859       599\n",
      "weighted avg   0.702504  0.672788  0.665283       599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dic_predictions_sentence = getDicPredictionsSentence2(combinacaoEntidadesAll, dic_predictions)\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_sentence, BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 31  17   4   2   0]\n",
      " [  6 145  81  24  29]\n",
      " [  0  17  96   0   0]\n",
      " [  1   7   0  75   0]\n",
      " [  0   8   0   0  56]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema',\n",
       " 'Tratamento',\n",
       " 'O',\n",
       " 'Problema',\n",
       " 'Problema',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'O']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_true_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema',\n",
       " 'Tratamento',\n",
       " 'O',\n",
       " 'Problema',\n",
       " 'Problema',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'Tratamento',\n",
       " 'Tratamento']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_pred_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['calcificação', 0, 1083],\n",
       "  ['mitral', 1, 1096],\n",
       "  ['e', 2, 1103],\n",
       "  ['aórtica', 3, 1105],\n",
       "  ['com', 4, 1113],\n",
       "  ['refluxo', 5, 1117],\n",
       "  ['leve', 6, 1125],\n",
       "  ['.', 7, 1129]],\n",
       " [['calcificação mitral e aórtica com refluxo leve',\n",
       "   [0, 1, 2, 3, 4, 5, 6],\n",
       "   'Problema'],\n",
       "  ['mitral', [1], 'Anatomia'],\n",
       "  ['aórtica', [3], 'Anatomia']]]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicSentences_new_test[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['calcificação', 0],\n",
       "  ['mitral', 1],\n",
       "  ['e', 2],\n",
       "  ['aórtica', 3],\n",
       "  ['com', 4],\n",
       "  ['refluxo', 5],\n",
       "  ['leve', 6],\n",
       "  ['.', 7]],\n",
       " [['calcificação', [0], 'Problema'],\n",
       "  ['mitral', [1], 'Tratamento'],\n",
       "  ['e', [2], 'Problema'],\n",
       "  ['aórtica', [3], 'Anatomia'],\n",
       "  ['refluxo leve', [5, 6], 'Problema']]]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['calcificação', 0],\n",
       "  ['mitral', 1],\n",
       "  ['e', 2],\n",
       "  ['aórtica', 3],\n",
       "  ['com', 4],\n",
       "  ['refluxo', 5],\n",
       "  ['leve', 6],\n",
       "  ['.', 7]],\n",
       " [['calcificação', [0], 'Problema'],\n",
       "  ['mitral', [1], 'Anatomia'],\n",
       "  ['e', [2], 'O'],\n",
       "  ['aórtica', [3], 'Anatomia'],\n",
       "  ['refluxo leve', [5, 6], 'Problema'],\n",
       "  ['refluxo', [5], 'Problema'],\n",
       "  ['leve', [6], 'O']]]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_sentence[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Avaliando modelo sem filtro (Região):-----\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102499d488da4d2b9b3bf9b3ba83b669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b0291985584e48aa5ff3f341718027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/679M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d2bf402f9d49249b138aa89354960c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b15b3ff136468c96cb99f1187c19e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8843ea20e91b4a72b245324511bd7fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3681a40ef2be4d2f97dbf0f4d4919c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamando predict\n"
     ]
    }
   ],
   "source": [
    "# avaliar por regiao.. \n",
    "print('-----Avaliando modelo sem filtro (Região):-----')\n",
    "# para suprimir output\n",
    "model = ClassificationModel('bert', 'lisaterumi/sentence_pairs_nested_all', use_cuda=False)\n",
    "#model = ClassificationModel('bert', r'C:\\Users\\lisat\\Downloads\\sentece-sem-filtro', use_cuda=False)\n",
    "#combinacaoEntidadesAll = f.load_obj('combinacaoEntidadesAll_'+str(BATCH))\n",
    "print('Chamando predict')\n",
    "combinacaoEntidadesAll = f.load_obj('combinacaoEntidadesAllSentence_'+str(BATCH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "pred_region_labels = list()\n",
    "for key, combinacao in enumerate(combinacaoEntidadesAll):\n",
    "    if key<BATCH:    \n",
    "        if len(combinacao)>0:\n",
    "            lista = [l[0:2] for l in combinacao]\n",
    "            predictions, _ = model.predict(lista) \n",
    "            pred_region_labels.append(predictions)\n",
    "            for comb, label in zip(combinacao, predictions):\n",
    "                comb.append(label)\n",
    "f.save_obj('combinacaoEntidadesAllSentenceComLabel3_'+str(BATCH), combinacaoEntidadesAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numErro1: 35\n",
      "numErro2: 285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.791667  0.703704  0.745098        54\n",
      "           O   0.753695  0.536842  0.627049       285\n",
      "    Problema   0.514970  0.761062  0.614286       113\n",
      "       Teste   0.844444  0.915663  0.878613        83\n",
      "  Tratamento   0.637363  0.906250  0.748387        64\n",
      "\n",
      "    accuracy                       0.686144       599\n",
      "   macro avg   0.708428  0.764704  0.722687       599\n",
      "weighted avg   0.712228  0.686144  0.683106       599\n",
      "\n",
      "[[ 38  12   4   0   0]\n",
      " [ 10 153  77  12  33]\n",
      " [  0  26  86   1   0]\n",
      " [  0   7   0  76   0]\n",
      " [  0   5   0   1  58]]\n"
     ]
    }
   ],
   "source": [
    "dic_predictions_sentence = getDicPredictionsSentence(combinacaoEntidadesAll, dic_predictions)\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_sentence, BATCH)\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, merge com dic_predictions?/\n",
    "\n",
    "Acho que nao precisa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora, com pos processamento\n",
    "\n",
    "Regras:\n",
    "\n",
    "- Pega os de dentro (aninhadas), apenas se o tipo for diferente do tipo da entidade de fora... se for do mesmo tipo, não pega..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isEntidadeAninhada(a, b):\n",
    "    inicio1=a[0]\n",
    "    fim1=a[-1]\n",
    "    #print(inicio1, fim1)\n",
    "    inicio2=b[0]\n",
    "    fim2=b[-1]\n",
    "    #print(inicio2, fim2)\n",
    "    if inicio1 >=inicio2 and fim1 <=fim2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "isEntidadeAninhada([2], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juntando sentence + ner, com pos processamento\n",
      "Não é aninhada, incluindo: ['glicazida', [22], 'O']\n",
      "Não é aninhada, incluindo: ['metformina', [9], 'O']\n",
      "Não é aninhada, incluindo: ['carvedilol', [20], 'Problema']\n",
      "Não é aninhada, incluindo: ['esquerdo', [3], 'O']\n",
      "Não é aninhada, incluindo: ['ventrículo', [2], 'O']\n",
      "Não é aninhada, incluindo: ['VE', [36], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['moderado', [38], 'O']\n",
      "Não é aninhada, incluindo: ['difuso', [34], 'O']\n",
      "Não é aninhada, incluindo: ['grau moderado', [37, 38], 'O']\n",
      "Não é aninhada, incluindo: ['do', [35], 'O']\n",
      "Não é aninhada, incluindo: ['difuso do VE', [34, 35, 36], 'O']\n",
      "Não é aninhada, incluindo: ['insuf', [40], 'O']\n",
      "Não é aninhada, incluindo: ['insuf', [44], 'O']\n",
      "Não é aninhada, incluindo: ['VE grau', [36, 37], 'O']\n",
      "Não é aninhada, incluindo: ['intermitente', [3], 'O']\n",
      "Não é aninhada, incluindo: ['MMII', [5], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['turvação', [11], 'O']\n",
      "Não é aninhada, incluindo: ['visual', [12], 'O']\n",
      "Não é aninhada, incluindo: ['fraqueza', [2], 'O']\n",
      "Não é aninhada, incluindo: ['em', [4], 'O']\n",
      "Não é aninhada, incluindo: ['dor', [1], 'O']\n",
      "Não é aninhada, incluindo: ['toracica', [2], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['queixas', [1], 'O']\n",
      "Não é aninhada, incluindo: ['urinarias', [2], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['isolada', [63], 'O']\n",
      "Não é aninhada, incluindo: ['acido', [16], 'O']\n",
      "Não é aninhada, incluindo: ['urico', [17], 'O']\n",
      "Não é aninhada, incluindo: ['anlodipino', [9], 'O']\n",
      "Não é aninhada, incluindo: ['sinvastatina', [36], 'O']\n",
      "Não é aninhada, incluindo: ['AAS', [26], 'O']\n",
      "Não é aninhada, incluindo: ['clopidogrel', [31], 'O']\n",
      "Não é aninhada, incluindo: ['ICC', [4], 'O']\n",
      "Não é aninhada, incluindo: ['dispneia', [2], 'O']\n",
      "Não é aninhada, incluindo: ['esforços', [5], 'O']\n",
      "Não é aninhada, incluindo: ['aos', [3], 'O']\n",
      "Não é aninhada, incluindo: ['alterações', [26], 'O']\n",
      "Não é aninhada, incluindo: ['alteração', [41], 'O']\n",
      "Não é aninhada, incluindo: ['abdome total', [21, 22], 'O']\n",
      "Não é aninhada, incluindo: ['US', [20], 'O']\n",
      "Não é aninhada, incluindo: ['bulhas', [99], 'O']\n",
      "Não é aninhada, incluindo: ['alteração de repolarização', [41, 42, 43], 'O']\n",
      "Não é aninhada, incluindo: ['infero', [45], 'O']\n",
      "Não é aninhada, incluindo: ['classe III', [122, 123], 'O']\n",
      "Não é aninhada, incluindo: ['diastólica classe III', [121, 122, 123], 'O']\n",
      "Não é aninhada, incluindo: ['lateral', [47], 'O']\n",
      "Não é aninhada, incluindo: ['repolarização', [43], 'O']\n",
      "Não é aninhada, incluindo: ['ICC diastólica classe', [120, 121, 122], 'O']\n",
      "Não é aninhada, incluindo: ['classe', [122], 'O']\n",
      "Não é aninhada, incluindo: ['US abdome', [20, 21], 'O']\n",
      "Não é aninhada, incluindo: ['hipofonese', [97], 'O']\n",
      "Não é aninhada, incluindo: ['subepicárdica', [38], 'O']\n",
      "Não é aninhada, incluindo: ['anterior', [39], 'O']\n",
      "Não é aninhada, incluindo: ['subepicárdica anterior', [38, 39], 'O']\n",
      "Não é aninhada, incluindo: ['de', [98], 'O']\n",
      "Não é aninhada, incluindo: ['ICC diastólica', [120, 121], 'O']\n",
      "Não é aninhada, incluindo: ['total', [22], 'O']\n",
      "Não é aninhada, incluindo: ['isquemia', [37], 'O']\n",
      "Não é aninhada, incluindo: ['ventricular', [44], 'Teste']\n",
      "Não é aninhada, incluindo: ['III', [123], 'O']\n",
      "Não é aninhada, incluindo: ['diastólica', [121], 'O']\n",
      "Não é aninhada, incluindo: ['infero - lateral', [45, 46, 47], 'O']\n",
      "Não é aninhada, incluindo: ['de', [42], 'O']\n",
      "Não é aninhada, incluindo: ['repolarização ventricular infero', [43, 44, 45], 'O']\n",
      "Não é aninhada, incluindo: ['clearence', [62], 'O']\n",
      "Não é aninhada, incluindo: ['isquemia subepicárdica', [37, 38], 'O']\n",
      "Não é aninhada, incluindo: ['ICC', [120], 'O']\n",
      "Não é aninhada, incluindo: ['repolarização ventricular', [43, 44], 'O']\n",
      "Não é aninhada, incluindo: ['losartana', [35], 'O']\n",
      "Não é aninhada, incluindo: ['atenolol', [8], 'O']\n",
      "Não é aninhada, incluindo: ['metformina', [42], 'O']\n",
      "Não é aninhada, incluindo: ['furosemida', [19], 'O']\n",
      "Não é aninhada, incluindo: ['classe', [1], 'O']\n",
      "Não é aninhada, incluindo: ['ICC classe', [0, 1], 'O']\n",
      "Não é aninhada, incluindo: ['III', [2], 'O']\n",
      "Não é aninhada, incluindo: ['anlodipino', [26], 'O']\n",
      "Não é aninhada, incluindo: ['EVEROLIMUS 0', [3, 4], 'O']\n",
      "Não é aninhada, incluindo: ['AZATIOPRINA', [12], 'O']\n",
      "Não é aninhada, incluindo: ['INSUF', [35], 'O']\n",
      "Não é aninhada, incluindo: ['TRI', [36], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['INSUF', [32], 'O']\n",
      "Não é aninhada, incluindo: ['DUPLA', [26], 'O']\n",
      "Não é aninhada, incluindo: ['LESAO', [27], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['MI', [28], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['LESAO MI', [27, 28], 'O']\n",
      "Não é aninhada, incluindo: ['REFLUXO', [23], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['DISCRETO', [24], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['Espironolactona', [20], 'O']\n",
      "Não é aninhada, incluindo: ['Sinvastatina', [25], 'O']\n",
      "Não é aninhada, incluindo: ['Enalapril', [2], 'O']\n",
      "Não é aninhada, incluindo: ['Marevan', [37], 'O']\n",
      "Não é aninhada, incluindo: ['Calcio', [31], 'O']\n",
      "Não é aninhada, incluindo: ['Atenolol', [11], 'O']\n",
      "Não é aninhada, incluindo: ['dor', [10], 'O']\n",
      "Não é aninhada, incluindo: ['Dispnia', [0], 'O']\n",
      "Não é aninhada, incluindo: ['toracica', [11], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['edema', [3], 'O']\n",
      "Não é aninhada, incluindo: ['eventual', [5], 'O']\n",
      "Não é aninhada, incluindo: ['mmii', [4], 'Anatomia']\n",
      "Não é aninhada, incluindo: ['Urina', [33], 'O']\n",
      "Não é aninhada, incluindo: ['I', [34], 'O']\n",
      "Não é aninhada, incluindo: ['protese', [1], 'O']\n",
      "Não é aninhada, incluindo: ['metalica', [2], 'O']\n",
      "numErro1: 66\n",
      "numErro2: 130\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.766667  0.425926  0.547619        54\n",
      "           O   0.561290  0.669231  0.610526       130\n",
      "    Problema   0.845455  0.823009  0.834081       113\n",
      "       Teste   0.870588  0.891566  0.880952        83\n",
      "  Tratamento   0.828125  0.828125  0.828125        64\n",
      "\n",
      "    accuracy                       0.743243       444\n",
      "   macro avg   0.774425  0.727571  0.740261       444\n",
      "weighted avg   0.754871  0.743243  0.741689       444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# juntar all_predictions\n",
    "print('juntando sentence + ner, com pos processamento')\n",
    "#dic_predictions = f.load_obj('dic_predictions_results_ner_'+str(BATCH))\n",
    "#dic_predictions_all = f.getDicPredictionsAll(combinacaoEntidadesAll_pred, dic_predictions)\n",
    "\n",
    "def juntaPredictons(dic_predictions, dic_predictions_sentence):\n",
    "    dic_predictions_all = {}\n",
    "    for key, value in dic_predictions.items():\n",
    "        #dic_predictions_all[key] = value.copy()\n",
    "        tokens = value[0].copy()\n",
    "        listaEntidadesNer = value[1].copy()\n",
    "        listaIndicesNer=list()\n",
    "        listaTipoNer=list()\n",
    "        for entidadeNer in listaEntidadesNer:\n",
    "            listaIndicesNer.append(entidadeNer[1])\n",
    "            listaTipoNer.append(entidadeNer[2])\n",
    "        #print('listaIndicesNer:', listaIndicesNer)\n",
    "        listaEntidadesSpan = dic_predictions_sentence[key][1]\n",
    "        for entidadeSpan in listaEntidadesSpan:\n",
    "            indices = entidadeSpan[1]\n",
    "            if indices in listaIndicesNer:\n",
    "                #print('ja tem, pulando')\n",
    "                pass\n",
    "            else:\n",
    "                #print('incluindo:', entidadeSpan)\n",
    "                # só acrescenta se nao tem entidade mais externa do mesmo tipo\n",
    "                # ver pelo indice\n",
    "                isAninhada=False\n",
    "                tipo=entidadeSpan[2]\n",
    "                for indicesNer, tipoNer in zip(listaIndicesNer, listaTipoNer):\n",
    "                    isAninhada = isEntidadeAninhada(indices, indicesNer) # é aninhada com alguma entidade?\n",
    "                    if isAninhada and tipoNer == tipo:\n",
    "                        break\n",
    "                # ver pelo tipo tb\n",
    "                if not isAninhada:\n",
    "                    print('Não é aninhada, incluindo:', entidadeSpan)\n",
    "                    listaEntidadesNer.append(entidadeSpan)\n",
    "                else:\n",
    "                    #print('aninhada:', entidadeSpan)\n",
    "                    pass\n",
    "        dic_predictions_all[key] = [tokens, listaEntidadesNer]\n",
    "        #if key>15:\n",
    "        #    break\n",
    "    return dic_predictions_all\n",
    "\n",
    "dic_predictions_all = juntaPredictons(dic_predictions, dic_predictions_sentence)\n",
    "#dic_predictions_all\n",
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_all, BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numErro1: 66\n",
      "numErro2: 130\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.766667  0.425926  0.547619        54\n",
      "           O   0.561290  0.669231  0.610526       130\n",
      "    Problema   0.845455  0.823009  0.834081       113\n",
      "       Teste   0.870588  0.891566  0.880952        83\n",
      "  Tratamento   0.828125  0.828125  0.828125        64\n",
      "\n",
      "    accuracy                       0.743243       444\n",
      "   macro avg   0.774425  0.727571  0.740261       444\n",
      "weighted avg   0.754871  0.743243  0.741689       444\n",
      "\n",
      "[[23 28  1  1  1]\n",
      " [ 7 87 16 10 10]\n",
      " [ 0 20 93  0  0]\n",
      " [ 0  9  0 74  0]\n",
      " [ 0 11  0  0 53]]\n"
     ]
    }
   ],
   "source": [
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions_all, BATCH)\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Otimizo', 0],\n",
       "  ['dose', 1],\n",
       "  ['da', 2],\n",
       "  ['sinvastatina', 3],\n",
       "  ['para', 4],\n",
       "  ['40mg', 5],\n",
       "  ['/', 6],\n",
       "  ['dia', 7],\n",
       "  ['.', 8]],\n",
       " [['dose da sinvastatina para 40mg', [1, 2, 3, 4, 5], 'Tratamento']]]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_all[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Otimizo', 0],\n",
       "  ['dose', 1],\n",
       "  ['da', 2],\n",
       "  ['sinvastatina', 3],\n",
       "  ['para', 4],\n",
       "  ['40mg', 5],\n",
       "  ['/', 6],\n",
       "  ['dia', 7],\n",
       "  ['.', 8]],\n",
       " [['dose da sinvastatina para 40mg', [1, 2, 3, 4, 5], 'Tratamento'],\n",
       "  ['sinvastatina', [3], 'O'],\n",
       "  ['dose', [1], 'O'],\n",
       "  ['dose da sinvastatina', [1, 2, 3], 'O'],\n",
       "  ['da', [2], 'O'],\n",
       "  ['para', [4], 'O'],\n",
       "  ['sinvastatina para 40mg', [3, 4, 5], 'Tratamento']]]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_sentence[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Otimizo', 0],\n",
       "  ['dose', 1],\n",
       "  ['da', 2],\n",
       "  ['sinvastatina', 3],\n",
       "  ['para', 4],\n",
       "  ['40mg', 5],\n",
       "  ['/', 6],\n",
       "  ['dia', 7],\n",
       "  ['.', 8]],\n",
       " [['dose da sinvastatina para 40mg', [1, 2, 3, 4, 5], 'Tratamento']]]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
