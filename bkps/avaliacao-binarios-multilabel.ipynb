{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "# ver qtos o modelo apenas de ner acertaria\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import nltk    \n",
    "from nltk import tokenize \n",
    "import torch\n",
    "from transformers import BertTokenizer,BertForTokenClassification\n",
    "import numpy as np\n",
    "import json   \n",
    "from importlib import reload  # Python 3.4+\n",
    "import random\n",
    "from model import BertForChunkClassification\n",
    "from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload \n",
    "#from eval import predict\n",
    "import eval\n",
    "#import importlib\n",
    "#importlib.reload(module)\n",
    "from dataset import InputFeatures, load_and_cache_examples\n",
    "import dataset\n",
    "import functionsAval as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n",
    "\n",
    "path_model=r'.\\model-multilabel-io\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx2tag: {0: 'RNA', 1: 'protein-protein', 2: 'RNA-cell_type', 3: 'protein-cell_line', 4: 'DNA-RNA', 5: 'cell_line-cell_line', 6: 'RNA-RNA', 7: 'cell_type-cell_type', 8: 'protein', 9: 'protein-DNA', 10: 'DNA-cell_line', 11: 'cell_line-RNA', 12: 'protein-cell_type', 13: 'O', 14: 'cell_line-DNA', 15: 'cell_type', 16: 'DNA', 17: 'cell_type-DNA', 18: 'cell_line', 19: 'DNA-DNA', 20: 'protein-RNA', 21: 'cell_type-cell_line', 22: '<pad>'}\n",
      "[['O', 'O', 'O', 'O', 'O', 'DNA', 'DNA', 'DNA', 'DNA', 'O', 'O', 'protein-DNA', 'protein-DNA', 'protein-DNA', 'DNA', 'DNA', 'O', 'O', 'O', 'DNA', 'DNA', 'O', 'DNA', 'O', 'O', 'O', 'O', 'O', 'DNA', 'DNA', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'protein', 'protein', 'protein', 'O']]\n",
      "[['we', 'have', 'previously', 'found', 'a', 'cis', '-', 'acting', 'region', 'spanning', 'the', 'gm', '-', 'csf', 'promoter', 'region', '(', 'positions', '-', '95', 'to', '+', '27', ')', 'that', 'confers', 'inducibility', 'to', 'reporter', 'genes', 'in', 'transient', 'transfection', 'assays', '.'], ['human', 'and', 'mouse', 'gene', 'in', 'cd28', 'surface', 'receptor', '.']]\n"
     ]
    }
   ],
   "source": [
    "tags, tokens = f.predictBERTNER_multi_IO(['We have previously found a cis - acting region spanning the GM - CSF promoter region ( positions - 95 to + 27 ) that confers inducibility to reporter genes in transient transfection assays .','human and mouse gene in CD28 surface receptor.'], path_model)\n",
    "print(tags)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegando sentencas de teste gabarito: dic_sentencesTest.pkl\n",
      "506\n",
      "[[['Lucas', 0, 43], [',', 1, 48], ['74', 2, 50], ['anos', 3, 53], ['.', 4, 57]], []]\n",
      "numero de sentencas no total: 10\n"
     ]
    }
   ],
   "source": [
    "BATCH=10\n",
    "dicSentences_new_test = f.loadSentencesTest()\n",
    "print(len(dicSentences_new_test))\n",
    "dicSentences_new_test = {k: v for k, v in dicSentences_new_test.items() if k<BATCH}\n",
    "print(dicSentences_new_test[0])\n",
    "#print(dicSentences_new_test[27])\n",
    "print('numero de sentencas no total:', len(dicSentences_new_test))\n",
    "\n",
    "sentences=list()\n",
    "for key, value in dicSentences_new_test.items():\n",
    "    if key<BATCH:\n",
    "        tokens = value[0]\n",
    "        tokens = [tok[0] for tok in tokens]\n",
    "        sentences.append(' '.join(tokens).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[['Lucas', 0, 43],\n",
       "   [',', 1, 48],\n",
       "   ['74', 2, 50],\n",
       "   ['anos', 3, 53],\n",
       "   ['.', 4, 57]],\n",
       "  []],\n",
       " 1: [[['Em', 0, 59],\n",
       "   ['acompanhamento', 1, 62],\n",
       "   ['no', 2, 77],\n",
       "   ['ambualtorio', 3, 80],\n",
       "   ['há', 4, 92],\n",
       "   ['5', 5, 95],\n",
       "   ['anos', 6, 97],\n",
       "   ['por', 7, 102],\n",
       "   ['FA', 8, 106],\n",
       "   [',', 9, 108],\n",
       "   ['uso', 10, 110],\n",
       "   ['de', 11, 114],\n",
       "   ['marevan', 12, 117],\n",
       "   ['5mg', 13, 125],\n",
       "   ['1', 14, 129],\n",
       "   ['x', 15, 131],\n",
       "   ['ao', 16, 133],\n",
       "   ['dia', 17, 136],\n",
       "   ['.', 18, 139]],\n",
       "  [['FA', [8], 'Problema'], ['marevan 5mg', [12, 13], 'Tratamento']]],\n",
       " 2: [[['Comorbidades', 0, 142],\n",
       "   [':', 1, 154],\n",
       "   ['DM', 2, 156],\n",
       "   ['há', 3, 159],\n",
       "   ['10', 4, 162],\n",
       "   ['anos', 5, 165],\n",
       "   ['em', 6, 170],\n",
       "   ['uso', 7, 173],\n",
       "   ['de', 8, 177],\n",
       "   ['metformina', 9, 180],\n",
       "   ['850mg', 10, 191],\n",
       "   ['3', 11, 197],\n",
       "   ['cp', 12, 199],\n",
       "   ['/', 13, 201],\n",
       "   ['dia', 14, 202],\n",
       "   [',', 15, 205],\n",
       "   ['acarbose', 16, 207],\n",
       "   ['1', 17, 216],\n",
       "   ['cp', 18, 218],\n",
       "   ['/', 19, 220],\n",
       "   ['dia', 20, 221],\n",
       "   ['e', 21, 225],\n",
       "   ['glicazida', 22, 227],\n",
       "   ['60mg', 23, 237],\n",
       "   ['2', 24, 242],\n",
       "   ['cp', 25, 244],\n",
       "   ['/', 26, 246],\n",
       "   ['dia', 27, 247],\n",
       "   ['e', 28, 251],\n",
       "   ['insulina', 29, 253],\n",
       "   ['(', 30, 262],\n",
       "   ['24', 31, 263],\n",
       "   ['-', 32, 266],\n",
       "   ['0', 33, 268],\n",
       "   ['-', 34, 270],\n",
       "   ['24', 35, 272],\n",
       "   [')', 36, 274],\n",
       "   ['.', 37, 275]],\n",
       "  [['Comorbidades', [0], 'Problema'],\n",
       "   ['DM', [2], 'Problema'],\n",
       "   ['metformina 850mg', [9, 10], 'Tratamento'],\n",
       "   ['acarbose', [16], 'Tratamento'],\n",
       "   ['glicazida 60mg', [22, 23], 'Tratamento'],\n",
       "   ['insulina', [29], 'Tratamento']]],\n",
       " 3: [[['HAS', 0, 277],\n",
       "   ['há', 1, 281],\n",
       "   ['15', 2, 284],\n",
       "   ['anos', 3, 287],\n",
       "   ['em', 4, 292],\n",
       "   ['uso', 5, 295],\n",
       "   ['de', 6, 299],\n",
       "   ['losartana', 7, 302],\n",
       "   ['50mg', 8, 312],\n",
       "   ['/', 9, 317],\n",
       "   ['dia', 10, 318],\n",
       "   ['e', 11, 322],\n",
       "   ['digoxina', 12, 324],\n",
       "   ['1', 13, 333],\n",
       "   ['/', 14, 334],\n",
       "   ['2', 15, 335],\n",
       "   ['cp', 16, 337],\n",
       "   ['/', 17, 340],\n",
       "   ['dia', 18, 341],\n",
       "   [',', 19, 344],\n",
       "   ['carvedilol', 20, 346],\n",
       "   ['25', 21, 357],\n",
       "   ['12', 22, 360],\n",
       "   ['/', 23, 362],\n",
       "   ['12', 24, 363],\n",
       "   [',', 25, 365],\n",
       "   ['HCTZ', 26, 367],\n",
       "   ['.', 27, 371]],\n",
       "  [['HAS', [0], 'Problema'],\n",
       "   ['losartana 50mg', [7, 8], 'Tratamento'],\n",
       "   ['digoxina', [12], 'Tratamento'],\n",
       "   ['carvedilol 25', [20, 21], 'Tratamento'],\n",
       "   ['HCTZ', [26], 'Tratamento']]],\n",
       " 4: [[['DSLP', 0, 373],\n",
       "   ['em', 1, 378],\n",
       "   ['uso', 2, 381],\n",
       "   ['de', 3, 385],\n",
       "   ['sinvastatina', 4, 388],\n",
       "   [',', 5, 400],\n",
       "   ['marevan', 6, 402],\n",
       "   ['1', 7, 410],\n",
       "   ['cp', 8, 412],\n",
       "   ['/', 9, 414],\n",
       "   ['dia', 10, 415],\n",
       "   ['seg', 11, 419],\n",
       "   ['-', 12, 423],\n",
       "   ['sab', 13, 425],\n",
       "   ['para', 14, 429],\n",
       "   ['no', 15, 434],\n",
       "   ['alvo', 16, 437],\n",
       "   ['sic', 17, 442],\n",
       "   ['.', 18, 445]],\n",
       "  [['DSLP', [0], 'Problema'],\n",
       "   ['sinvastatina', [4], 'Tratamento'],\n",
       "   ['marevan', [6], 'Tratamento']]],\n",
       " 5: [[['S', 0, 448], [':', 1, 450], ['Assintomática', 2, 452], ['.', 3, 465]],\n",
       "  []],\n",
       " 6: [[['Nega', 0, 467],\n",
       "   ['dispnéia', 1, 472],\n",
       "   [',', 2, 480],\n",
       "   ['DPN', 3, 482],\n",
       "   ['e', 4, 486],\n",
       "   ['ortopneia', 5, 488],\n",
       "   [',', 6, 497],\n",
       "   ['palpitações', 7, 499],\n",
       "   ['e', 8, 511],\n",
       "   ['sincope', 9, 513],\n",
       "   ['.', 10, 520]],\n",
       "  [['dispnéia', [1], 'Problema'],\n",
       "   ['DPN', [3], 'Problema'],\n",
       "   ['ortopneia', [5], 'Problema'],\n",
       "   ['palpitações', [7], 'Problema'],\n",
       "   ['sincope', [9], 'Problema']]],\n",
       " 7: [[['O', 0, 522],\n",
       "   [':', 1, 524],\n",
       "   ['BEG', 2, 526],\n",
       "   [',', 3, 529],\n",
       "   ['corada', 4, 531],\n",
       "   [',', 5, 537],\n",
       "   ['hidtratada', 6, 539],\n",
       "   [',', 7, 549],\n",
       "   ['afebril', 8, 551],\n",
       "   [',', 9, 558],\n",
       "   ['fc', 10, 560],\n",
       "   ['63', 11, 563],\n",
       "   [',', 12, 565],\n",
       "   ['so2', 13, 567],\n",
       "   ['97', 14, 571],\n",
       "   ['%', 15, 573],\n",
       "   [',', 16, 574],\n",
       "   ['pa', 17, 576],\n",
       "   ['130', 18, 579],\n",
       "   ['/', 19, 582],\n",
       "   ['80', 20, 583],\n",
       "   [';', 21, 585],\n",
       "   ['MV', 22, 587],\n",
       "   ['presente', 23, 590],\n",
       "   [',', 24, 598],\n",
       "   ['simétrico', 25, 600],\n",
       "   [',', 26, 609],\n",
       "   ['sem', 27, 611],\n",
       "   ['RA', 28, 615],\n",
       "   ['.', 29, 617]],\n",
       "  [['afebril', [8], 'Problema'],\n",
       "   ['fc', [10], 'Teste'],\n",
       "   ['so2', [13], 'Teste'],\n",
       "   ['pa', [17], 'Teste'],\n",
       "   ['RA', [28], 'Problema']]],\n",
       " 8: [[['BC', 0, 619],\n",
       "   ['arritmicas', 1, 622],\n",
       "   [',', 2, 632],\n",
       "   ['NF', 3, 634],\n",
       "   ['SS', 4, 637],\n",
       "   ['2T', 5, 640],\n",
       "   ['.', 6, 642]],\n",
       "  [['BC arritmicas', [0, 1], 'Problema'], ['SS', [4], 'Problema']]],\n",
       " 9: [[['Abd', 0, 644],\n",
       "   ['globoso', 1, 648],\n",
       "   [',', 2, 655],\n",
       "   ['flacido', 3, 657],\n",
       "   [',', 4, 664],\n",
       "   ['indolor', 5, 666],\n",
       "   ['a', 6, 674],\n",
       "   ['palpacao', 7, 676],\n",
       "   [',', 8, 684],\n",
       "   ['sem', 9, 686],\n",
       "   ['VCM', 10, 690],\n",
       "   ['.', 11, 693]],\n",
       "  [['Abd', [0], 'Anatomia'], ['VCM', [10], 'Problema']]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicSentences_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'DNA', 'DNA', 'DNA', 'DNA', 'O', 'O', 'protein-DNA', 'protein-DNA', 'protein-DNA', 'DNA', 'DNA', 'O', 'O', 'O', 'DNA', 'DNA', 'O', 'DNA', 'O', 'O', 'O', 'O', 'O', 'DNA', 'DNA', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "[['we', 'have', 'previously', 'found', 'a', 'cis', '-', 'acting', 'region', 'spanning', 'the', 'gm', '-', 'csf', 'promoter', 'region', '(', 'positions', '-', '95', 'to', '+', '27', ')', 'that', 'confers', 'inducibility', 'to', 'reporter', 'genes', 'in', 'transient', 'transfection', 'assays', '.'], ['further', 'analysis', 'identified', 'three', 'elements', 'required', 'for', 'efficient', 'induction', 'of', 'mouse', 'and', 'human', 'gene', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(tags)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['FRASE2', [['gm - csf', ['DNA']]]],\n",
       " 1: ['FRASE1', [['cd28 surface receptor', 'protein']]]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaTags=['DNA', 'RNA','cell_type', 'cell_line','protein']\n",
    "\n",
    "dic_predictions = {}\n",
    "i=0\n",
    "for tags_sentence, tokens_sentence in zip(tags, tokens):\n",
    "    listaEntidades=[]\n",
    "    isEnt=0\n",
    "    labelAnterior=''\n",
    "    entidade=''\n",
    "    label=''\n",
    "    for tag, token in zip(tags_sentence, tokens_sentence):\n",
    "        #print(token, tag)\n",
    "        if tag!='O':\n",
    "            isEnt=1\n",
    "            label = tag.split('-')[0]\n",
    "            #print('---label-->:', label)\n",
    "            #print('---labelAnterior-->:', labelAnterior)\n",
    "            if label == labelAnterior:\n",
    "                # continuacao\n",
    "                entidade = entidade+' '+token\n",
    "            elif labelAnterior=='': # primeiro token da entidade\n",
    "                entidade=token\n",
    "                labelAnterior=label\n",
    "            else: # mudou de entidade\n",
    "                listaEntidades.append([entidade, labelAnterior])\n",
    "                entidade=token\n",
    "            labelAnterior = label\n",
    "        else:\n",
    "            if isEnt==1:\n",
    "                if entidade:\n",
    "                    #print('---label-->:', label)\n",
    "                    listaEntidades.append([entidade, label])\n",
    "            entidade=''\n",
    "            labelAnterior=''\n",
    "            isEnt=0\n",
    "            label=''\n",
    "\n",
    "    if len(listaEntidades)>0:\n",
    "        dic_predictions[i]=['FRASE1', listaEntidades]\n",
    "    i=i+1\n",
    "    \n",
    "i=0\n",
    "for tags_sentence, tokens_sentence in zip(tags, tokens):\n",
    "    listaEntidades=[]\n",
    "    isEnt=0\n",
    "    labelAnterior=''\n",
    "    entidade=''\n",
    "    label=''\n",
    "    for tag, token in zip(tags_sentence, tokens_sentence):\n",
    "        #print(token, tag)\n",
    "        if tag!='O':\n",
    "            isEnt=1\n",
    "            label = tag.split('-')\n",
    "            #print('label:', label)\n",
    "            #print('len(label):', len(label))\n",
    "            if len(label)>1:\n",
    "                label=label[1]\n",
    "                #print('---label-->:', label)\n",
    "                #print('---labelAnterior-->:', labelAnterior)\n",
    "                if label == labelAnterior:\n",
    "                    # continuacao\n",
    "                    entidade = entidade+' '+token\n",
    "                elif labelAnterior=='': # primeiro token da entidade\n",
    "                    entidade=token\n",
    "                    labelAnterior=label\n",
    "                else: # mudou de entidade\n",
    "                    listaEntidades.append([entidade, labelAnterior])\n",
    "                    entidade=token\n",
    "                labelAnterior = label\n",
    "        else:\n",
    "            if isEnt==1:\n",
    "                if entidade:\n",
    "                    #print('---label-->:', label)\n",
    "                    listaEntidades.append([entidade, label])\n",
    "            entidade=''\n",
    "            labelAnterior=''\n",
    "            isEnt=0\n",
    "            label=''\n",
    "\n",
    "    if len(listaEntidades)>0:\n",
    "        listaEntidadesTava=dic_predictions[i][1]\n",
    "        listaEntidadesTava.append(listaEntidades)\n",
    "        dic_predictions[i]=['FRASE2', listaEntidadesTava]\n",
    "    i=i+1\n",
    "dic_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_true_list, region_pred_list = f.AvalFinal(dicSentences_new_test, dic_predictions, BATCH)\n",
    "print(confusion_matrix(region_true_list, region_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 800\n",
      "Pegando sentencas de teste gabarito: dic_sentencesTest.pkl\n",
      "506\n",
      "[[['Nega', 0, 422], ['sincope', 1, 427], ['.', 2, 434]], [['sincope', [1], 'Problema']]]\n",
      "numero de sentencas no total: 506\n"
     ]
    }
   ],
   "source": [
    "# em numero de frases\n",
    "#BATCH=30\n",
    "#BATCH=100 \n",
    "BATCH=800\n",
    "#BATCH=8000 \n",
    "print('BATCH:', BATCH)\n",
    "\n",
    "dicSentences_new_test = f.loadSentencesTest()\n",
    "print(len(dicSentences_new_test))\n",
    "dicSentences_new_test = {k: v for k, v in dicSentences_new_test.items() if k<=BATCH}\n",
    "#print(dicSentences_new_test[0])\n",
    "print(dicSentences_new_test[27])\n",
    "print('numero de sentencas no total:', len(dicSentences_new_test))\n",
    "\n",
    "\n",
    "sentences=list()\n",
    "for key, value in dicSentences_new_test.items():\n",
    "    if key<BATCH:\n",
    "        tokens = value[0]\n",
    "        tokens = [tok[0] for tok in tokens]\n",
    "        sentences.append(' '.join(tokens).strip())\n",
    "#print(sentences[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx2tag: {0: 'O', 1: 'Anatomia', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'Problema', 1: 'O', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'O', 1: 'Tratamento', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n",
      "idx2tag: {0: 'O', 1: 'Teste', 2: '<pad>'}\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "len(dic_predictions): 506\n"
     ]
    }
   ],
   "source": [
    "tipos_entidade = ['Anatomia','Problema','Tratamento','Teste']\n",
    "#tipos_entidade = ['Anatomia']\n",
    "all_predictions = list()\n",
    "for tipo_entidade in tipos_entidade:\n",
    "    tags, tokens = f.predictBERTNER_IO(sentences, tipo_entidade)\n",
    "    dic_predictions = f.getDicPredictions(tags, tokens)\n",
    "    print(dic_predictions[0])\n",
    "    print('len(dic_predictions):', len(dic_predictions))\n",
    "    all_predictions.append(dic_predictions)\n",
    "    #f.save_obj('dic_predictions_io_bkp', dic_predictions)\n",
    "#dic_predictions = load_obj('dic_predictions_io_bkp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Abd', 0],\n",
       "  ['globoso', 1],\n",
       "  [',', 2],\n",
       "  ['flacido', 3],\n",
       "  [',', 4],\n",
       "  ['indolor', 5],\n",
       "  ['a', 6],\n",
       "  ['palpacao', 7],\n",
       "  [',', 8],\n",
       "  ['sem', 9],\n",
       "  ['VCM', 10],\n",
       "  ['.', 11]],\n",
       " [[['Abd'], [0], 'Anatomia']]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_obj('all_predictions_results_binarios_'+str(BATCH), all_predictions)\n",
    "#all_predictions = f.load_obj('all_predictions_results_binarios_batch_'+str(BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntar all_predictions\n",
    "dic_predictions = {}\n",
    "for num, prediction in enumerate(all_predictions):\n",
    "    if num==0:\n",
    "        dic_predictions = prediction.copy()\n",
    "        continue\n",
    "    for key, value in prediction.items():\n",
    "        entidadesJaEstavam=dic_predictions[key][1]\n",
    "        tokens=dic_predictions[key][0]\n",
    "        lista_entidade = [e for e in entidadesJaEstavam]\n",
    "        #print('lista_entidade:', lista_entidade)\n",
    "        entidades = value[1].copy()\n",
    "        if len(entidades)>0:\n",
    "            #print(entidades)\n",
    "            for entidade in entidades:\n",
    "                lista_entidade.append(entidade)\n",
    "            dic_predictions[key]=[tokens,lista_entidade]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 0\n",
      "[[['Lucas', 0], [',', 1], ['74', 2], ['anos', 3], ['.', 4]], []]\n",
      "key: 1\n",
      "[[['Em', 0], ['acompanhamento', 1], ['no', 2], ['ambualtorio', 3], ['há', 4], ['5', 5], ['anos', 6], ['por', 7], ['FA', 8], [',', 9], ['uso', 10], ['de', 11], ['marevan', 12], ['5mg', 13], ['1', 14], ['x', 15], ['ao', 16], ['dia', 17], ['.', 18]], [[['FA'], [8], 'Problema'], [['marevan', '5mg'], [12, 13], 'Tratamento']]]\n",
      "key: 2\n",
      "[[['Comorbidades', 0], [':', 1], ['DM', 2], ['há', 3], ['10', 4], ['anos', 5], ['em', 6], ['uso', 7], ['de', 8], ['metformina', 9], ['850mg', 10], ['3', 11], ['cp', 12], ['/', 13], ['dia', 14], [',', 15], ['acarbose', 16], ['1', 17], ['cp', 18], ['/', 19], ['dia', 20], ['e', 21], ['glicazida', 22], ['60mg', 23], ['2', 24], ['cp', 25], ['/', 26], ['dia', 27], ['e', 28], ['insulina', 29], ['(', 30], ['24', 31], ['-', 32], ['0', 33], ['-', 34], ['24', 35], [')', 36], ['.', 37]], [[['Comorbidades'], [0], 'Problema'], [['DM'], [2], 'Problema'], [['metformina', '850mg'], [9, 10], 'Tratamento'], [['acarbose'], [16], 'Tratamento'], [['glicazida', '60mg'], [22, 23], 'Tratamento'], [['insulina'], [29], 'Tratamento']]]\n",
      "key: 3\n",
      "[[['HAS', 0], ['há', 1], ['15', 2], ['anos', 3], ['em', 4], ['uso', 5], ['de', 6], ['losartana', 7], ['50mg', 8], ['/', 9], ['dia', 10], ['e', 11], ['digoxina', 12], ['1', 13], ['/', 14], ['2', 15], ['cp', 16], ['/', 17], ['dia', 18], [',', 19], ['carvedilol', 20], ['25', 21], ['12', 22], ['/', 23], ['12', 24], [',', 25], ['HCTZ', 26], ['.', 27]], [[['HAS'], [0], 'Problema'], [['losartana', '50mg'], [7, 8], 'Tratamento'], [['digoxina'], [12], 'Tratamento'], [['carvedilol', '25'], [20, 21], 'Tratamento'], [['HCTZ'], [26], 'Tratamento']]]\n",
      "key: 4\n",
      "[[['DSLP', 0], ['em', 1], ['uso', 2], ['de', 3], ['sinvastatina', 4], [',', 5], ['marevan', 6], ['1', 7], ['cp', 8], ['/', 9], ['dia', 10], ['seg', 11], ['-', 12], ['sab', 13], ['para', 14], ['no', 15], ['alvo', 16], ['sic', 17], ['.', 18]], [[['DSLP'], [0], 'Problema'], [['sinvastatina'], [4], 'Tratamento'], [['marevan'], [6], 'Tratamento']]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in dic_predictions.items():\n",
    "    print('key:',key)\n",
    "    print(dic_predictions[key])\n",
    "    if key>3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eval' from 'C:\\\\Users\\\\lisat\\\\OneDrive\\\\jupyter notebook\\\\spanclassification\\\\avaliacao\\\\eval.py'>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = reload(f)\n",
    "reload(dataset)\n",
    "reload(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['FA'], [8], 'Problema'], [['marevan', '5mg'], [12, 13], 'Tratamento']]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "506\n"
     ]
    }
   ],
   "source": [
    "print(len(dicSentences_new_test))\n",
    "print(len(dic_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_true_list, region_pred_list, lista_erros = f.getListaRegionsTruePred(BATCH, dicSentences_new_test, dic_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema', 'Tratamento', 'Problema', 'Problema']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_pred_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Problema', 'Tratamento', 'Problema', 'Problema']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_true_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 11, 11, 13, 13]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_erros[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['BC', 0], ['arritmicas', 1], [',', 2], ['NF', 3], ['SS', 4], ['2T', 5], ['.', 6]], [[['arritmicas'], [1], 'Problema'], [['NF', 'SS'], [3, 4], 'Problema']]]\n",
      "[['BC arritmicas', [0, 1], 'Problema'], ['SS', [4], 'Problema']]\n"
     ]
    }
   ],
   "source": [
    "print(dic_predictions[8])\n",
    "print(dicSentences_new_test[8][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Exames', 0], ['-', 1], ['Holter', 2], [':', 3], ['FC', 4], ['controlada', 5], [',', 6], ['media', 7], ['92', 8], ['.', 9]], [[['controlada'], [5], 'Problema'], [['Exames'], [0], 'Teste'], [['Holter'], [2], 'Teste'], [['FC'], [4], 'Teste']]]\n",
      "[['Exames', [0], 'Teste'], ['Holter', [2], 'Teste']]\n"
     ]
    }
   ],
   "source": [
    "print(dic_predictions[11])\n",
    "print(dicSentences_new_test[11][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Ecocardiograma', 0], ['-', 1], ['ventrículo', 2], ['esquerdo', 3], ['com', 4], ['hipertrofia', 5], ['concentrica', 6], ['de', 7], ['grau', 8], ['discreto', 9], ['e', 10], ['função', 11], ['sistólica', 12], ['preservada', 13], ['.', 14]], [[['ventrículo', 'esquerdo'], [2, 3], 'Anatomia'], [['hipertrofia', 'concentrica', 'de', 'grau', 'discreto'], [5, 6, 7, 8, 9], 'Problema'], [['Ecocardiograma'], [0], 'Teste']]]\n",
      "[['Ecocardiograma', [0], 'Teste'], ['ventrículo esquerdo com hipertrofia concentrica de grau discreto', [2, 3, 4, 5, 6, 7, 8, 9], 'Problema'], ['ventrículo esquerdo', [2, 3], 'Anatomia']]\n"
     ]
    }
   ],
   "source": [
    "print(dic_predictions[13])\n",
    "print(dicSentences_new_test[13][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(region_true_list): 1190\n",
      "len(region_pred_list): 1190\n",
      "-----Avaliando só modelo de NER:-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Anatomia   0.786730  0.846939  0.815725       196\n",
      "           O   0.000000  0.000000  0.000000       199\n",
      "    Problema   0.760753  0.837278  0.797183       338\n",
      "       Teste   0.867769  0.864198  0.865979       243\n",
      "  Tratamento   0.810185  0.817757  0.813953       214\n",
      "\n",
      "    accuracy                       0.700840      1190\n",
      "   macro avg   0.645087  0.673234  0.658568      1190\n",
      "weighted avg   0.668555  0.700840  0.683991      1190\n",
      "\n",
      "[[166  27   3   0   0]\n",
      " [ 44   0  83  32  40]\n",
      " [  0  55 283   0   0]\n",
      " [  1  31   0 210   1]\n",
      " [  0  36   3   0 175]]\n"
     ]
    }
   ],
   "source": [
    "print('len(region_true_list):', len(region_true_list))\n",
    "print('len(region_pred_list):', len(region_pred_list))\n",
    "#print('pred:',region_pred_list[:15])\n",
    "#print('true:',region_true_list[:15])\n",
    "\n",
    "print('-----Avaliando só modelo de NER:-----')\n",
    "\n",
    "print(classification_report(region_true_list, region_pred_list, digits=6))\n",
    "print(confusion_matrix(region_true_list, region_pred_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
