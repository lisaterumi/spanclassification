{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn_crfsuite as crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "NUM_JANELA=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dor'],\n",
       " ['no'],\n",
       " ['braço'],\n",
       " ['esquerdo'],\n",
       " ['e'],\n",
       " ['direito'],\n",
       " ['dor', 'no'],\n",
       " ['no', 'braço'],\n",
       " ['braço', 'esquerdo'],\n",
       " ['esquerdo', 'e'],\n",
       " ['e', 'direito'],\n",
       " ['dor', 'no', 'braço'],\n",
       " ['no', 'braço', 'esquerdo'],\n",
       " ['braço', 'esquerdo', 'e'],\n",
       " ['esquerdo', 'e', 'direito'],\n",
       " ['dor', 'no', 'braço', 'esquerdo'],\n",
       " ['no', 'braço', 'esquerdo', 'e'],\n",
       " ['braço', 'esquerdo', 'e', 'direito'],\n",
       " ['dor', 'no', 'braço', 'esquerdo', 'e'],\n",
       " ['no', 'braço', 'esquerdo', 'e', 'direito'],\n",
       " ['dor', 'no', 'braço', 'esquerdo', 'e', 'direito']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entidade = ['dor', 'no', 'braço', 'esquerdo','e','direito']\n",
    "\n",
    "lista=list()\n",
    "for i in range(1, len(entidade)+1):\n",
    "    #lista.append(entidade[i-1])\n",
    "    for j in range(len(entidade) - i + 1):\n",
    "        lista.append(entidade[j:j + i])\n",
    "        \n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTiposEntidade():\n",
    "    return ['Problema','Teste','Tratamento','Anatomia']\n",
    "\n",
    "def replaceWhiteSpaces(str):\n",
    "    return re.sub('\\s{2,}',' ',str)\n",
    "\n",
    "def save_obj(name, obj):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    print('Load obj em: ', 'obj/' + name + '.pkl')\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load obj em:  obj/../spanclassification/obj/dic_sentencesTrain.pkl\n",
      "Load obj em:  obj/../spanclassification/obj/dic_sentencesDev.pkl\n",
      "Load obj em:  obj/../spanclassification/obj/dic_sentencesTest.pkl\n"
     ]
    }
   ],
   "source": [
    "dic_sentencesTrain = load_obj(r'../spanclassification/obj/dic_sentencesTrain')\n",
    "dic_sentencesDev = load_obj(r'../spanclassification/obj/dic_sentencesDev')\n",
    "dic_sentencesTest = load_obj(r'../spanclassification/obj/dic_sentencesTest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Em', 0, 59],\n",
       "  ['acompanhamento', 1, 62],\n",
       "  ['no', 2, 77],\n",
       "  ['ambualtorio', 3, 80],\n",
       "  ['há', 4, 92],\n",
       "  ['5', 5, 95],\n",
       "  ['anos', 6, 97],\n",
       "  ['por', 7, 102],\n",
       "  ['FA', 8, 106],\n",
       "  [',', 9, 108],\n",
       "  ['uso', 10, 110],\n",
       "  ['de', 11, 114],\n",
       "  ['marevan', 12, 117],\n",
       "  ['5mg', 13, 125],\n",
       "  ['1', 14, 129],\n",
       "  ['x', 15, 131],\n",
       "  ['ao', 16, 133],\n",
       "  ['dia', 17, 136],\n",
       "  ['.', 18, 139]],\n",
       " [['FA', [8], 'Problema'], ['marevan 5mg', [12, 13], 'Tratamento']]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sentencesTest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListaPositiva(dic_sentences):\n",
    "    # só positivas:\n",
    "    listaSentencas=list()\n",
    "    lista=list()\n",
    "    numJanela=NUM_JANELA\n",
    "    for key, value in dic_sentences.items():\n",
    "        #print('value:', value)\n",
    "        entidades = value[1]\n",
    "        if len(entidades)==0:\n",
    "            continue\n",
    "        for entidade in entidades:\n",
    "            #print('entidade:', entidade)\n",
    "            label = entidade[2]\n",
    "            indiceEntidade1=entidade[1][0]\n",
    "            indiceEntidade2=entidade[1][-1]\n",
    "            vizinhosAntes = list()\n",
    "            vizinhosDepois = list()\n",
    "            #print('indiceEntidade:', indiceEntidade)\n",
    "            for tokens in value[0]:\n",
    "                indice=tokens[1]\n",
    "                #print('token: {}, indice: {}'.format(tokens[0], indice))\n",
    "                if indice+4>=indiceEntidade1 and indice<indiceEntidade1:\n",
    "                    vizinhosAntes.append(tokens[0])\n",
    "                if indice-4<=indiceEntidade2 and indice>indiceEntidade2:\n",
    "                    vizinhosDepois.append(tokens[0])\n",
    "            lista.append([entidade[0], vizinhosAntes, vizinhosDepois, label])\n",
    "        listaSentencas.append(lista)\n",
    "        lista=list()\n",
    "    return listaSentencas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['FA',\n",
       "   ['há', '5', 'anos', 'por'],\n",
       "   [',', 'uso', 'de', 'marevan'],\n",
       "   'Problema'],\n",
       "  ['marevan 5mg',\n",
       "   ['FA', ',', 'uso', 'de'],\n",
       "   ['1', 'x', 'ao', 'dia'],\n",
       "   'Tratamento']],\n",
       " [['Comorbidades', [], [':', 'DM', 'há', '10'], 'Problema'],\n",
       "  ['DM', ['Comorbidades', ':'], ['há', '10', 'anos', 'em'], 'Problema'],\n",
       "  ['metformina 850mg',\n",
       "   ['anos', 'em', 'uso', 'de'],\n",
       "   ['3', 'cp', '/', 'dia'],\n",
       "   'Tratamento'],\n",
       "  ['acarbose', ['cp', '/', 'dia', ','], ['1', 'cp', '/', 'dia'], 'Tratamento'],\n",
       "  ['glicazida 60mg',\n",
       "   ['cp', '/', 'dia', 'e'],\n",
       "   ['2', 'cp', '/', 'dia'],\n",
       "   'Tratamento'],\n",
       "  ['insulina', ['cp', '/', 'dia', 'e'], ['(', '24', '-', '0'], 'Tratamento']]]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = getListaPositiva(dic_sentencesTest)\n",
    "lista[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['HAS', [], [',', 'ICC', ',', 'nega'], 'Problema'],\n",
       "  ['ICC', ['HAS', ','], [',', 'nega', 'DM', '.'], 'Problema'],\n",
       "  ['DM', [',', 'ICC', ',', 'nega'], ['.'], 'Problema']],\n",
       " [['carvedilol', [], ['1', 'cp', '12', '/'], 'Tratamento'],\n",
       "  ['furosemida 20mg',\n",
       "   ['12', '/', '12', ','],\n",
       "   ['2', 'cp', 'de', '12'],\n",
       "   'Tratamento'],\n",
       "  ['sinvastatina',\n",
       "   ['12', '/', '12', ','],\n",
       "   ['1cp', 'a', 'noite', ','],\n",
       "   'Tratamento'],\n",
       "  ['AAS 100mg',\n",
       "   ['1cp', 'a', 'noite', ','],\n",
       "   ['apos', 'almoço', 'e', 'Omeprazol'],\n",
       "   'Tratamento'],\n",
       "  ['Omeprazol 20mg',\n",
       "   ['100mg', 'apos', 'almoço', 'e'],\n",
       "   ['1', 'xdia', '.'],\n",
       "   'Tratamento']]]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaDev = getListaPositiva(dic_sentencesDev)\n",
    "listaDev[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicPostagger['cardiaco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load obj em:  obj/../spanclassification/obj/dic_postagger.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicPostagger = load_obj('../spanclassification/obj/dic_postagger')\n",
    "def tipoPostaggerTokens(token, dicPostagger):\n",
    "    postagger = 'N' # na duvida é N\n",
    "    if token.lower() in dicPostagger.keys():\n",
    "        postagger = dicPostagger.get(token.lower())\n",
    "    return postagger\n",
    "tipoPostaggerTokens('coração', dicPostagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clusters(cluster_file):\n",
    "    word2cluster = {}\n",
    "    try:\n",
    "        with open(cluster_file, encoding='utf-8') as i:\n",
    "            for num, line in enumerate(i):\n",
    "                if line:\n",
    "                    word, cluster = line.strip().split('\\t')\n",
    "                    word2cluster[word] = cluster\n",
    "    except:\n",
    "        print(line)\n",
    "        print(num)\n",
    "        raise\n",
    "    return word2cluster\n",
    "\n",
    "\n",
    "def word2features(sent, word2cluster, dicPostagger):\n",
    "    try:\n",
    "        features = list()\n",
    "        entidades = sent[0]\n",
    "        for entidade in entidades.split():\n",
    "            postag = tipoPostaggerTokens(entidade, dicPostagger)\n",
    "            features.extend([\n",
    "            'bias',\n",
    "            'word.lower=' + entidade.lower(),\n",
    "            'word[-3:]=' + entidade[-3:],\n",
    "            'word[-2:]=' + entidade[-2:],\n",
    "            'word.isupper=%s' % entidade.isupper(),\n",
    "            'word.istitle=%s' % entidade.istitle(),\n",
    "            'word.isdigit=%s' % entidade.isdigit(),\n",
    "            'word.cluster=%s' % word2cluster[entidade.lower()] if entidade.lower() in word2cluster else \"0\",\n",
    "            'postag=' + postag\n",
    "            ])\n",
    "        # palavras anteriores\n",
    "        vizinhosAntes = sent[1] \n",
    "        if len(vizinhosAntes)>0:\n",
    "            for num, vizinhoAntes in enumerate(vizinhosAntes):\n",
    "                word1 = vizinhoAntes\n",
    "                postag1 =  tipoPostaggerTokens(vizinhoAntes, dicPostagger)\n",
    "                features.extend([\n",
    "                    '-'+str(num+1)+':word.lower=' + word1.lower(),\n",
    "                    '-'+str(num+1)+':word.istitle=%s' % word1.istitle(),\n",
    "                    '-'+str(num+1)+':word.isupper=%s' % word1.isupper(),\n",
    "                    '-'+str(num+1)+':postag=' + postag1\n",
    "                ])\n",
    "        else:\n",
    "            features.append('BOS')\n",
    "\n",
    "        # próximas palavras\n",
    "        vizinhosDepois = sent[2]\n",
    "        if len(vizinhosDepois)>0:\n",
    "            for num, vizinhoDepois in enumerate(vizinhosDepois):\n",
    "                word1 = vizinhoDepois\n",
    "                postag1 =  tipoPostaggerTokens(vizinhoDepois, dicPostagger)\n",
    "                features.extend([\n",
    "                    '+'+str(num+1)+':word.lower=' + word1.lower(),\n",
    "                    '+'+str(num+1)+':word.istitle=%s' % word1.istitle(),\n",
    "                    '+'+str(num+1)+':word.isupper=%s' % word1.isupper(),\n",
    "                    '+'+str(num+1)+':postag=' + postag1\n",
    "                ])\n",
    "        else:\n",
    "            features.append('EOS')\n",
    "    except:\n",
    "        print('sent:', sent)\n",
    "        raise\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(lista, word2cluster, dicPostagger):\n",
    "    #return word2features(lista, word2cluster, dicPostagger)\n",
    "    return [word2features(lista[i], word2cluster, dicPostagger) for i in range(len(lista))]\n",
    "\n",
    "def sent2labels(lista):\n",
    "    #return [label for _, _, _, label in lista]\n",
    "    return [label for _, _, _, label in lista]\n",
    "\n",
    "\n",
    "#def sent2tokens(sent):\n",
    "#    return [token for token, postag, label in sent]\n",
    "\n",
    "word2cluster = read_clusters(r\"clusters/cluster-50.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dor: 25\n",
      "esquerdo: 11\n",
      "direito: 11\n",
      "peito: 31\n",
      "no: 24\n",
      "na: 24\n",
      "coração: 11\n",
      "válvula: 29\n",
      "cardíaca: 9\n",
      "miocárdica: 46\n",
      "mitral: 41\n",
      "mmii: 7\n",
      "coronária: 5\n"
     ]
    }
   ],
   "source": [
    "print('dor:',word2cluster['dor'])\n",
    "print('esquerdo:',word2cluster['esquerdo'])\n",
    "print('direito:',word2cluster['direito'])\n",
    "print('peito:',word2cluster['peito'])\n",
    "print('no:',word2cluster['no'])\n",
    "print('na:',word2cluster['na'])\n",
    "print('coração:',word2cluster['coração'])\n",
    "print('válvula:',word2cluster['válvula'])\n",
    "print('cardíaca:',word2cluster['cardíaca'])\n",
    "print('miocárdica:',word2cluster['miocárdica'])\n",
    "print('mitral:',word2cluster['mitral'])\n",
    "print('mmii:',word2cluster['mmii'])\n",
    "print('coronária:',word2cluster['coronária'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word.lower=fa',\n",
       " 'word[-3:]=FA',\n",
       " 'word[-2:]=FA',\n",
       " 'word.isupper=True',\n",
       " 'word.istitle=False',\n",
       " 'word.isdigit=False',\n",
       " 'word.cluster=8',\n",
       " 'postag=N',\n",
       " '-1:word.lower=há',\n",
       " '-1:word.istitle=False',\n",
       " '-1:word.isupper=False',\n",
       " '-1:postag=V',\n",
       " '-2:word.lower=5',\n",
       " '-2:word.istitle=False',\n",
       " '-2:word.isupper=False',\n",
       " '-2:postag=NUM',\n",
       " '-3:word.lower=anos',\n",
       " '-3:word.istitle=False',\n",
       " '-3:word.isupper=False',\n",
       " '-3:postag=N',\n",
       " '-4:word.lower=por',\n",
       " '-4:word.istitle=False',\n",
       " '-4:word.isupper=False',\n",
       " '-4:postag=PREP',\n",
       " '+1:word.lower=,',\n",
       " '+1:word.istitle=False',\n",
       " '+1:word.isupper=False',\n",
       " '+1:postag=PU',\n",
       " '+2:word.lower=uso',\n",
       " '+2:word.istitle=False',\n",
       " '+2:word.isupper=False',\n",
       " '+2:postag=N',\n",
       " '+3:word.lower=de',\n",
       " '+3:word.istitle=False',\n",
       " '+3:word.isupper=False',\n",
       " '+3:postag=PREP',\n",
       " '+4:word.lower=marevan',\n",
       " '+4:word.istitle=False',\n",
       " '+4:word.isupper=False',\n",
       " '+4:postag=N']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(lista[0], word2cluster, dicPostagger)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = word2features(lista, word2cluster, dicPostagger)\n",
    "#X_train = [sent2features(s, word2cluster) for s in train_sents]\n",
    "X_train = [sent2features(s, word2cluster, dicPostagger) for s in lista]\n",
    "#y_train = [sent2labels(s) for s in train_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bias', 'word.lower=fa', 'word[-3:]=FA', 'word[-2:]=FA', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'word.cluster=8', 'postag=N', '-1:word.lower=há', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=V', '-2:word.lower=5', '-2:word.istitle=False', '-2:word.isupper=False', '-2:postag=NUM', '-3:word.lower=anos', '-3:word.istitle=False', '-3:word.isupper=False', '-3:postag=N', '-4:word.lower=por', '-4:word.istitle=False', '-4:word.isupper=False', '-4:postag=PREP', '+1:word.lower=,', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=PU', '+2:word.lower=uso', '+2:word.istitle=False', '+2:word.isupper=False', '+2:postag=N', '+3:word.lower=de', '+3:word.istitle=False', '+3:word.isupper=False', '+3:postag=PREP', '+4:word.lower=marevan', '+4:word.istitle=False', '+4:word.isupper=False', '+4:postag=N'], ['bias', 'word.lower=marevan', 'word[-3:]=van', 'word[-2:]=an', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'word.cluster=17', 'postag=N', 'bias', 'word.lower=5mg', 'word[-3:]=5mg', 'word[-2:]=mg', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'word.cluster=17', 'postag=N', '-1:word.lower=fa', '-1:word.istitle=False', '-1:word.isupper=True', '-1:postag=N', '-2:word.lower=,', '-2:word.istitle=False', '-2:word.isupper=False', '-2:postag=PU', '-3:word.lower=uso', '-3:word.istitle=False', '-3:word.isupper=False', '-3:postag=N', '-4:word.lower=de', '-4:word.istitle=False', '-4:word.isupper=False', '-4:postag=PREP', '+1:word.lower=1', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=NUM', '+2:word.lower=x', '+2:word.istitle=False', '+2:word.isupper=False', '+2:postag=N', '+3:word.lower=ao', '+3:word.istitle=False', '+3:word.isupper=False', '+3:postag=PREP', '+4:word.lower=dia', '+4:word.istitle=False', '+4:word.isupper=False', '+4:postag=N']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = sent2labels(lista)\n",
    "y_train =[sent2labels(s) for s in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = [sent2features(s, word2cluster, dicPostagger) for s in listaDev]\n",
    "y_dev = [sent2labels(s) for s in listaDev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Problema', 'Tratamento'],\n",
       " ['Problema',\n",
       "  'Problema',\n",
       "  'Tratamento',\n",
       "  'Tratamento',\n",
       "  'Tratamento',\n",
       "  'Tratamento'],\n",
       " ['Problema', 'Tratamento', 'Tratamento', 'Tratamento', 'Tratamento'],\n",
       " ['Problema', 'Tratamento', 'Tratamento'],\n",
       " ['Problema', 'Problema', 'Problema', 'Problema', 'Problema'],\n",
       " ['Problema', 'Teste', 'Teste', 'Teste', 'Problema'],\n",
       " ['Problema', 'Problema'],\n",
       " ['Anatomia', 'Problema'],\n",
       " ['Anatomia', 'Problema', 'Anatomia'],\n",
       " ['Teste', 'Teste']]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(lista))\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 399/399 [00:00<00:00, 7124.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading dev data to CRFsuite: 100%|██████████| 327/327 [00:00<00:00, 12110.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout group: 2\n",
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 5102\n",
      "Seconds required: 0.030\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.01  loss=1286.91  active=4999  precision=0.088  recall=0.250  F1=0.130  Acc(item/seq)=0.353 0.315  feature_norm=0.25\n",
      "Iter 2   time=0.01  loss=1231.02  active=4961  precision=0.307  recall=0.280  F1=0.187  Acc(item/seq)=0.380 0.318  feature_norm=0.28\n",
      "Iter 3   time=0.01  loss=1053.20  active=4863  precision=0.727  recall=0.557  F1=0.518  Acc(item/seq)=0.612 0.498  feature_norm=0.73\n",
      "Iter 4   time=0.00  loss=899.16   active=5000  precision=0.710  recall=0.661  F1=0.669  Acc(item/seq)=0.701 0.569  feature_norm=1.21\n",
      "Iter 5   time=0.00  loss=707.84   active=4960  precision=0.759  recall=0.690  F1=0.705  Acc(item/seq)=0.734 0.599  feature_norm=2.47\n",
      "Iter 6   time=0.01  loss=600.05   active=4890  precision=0.738  recall=0.726  F1=0.716  Acc(item/seq)=0.725 0.606  feature_norm=3.51\n",
      "Iter 7   time=0.00  loss=498.77   active=4947  precision=0.744  recall=0.722  F1=0.725  Acc(item/seq)=0.750 0.636  feature_norm=4.48\n",
      "Iter 8   time=0.00  loss=422.33   active=4967  precision=0.795  recall=0.782  F1=0.785  Acc(item/seq)=0.794 0.685  feature_norm=5.72\n",
      "Iter 9   time=0.00  loss=361.12   active=4956  precision=0.799  recall=0.782  F1=0.781  Acc(item/seq)=0.798 0.706  feature_norm=7.19\n",
      "Iter 10  time=0.00  loss=312.58   active=4989  precision=0.822  recall=0.820  F1=0.819  Acc(item/seq)=0.825 0.734  feature_norm=8.15\n",
      "Iter 11  time=0.00  loss=276.76   active=4967  precision=0.832  recall=0.835  F1=0.833  Acc(item/seq)=0.838 0.737  feature_norm=9.23\n",
      "Iter 12  time=0.00  loss=264.25   active=4667  precision=0.861  recall=0.822  F1=0.829  Acc(item/seq)=0.829 0.740  feature_norm=11.64\n",
      "Iter 13  time=0.00  loss=216.96   active=4659  precision=0.854  recall=0.852  F1=0.852  Acc(item/seq)=0.855 0.771  feature_norm=12.48\n",
      "Iter 14  time=0.00  loss=206.49   active=4661  precision=0.850  recall=0.855  F1=0.852  Acc(item/seq)=0.855 0.768  feature_norm=12.99\n",
      "Iter 15  time=0.00  loss=190.39   active=4643  precision=0.873  recall=0.867  F1=0.868  Acc(item/seq)=0.871 0.792  feature_norm=13.77\n",
      "Iter 16  time=0.00  loss=167.55   active=4478  precision=0.871  recall=0.873  F1=0.871  Acc(item/seq)=0.873 0.795  feature_norm=15.14\n",
      "Iter 17  time=0.00  loss=157.00   active=4269  precision=0.887  recall=0.864  F1=0.872  Acc(item/seq)=0.872 0.792  feature_norm=15.49\n",
      "Iter 18  time=0.00  loss=148.59   active=4246  precision=0.876  recall=0.867  F1=0.869  Acc(item/seq)=0.869 0.789  feature_norm=15.94\n",
      "Iter 19  time=0.00  loss=143.18   active=4076  precision=0.880  recall=0.875  F1=0.875  Acc(item/seq)=0.876 0.795  feature_norm=16.21\n",
      "Iter 20  time=0.00  loss=138.22   active=3769  precision=0.875  recall=0.868  F1=0.868  Acc(item/seq)=0.869 0.783  feature_norm=16.44\n",
      "Iter 21  time=0.00  loss=135.17   active=3569  precision=0.885  recall=0.888  F1=0.885  Acc(item/seq)=0.886 0.813  feature_norm=16.66\n",
      "Iter 22  time=0.00  loss=133.54   active=3445  precision=0.884  recall=0.884  F1=0.882  Acc(item/seq)=0.883 0.807  feature_norm=16.72\n",
      "Iter 23  time=0.00  loss=131.17   active=3126  precision=0.880  recall=0.878  F1=0.877  Acc(item/seq)=0.879 0.804  feature_norm=16.95\n",
      "Iter 24  time=0.00  loss=129.56   active=2895  precision=0.883  recall=0.883  F1=0.881  Acc(item/seq)=0.883 0.810  feature_norm=17.45\n",
      "Iter 25  time=0.00  loss=128.48   active=2871  precision=0.884  recall=0.876  F1=0.878  Acc(item/seq)=0.881 0.804  feature_norm=17.59\n",
      "Iter 26  time=0.00  loss=127.86   active=2844  precision=0.878  recall=0.875  F1=0.875  Acc(item/seq)=0.878 0.801  feature_norm=17.68\n",
      "Iter 27  time=0.00  loss=127.33   active=2802  precision=0.880  recall=0.880  F1=0.878  Acc(item/seq)=0.882 0.810  feature_norm=17.74\n",
      "Iter 28  time=0.00  loss=125.97   active=2676  precision=0.880  recall=0.878  F1=0.877  Acc(item/seq)=0.881 0.807  feature_norm=17.83\n",
      "Iter 29  time=0.00  loss=125.80   active=2497  precision=0.881  recall=0.880  F1=0.879  Acc(item/seq)=0.881 0.807  feature_norm=17.91\n",
      "Iter 30  time=0.00  loss=124.63   active=2525  precision=0.876  recall=0.874  F1=0.873  Acc(item/seq)=0.875 0.801  feature_norm=17.89\n",
      "Iter 31  time=0.00  loss=124.26   active=2482  precision=0.875  recall=0.872  F1=0.871  Acc(item/seq)=0.873 0.798  feature_norm=17.87\n",
      "Iter 32  time=0.00  loss=123.70   active=2400  precision=0.878  recall=0.878  F1=0.876  Acc(item/seq)=0.878 0.807  feature_norm=17.91\n",
      "Iter 33  time=0.00  loss=123.30   active=2284  precision=0.873  recall=0.867  F1=0.867  Acc(item/seq)=0.869 0.801  feature_norm=17.90\n",
      "Iter 34  time=0.00  loss=122.77   active=2265  precision=0.874  recall=0.872  F1=0.870  Acc(item/seq)=0.872 0.801  feature_norm=17.93\n",
      "Iter 35  time=0.00  loss=122.45   active=2204  precision=0.876  recall=0.873  F1=0.872  Acc(item/seq)=0.873 0.804  feature_norm=17.93\n",
      "Iter 36  time=0.00  loss=122.06   active=2099  precision=0.880  recall=0.881  F1=0.878  Acc(item/seq)=0.882 0.807  feature_norm=17.94\n",
      "Iter 37  time=0.00  loss=121.75   active=2080  precision=0.880  recall=0.876  F1=0.876  Acc(item/seq)=0.878 0.810  feature_norm=17.93\n",
      "Iter 38  time=0.00  loss=121.49   active=2047  precision=0.879  recall=0.876  F1=0.875  Acc(item/seq)=0.878 0.810  feature_norm=17.96\n",
      "Iter 39  time=0.00  loss=121.21   active=2021  precision=0.879  recall=0.876  F1=0.875  Acc(item/seq)=0.878 0.810  feature_norm=17.95\n",
      "Iter 40  time=0.00  loss=120.97   active=1972  precision=0.880  recall=0.881  F1=0.879  Acc(item/seq)=0.882 0.807  feature_norm=17.97\n",
      "Iter 41  time=0.00  loss=120.75   active=1973  precision=0.877  recall=0.874  F1=0.873  Acc(item/seq)=0.876 0.807  feature_norm=17.96\n",
      "Iter 42  time=0.00  loss=120.63   active=1947  precision=0.877  recall=0.874  F1=0.873  Acc(item/seq)=0.876 0.807  feature_norm=17.97\n",
      "Iter 43  time=0.00  loss=120.44   active=1919  precision=0.877  recall=0.874  F1=0.873  Acc(item/seq)=0.876 0.807  feature_norm=17.97\n",
      "Iter 44  time=0.00  loss=120.32   active=1904  precision=0.875  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.804  feature_norm=17.99\n",
      "Iter 45  time=0.00  loss=120.21   active=1909  precision=0.875  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.804  feature_norm=17.98\n",
      "Iter 46  time=0.00  loss=120.11   active=1891  precision=0.876  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.807  feature_norm=17.99\n",
      "Iter 47  time=0.00  loss=120.01   active=1876  precision=0.874  recall=0.872  F1=0.871  Acc(item/seq)=0.873 0.804  feature_norm=18.01\n",
      "Iter 48  time=0.00  loss=119.92   active=1868  precision=0.876  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.807  feature_norm=18.02\n",
      "Iter 49  time=0.00  loss=119.86   active=1865  precision=0.876  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.807  feature_norm=18.03\n",
      "Iter 50  time=0.00  loss=119.80   active=1849  precision=0.878  recall=0.874  F1=0.874  Acc(item/seq)=0.876 0.810  feature_norm=18.03\n",
      "Iter 51  time=0.00  loss=119.73   active=1825  precision=0.880  recall=0.877  F1=0.876  Acc(item/seq)=0.878 0.813  feature_norm=18.04\n",
      "Iter 52  time=0.00  loss=119.68   active=1805  precision=0.880  recall=0.877  F1=0.876  Acc(item/seq)=0.878 0.813  feature_norm=18.05\n",
      "Iter 53  time=0.00  loss=119.62   active=1794  precision=0.880  recall=0.877  F1=0.876  Acc(item/seq)=0.878 0.813  feature_norm=18.05\n",
      "Iter 54  time=0.00  loss=119.58   active=1791  precision=0.882  recall=0.878  F1=0.878  Acc(item/seq)=0.879 0.817  feature_norm=18.06\n",
      "Iter 55  time=0.00  loss=119.54   active=1777  precision=0.876  recall=0.873  F1=0.872  Acc(item/seq)=0.875 0.810  feature_norm=18.08\n",
      "Iter 56  time=0.00  loss=119.51   active=1770  precision=0.884  recall=0.878  F1=0.879  Acc(item/seq)=0.881 0.817  feature_norm=18.08\n",
      "Iter 57  time=0.00  loss=119.47   active=1766  precision=0.876  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.09\n",
      "Iter 58  time=0.00  loss=119.44   active=1749  precision=0.878  recall=0.873  F1=0.873  Acc(item/seq)=0.876 0.817  feature_norm=18.09\n",
      "Iter 59  time=0.00  loss=119.42   active=1744  precision=0.876  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.10\n",
      "Iter 60  time=0.00  loss=119.40   active=1743  precision=0.878  recall=0.873  F1=0.873  Acc(item/seq)=0.876 0.817  feature_norm=18.10\n",
      "Iter 61  time=0.00  loss=119.37   active=1728  precision=0.876  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.11\n",
      "Iter 62  time=0.00  loss=119.35   active=1722  precision=0.878  recall=0.873  F1=0.873  Acc(item/seq)=0.876 0.817  feature_norm=18.11\n",
      "Iter 63  time=0.00  loss=119.33   active=1717  precision=0.876  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.12\n",
      "Iter 64  time=0.00  loss=119.31   active=1711  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.12\n",
      "Iter 65  time=0.00  loss=119.29   active=1705  precision=0.873  recall=0.869  F1=0.869  Acc(item/seq)=0.872 0.810  feature_norm=18.13\n",
      "Iter 66  time=0.00  loss=119.28   active=1701  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.13\n",
      "Iter 67  time=0.00  loss=119.26   active=1697  precision=0.867  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.13\n",
      "Iter 68  time=0.00  loss=119.25   active=1692  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.13\n",
      "Iter 69  time=0.00  loss=119.23   active=1685  precision=0.866  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.14\n",
      "Iter 70  time=0.00  loss=119.21   active=1676  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.14\n",
      "Iter 71  time=0.00  loss=119.20   active=1673  precision=0.866  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.14\n",
      "Iter 72  time=0.00  loss=119.18   active=1668  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.14\n",
      "Iter 73  time=0.00  loss=119.17   active=1666  precision=0.866  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.15\n",
      "Iter 74  time=0.00  loss=119.16   active=1666  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.15\n",
      "Iter 75  time=0.00  loss=119.14   active=1665  precision=0.867  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.16\n",
      "Iter 76  time=0.00  loss=119.13   active=1666  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.15\n",
      "Iter 77  time=0.00  loss=119.12   active=1668  precision=0.867  recall=0.866  F1=0.864  Acc(item/seq)=0.868 0.801  feature_norm=18.17\n",
      "Iter 78  time=0.00  loss=119.11   active=1666  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.16\n",
      "Iter 79  time=0.00  loss=119.09   active=1665  precision=0.870  recall=0.869  F1=0.867  Acc(item/seq)=0.871 0.804  feature_norm=18.17\n",
      "Iter 80  time=0.00  loss=119.09   active=1661  precision=0.875  recall=0.870  F1=0.870  Acc(item/seq)=0.873 0.813  feature_norm=18.17\n",
      "Iter 81  time=0.00  loss=119.07   active=1660  precision=0.870  recall=0.869  F1=0.867  Acc(item/seq)=0.871 0.804  feature_norm=18.18\n",
      "Iter 82  time=0.00  loss=119.07   active=1661  precision=0.877  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.18\n",
      "Iter 83  time=0.00  loss=119.06   active=1661  precision=0.870  recall=0.869  F1=0.867  Acc(item/seq)=0.871 0.804  feature_norm=18.19\n",
      "Iter 84  time=0.00  loss=119.05   active=1659  precision=0.877  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.18\n",
      "Iter 85  time=0.00  loss=119.04   active=1658  precision=0.870  recall=0.869  F1=0.867  Acc(item/seq)=0.871 0.804  feature_norm=18.19\n",
      "Iter 86  time=0.00  loss=119.03   active=1656  precision=0.877  recall=0.872  F1=0.872  Acc(item/seq)=0.875 0.813  feature_norm=18.19\n",
      "Iter 87  time=0.00  loss=119.02   active=1655  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.20\n",
      "Iter 88  time=0.00  loss=119.02   active=1651  precision=0.878  recall=0.874  F1=0.874  Acc(item/seq)=0.876 0.817  feature_norm=18.19\n",
      "Iter 89  time=0.00  loss=119.01   active=1647  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 90  time=0.00  loss=119.00   active=1646  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.20\n",
      "Iter 91  time=0.00  loss=118.99   active=1645  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 92  time=0.00  loss=118.98   active=1642  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.20\n",
      "Iter 93  time=0.00  loss=118.98   active=1642  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 94  time=0.00  loss=118.97   active=1641  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 95  time=0.00  loss=118.97   active=1641  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 96  time=0.00  loss=118.96   active=1640  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 97  time=0.00  loss=118.95   active=1642  precision=0.870  recall=0.870  F1=0.868  Acc(item/seq)=0.871 0.807  feature_norm=18.22\n",
      "Iter 98  time=0.00  loss=118.95   active=1642  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.21\n",
      "Iter 99  time=0.00  loss=118.94   active=1639  precision=0.870  recall=0.870  F1=0.868  Acc(item/seq)=0.871 0.807  feature_norm=18.22\n",
      "Iter 100 time=0.00  loss=118.94   active=1636  precision=0.872  recall=0.871  F1=0.869  Acc(item/seq)=0.872 0.807  feature_norm=18.22\n",
      "===================================================\n",
      "Label         Precision    Recall     F1    Support\n",
      "----------  -----------  --------  -----  ---------\n",
      "Anatomia          0.841     0.826  0.833        109\n",
      "Problema          0.856     0.883  0.869        248\n",
      "Teste             0.864     0.974  0.916        156\n",
      "Tratamento        0.927     0.800  0.859        190\n",
      "---------------------------------------------------\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 0.267\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1636 (5102)\n",
      "Number of active attributes: 1147 (4881)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.004\n",
      "\n",
      "Training time: 0.4s\n",
      "CRF model was trained!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#crfsuite is an implementation for Conditional Random Field\n",
    "\n",
    "#!pip install sklearn-crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         verbose='true',\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "\n",
    "start = time.time()\n",
    "crf.fit(X_train, y_train, X_dev=X_dev, y_dev=y_dev)\n",
    "#crf.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {round(stop - start,2)}s\")\n",
    "\n",
    "print('CRF model was trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eli5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-242bcacf37fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'eli5'"
     ]
    }
   ],
   "source": [
    "!pip install eli5\n",
    "import eli5\n",
    "\n",
    "eli5.show_weights(crf, top=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load obj em:  obj/../spanclassification/obj/dic_predictions_results_ner_800.pkl\n"
     ]
    }
   ],
   "source": [
    "dic_predictions_results_ner = load_obj(r'../spanclassification/obj/dic_predictions_results_ner_800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Paciente', 0],\n",
       "  ['em', 1],\n",
       "  ['tratamento', 2],\n",
       "  ['para', 3],\n",
       "  ['ICC', 4],\n",
       "  ['diastólica', 5],\n",
       "  ['há', 6],\n",
       "  ['cerca', 7],\n",
       "  ['de', 8],\n",
       "  ['5', 9],\n",
       "  ['a', 10],\n",
       "  ['com', 11],\n",
       "  ['melhora', 12],\n",
       "  ['importante', 13],\n",
       "  ['dos', 14],\n",
       "  ['sintomas', 15],\n",
       "  ['após', 16],\n",
       "  ['início', 17],\n",
       "  ['do', 18],\n",
       "  ['tratamento', 19],\n",
       "  ['.', 20]],\n",
       " [['ICC diastólica', [4, 5], 'Problema'], ['tratamento', [19], 'Tratamento']]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_predictions_results_ner[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dor'], ['no'], ['peito'], ['dor', 'no'], ['no', 'peito'], ['dor', 'no', 'peito']]\n"
     ]
    }
   ],
   "source": [
    "# para corpus GENIA, ideal pq pega as descontinuas\n",
    "# no nestedclin, as descontinuas\n",
    "def powersetGenia(s):\n",
    "    x = len(s)\n",
    "    masks = [1 << i for i in range(x)]\n",
    "    for i in range(1 << x):\n",
    "        yield [ss for mask, ss in zip(masks, s) if i & mask]\n",
    "        \n",
    "def powerset(entidade):    \n",
    "    lista=list()\n",
    "    for i in range(1, len(entidade)+1):\n",
    "        #lista.append(entidade[i-1])\n",
    "        for j in range(len(entidade) - i + 1):\n",
    "            lista.append(entidade[j:j + i])\n",
    "    return lista\n",
    "        \n",
    "#print(list(powerset([4, 5, 6])))\n",
    "print(powerset(['dor', 'no', 'peito']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samplecorpusformat = [[['POI', 'B-Abbreviation'],  ['DE', 'O'],  ['LAVAGEM', 'O'],  ['+', 'O'],  ['CURETA', 'O'],  ['DE', 'O'],  ['TECIDO', 'O'],  ['NECROTICO', 'O'],  ['.', 'O']], [['18', 'O'],  [':', 'O'],  ['00', 'O'],  [':', 'O'],  ['PACIENTE', 'O'],  ['RETORNOU', 'O'],  ['DO', 'O'],  ['CC', 'B-Abbreviation'],  ['LUCIDO', 'O'], [',', 'O'],  ['ORIENTADO', 'O'],  [',', 'O'],  ['COMUNICATIVO', 'O'],  [';', 'O'], ['MANTEM', 'O'],  ['AVP', 'B-Abbreviation'],  ['COM', 'O'],  ['STP', 'B-Abbreviation'], ['.', 'O']]]\n",
    "\n",
    "# corpus:\n",
    "# gravar os indices dos tokens\n",
    "# para cada entidade, gerar a combinação possivel de tokens e pegar as features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
